"""AI æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨ (æ•´æ´é‡æ„ç‰ˆ)

ä¸»è¦åŠŸèƒ½:
- å•æ¡/æ‰¹é‡éœ€æ±‚ç”¨ä¾‹ç”Ÿæˆ
- èƒŒæ™¯çŸ¥è¯†æ–‡æ¡£æ”¯æŒ (docx/txt/md)
- CSV å¯¼å‡ºä¸ç»“æœåˆ†æ
"""

import re
import logging
from io import BytesIO
from typing import Dict, Any, List, Optional
import time
import pandas as pd
import streamlit as st

from helper_functions import fetch_feishu_document
from app_handlers import (
    handle_single_requirement,
    handle_batch_processing,
    handle_help_page
)
from file_processors import (
    _process_excel_file,
    _process_word_file,
    _process_pdf_file,
    _process_text_file
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === åº”ç”¨åŸºç¡€é…ç½® ===
class AppConfig:
    """åº”ç”¨ç¨‹åºé…ç½®"""
    # åŸºæœ¬å‚æ•°
    DEFAULT_HEADERS = ["æµ‹è¯•åç§°", "éœ€æ±‚ç¼–å·", "éœ€æ±‚æè¿°", "æµ‹è¯•æè¿°", "å‰ç½®æ¡ä»¶", "æµ‹è¯•æ­¥éª¤", "é¢„æœŸç»“æœ", "éœ€æ±‚è¿½æº¯"]
    DEFAULT_BASE_URL = "http://model.mify.ai.srv"  # å†…éƒ¨æœåŠ¡ä¼˜å…ˆ
    MAX_RETRY_ATTEMPTS = 3
    MIN_PARAGRAPH_LENGTH = 10
    API_KEY = "sk-HXFiS9bEeg95uypM96B6kJfKaxe3ze52FUeQEriGGaGIIefS"  # å›ºå®šç¡¬ç¼–ç 

    # æ¨¡å‹é…ç½®
    MODEL_MAP = {
        "MiMo-7B-RL": "MiMo-7B-RL",
        "Qwen-235B-A22B": "Qwen-235B-A22B", 
        "deepseek-v3.1": "deepseek-v3.1",
        "Qwen2.5-VL-72B-Instruct-AWQ": "Qwen2.5-VL-72B-Instruct-AWQ"
    }
    
    ALLOWED_MODELS = list(MODEL_MAP.keys())
    
    MODEL_PRICING_TAG = {
        "MiMo-7B-RL": "(å…è´¹)",
        "Qwen-235B-A22B": "(è®¡è´¹)",
        "deepseek-v3.1": "(è®¡è´¹)",
        "Qwen2.5-VL-72B-Instruct-AWQ": "(è®¡è´¹)"
    }
    
    # æœåŠ¡è·¯ç”±é…ç½®
    ROUTE_HEADER_VALUE = "xiaomi"  # é»˜è®¤ç”¨äº MiMo
    MODEL_PROVIDER_HEADER = {
        "MiMo-7B-RL": "xiaomi",
        "Qwen-235B-A22B": "openai_api_compatible",
        "deepseek-v3.1": "openai_api_compatible",
        "Qwen2.5-VL-72B-Instruct-AWQ": "openai_api_compatible"
    }

class FeishuConfig:
    """é£ä¹¦APIé…ç½®"""
    BASE_API = os.environ.get("FEISHU_OPEN_BASE", "https://open.feishu.cn")
    TOKEN_ENDPOINT = f"{BASE_API}/open-apis/auth/v3/tenant_access_token/internal"
    USER_TOKEN_ENDPOINT = f"{BASE_API}/open-apis/authen/v1/access_token"
    OAUTH_AUTHORIZE_URL = f"{BASE_API}/open-apis/authen/v1/authorize"
    OAUTH_TOKEN_URL = f"{BASE_API}/open-apis/authen/v1/refresh_access_token"
    DOC_ENDPOINT_TMPL = f"{BASE_API}/open-apis/docx/v1/documents/{{doc_id}}"
    BLOCKS_ENDPOINT_TMPL = f"{BASE_API}/open-apis/docx/v1/documents/{{doc_id}}/blocks/{{block_id}}?page_size={{page_size}}&page_token={{page_token}}"

# é£ä¹¦æ–‡æ¡£å—ç±»å‹æŠ½å–ç­–ç•¥
FEISHU_INLINE_KEY_CANDIDATES = ["elements", "runs", "inlines", "text_run"]

def handle_errors(func):
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.exception(e)
            msg = str(e)
            low = msg.lower()
            if ('401' in msg) or ('authentication' in low) or ('invalid' in low and 'key' in low):
                st.error("è®¤è¯å¤±è´¥ï¼šè¯·ç¡®è®¤åç«¯å·²ä¸ºå½“å‰ç¡¬ç¼–ç å¯†é’¥æˆæƒã€‚")
            else:
                st.error(f"æ“ä½œå¤±è´¥: {msg}")
            return None
    return wrapper

# === APIé”™è¯¯å¤„ç† ===
class APIError(Exception):
    """APIè°ƒç”¨ç›¸å…³é”™è¯¯çš„åŸºç±»"""
    def __init__(self, message: str, status_code: Optional[int] = None):
        super().__init__(message)
        self.status_code = status_code

class AuthenticationError(APIError):
    """è®¤è¯ç›¸å…³é”™è¯¯"""
    pass

class NetworkError(APIError):
    """ç½‘ç»œè¯·æ±‚é”™è¯¯"""
    pass

class ResponseError(APIError):
    """å“åº”è§£æé”™è¯¯"""
    pass

def handle_api_errors(func):
    """APIé”™è¯¯å¤„ç†è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except requests.exceptions.RequestException as e:
            raise NetworkError(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
        except (ValueError, json.JSONDecodeError) as e:
            raise ResponseError(f"å“åº”æ ¼å¼é”™è¯¯: {e}")
        except Exception as e:
            if isinstance(e, APIError):
                raise
            raise APIError(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
    return wrapper

# === é£ä¹¦APIè¾…åŠ©ç±» ===
class FeishuAPI:
    """é£ä¹¦APIæ“ä½œå°è£…"""
    def __init__(self, app_id: str, app_secret: str, debug: bool = False):
        self.app_id = app_id
        self.app_secret = app_secret
        self.debug = debug
    
    @handle_api_errors
    def get_user_access_token(self, code: str) -> str:
        """é€šè¿‡æˆæƒç è·å–é£ä¹¦ç”¨æˆ·è®¿é—®ä»¤ç‰Œ"""
        payload = {
            "grant_type": "authorization_code",
            "client_id": self.app_id,
            "client_secret": self.app_secret,
            "code": code
        }
        
        if self.debug:
            logger.debug(f"Requesting user token with code: {code[:10]}...")
            
        resp = requests.post(
            FeishuConfig.OAUTH_TOKEN_URL,
            json=payload,
            timeout=10
        )
        
        if self.debug:
            logger.debug(f"User token HTTP status: {resp.status_code}")
            
        if resp.status_code != 200:
            raise AuthenticationError(
                f"è·å–ç”¨æˆ·ä»¤ç‰Œå¤±è´¥: {resp.text[:300]}", 
                resp.status_code
            )
            
        data = resp.json()
        
        if self.debug:
            logger.debug(f"User token response: {json.dumps(data, ensure_ascii=False)[:400]}")
            
        if data.get("code") != 0:
            raise AuthenticationError(
                f"è·å–ç”¨æˆ·ä»¤ç‰Œå¤±è´¥: code={data.get('code')} msg={data.get('msg')}"
            )
            
        return data["data"]["access_token"]
    @handle_api_errors
    def get_tenant_access_token(self, retries: int = 3, base_delay: float = 0.8) -> str:
        """è·å–é£ä¹¦ç§Ÿæˆ·è®¿é—®ä»¤ç‰Œï¼Œæ”¯æŒæŒ‡æ•°é€€é¿é‡è¯•"""
        payload = {
            "app_id": self.app_id,
            "app_secret": self.app_secret
        }
        
        last_error: Optional[Exception] = None
        
        for attempt in range(1, retries + 1):
            if self.debug:
                logger.debug(f"Token request attempt {attempt}/{retries}")
                
            try:
                resp = requests.post(
                    FeishuConfig.TOKEN_ENDPOINT,
                    json=payload,
                    timeout=10
                )
                
                if self.debug:
                    logger.debug(f"Token response status: {resp.status_code}")
                
                if resp.status_code == 500:
                    snippet = resp.text[:300]
                    logger.warning(f"Server 500 error. Response: {snippet}")
                    last_error = APIError("æœåŠ¡å™¨å†…éƒ¨é”™è¯¯", 500)
                    
                elif resp.status_code != 200:
                    last_error = APIError(
                        f"è·å–ä»¤ç‰Œå¤±è´¥: {resp.text[:300]}", 
                        resp.status_code
                    )
                    
                else:
                    data = resp.json()
                    
                    if self.debug:
                        logger.debug(f"Token response: {json.dumps(data, ensure_ascii=False)[:400]}")
                    
                    if data.get("code") == 0:
                        return data["tenant_access_token"]
                    
                    last_error = APIError(
                        f"è·å–ä»¤ç‰Œå¤±è´¥: code={data.get('code')} msg={data.get('msg')}"
                    )
                    
            except requests.RequestException as e:
                last_error = NetworkError(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
                if self.debug:
                    logger.debug(f"Network error: {e}")
            
            # æŒ‡æ•°é€€é¿é‡è¯•
            if attempt < retries:
                delay = base_delay * (2 ** (attempt - 1))
                if self.debug:
                    logger.debug(f"Retrying in {delay:.2f}s")
                time.sleep(delay)
                
        raise last_error or APIError("è·å–ä»¤ç‰Œå¤±è´¥(æœªçŸ¥é”™è¯¯)")

    @handle_api_errors
    def api_get(self, url: str, token: str) -> Dict:
        """é€šç”¨é£ä¹¦API GETè¯·æ±‚æ–¹æ³•"""
        headers = {"Authorization": f"Bearer {token}"}
        
        if self.debug:
            logger.debug(f"GET {url}")
            
        resp = requests.get(url, headers=headers, timeout=10)
        
        if self.debug:
            logger.debug(f"Response status: {resp.status_code}")
            
        if resp.status_code != 200:
            raise APIError(
                f"è¯·æ±‚å¤±è´¥: {resp.text[:300]}", 
                resp.status_code
            )
            
        data = resp.json()
        
        if self.debug:
            logger.debug(f"Response data: {json.dumps(data, ensure_ascii=False)[:400]}")
            
        if data.get("code") not in (0, None):
            raise APIError(
                f"è¯·æ±‚å¤±è´¥: code={data.get('code')} msg={data.get('msg')}"
            )
            
        return data

    @handle_api_errors
    def fetch_document_blocks(self, doc_id: str, block_id: str, 
                            token: str, depth: int = 0, max_depth: int = 8) -> List[Dict]:
        """é€’å½’è·å–é£ä¹¦æ–‡æ¡£å—å†…å®¹
        
        Args:
            doc_id: æ–‡æ¡£ID
            block_id: å½“å‰å—ID
            token: è®¿é—®ä»¤ç‰Œ
            depth: å½“å‰é€’å½’æ·±åº¦
            max_depth: æœ€å¤§é€’å½’æ·±åº¦
            
        Returns:
            æ–‡æ¡£å—åˆ—è¡¨
        """
        # é˜²æ­¢è¿‡æ·±é€’å½’
        if depth > max_depth:
            logger.warning(f"è¾¾åˆ°æœ€å¤§é€’å½’æ·±åº¦ {max_depth}")
            return []
            
        results: List[Dict] = []
        
        # æ„å»ºAPIè¯·æ±‚URL
        url = FeishuConfig.BLOCKS_ENDPOINT_TMPL.format(
            doc_id=doc_id,
            block_id=block_id,
            page_size=200,
            page_token=""
        )
        
        # è·å–å—æ•°æ®
        data = self.api_get(url, token)
        block_data = data.get("data", {}).get("block")
        
        if not block_data:
            return results
            
        results.append(block_data)
        
        # å¤„ç†å­å—
        children = block_data.get("children", [])
        for child_id in children:
            if not child_id:
                continue
                
            try:
                child_blocks = self.fetch_document_blocks(
                    doc_id=doc_id,
                    block_id=child_id,
                    token=token,
                    depth=depth + 1,
                    max_depth=max_depth
                )
                results.extend(child_blocks)
            except Exception as e:
                logger.warning(f"è·å–å­å— {child_id} å¤±è´¥: {e}")
                
        return results

    def extract_block_text(self, block: Dict) -> str:
        """ä»æ–‡æ¡£å—ä¸­æå–æ–‡æœ¬å†…å®¹
        
        æ”¯æŒçš„å—ç±»å‹:
        - 1: é¡µé¢å—ï¼ˆæ ¹å—ï¼‰
        - 2: æ–‡æœ¬å—
        - å…¶ä»–: é€šç”¨å¤„ç†
        
        Args:
            block: æ–‡æ¡£å—æ•°æ®
            
        Returns:
            æå–çš„æ–‡æœ¬å†…å®¹
        """
        text_parts: List[str] = []
        block_type = block.get("block_type")
        
        # é¡µé¢å—å¤„ç†
        if block_type == 1:
            text_parts.extend(
                self._extract_elements_text(
                    block.get("page", {}).get("elements", [])
                )
            )
            
        # æ–‡æœ¬å—å¤„ç†
        elif block_type == 2:
            text_parts.extend(
                self._extract_elements_text(
                    block.get("text", {}).get("elements", [])
                )
            )
            
        # å…¶ä»–å—ç±»å‹é€šç”¨å¤„ç†
        else:
            block_content = block.get("block") or {}
            text_parts.extend(
                self._extract_nested_text(block_content)
            )
            
        return " ".join(text_parts).strip()
    
    def _extract_elements_text(self, elements: List[Dict]) -> List[str]:
        """ä»å…ƒç´ åˆ—è¡¨ä¸­æå–æ–‡æœ¬
        
        Args:
            elements: å…ƒç´ åˆ—è¡¨
            
        Returns:
            æ–‡æœ¬ç‰‡æ®µåˆ—è¡¨
        """
        texts: List[str] = []
        for elem in elements:
            if not isinstance(elem, dict):
                continue
                
            text_run = elem.get("text_run", {})
            content = text_run.get("content", "")
            if content:
                texts.append(
                    content.replace("\n", " ").strip()
                )
        return texts
        
    def _extract_nested_text(self, data: Dict) -> List[str]:
        """é€’å½’æå–åµŒå¥—æ•°æ®ä¸­çš„æ–‡æœ¬
        
        Args:
            data: åµŒå¥—çš„æ•°æ®ç»“æ„
            
        Returns:
            æ–‡æœ¬ç‰‡æ®µåˆ—è¡¨
        """
        texts: List[str] = []
        
        def _iter_dict(d: Dict) -> None:
            for key, value in d.items():
                if key == "text_run" and isinstance(value, dict):
                    content = value.get("content")
                    if content:
                        texts.append(
                            content.replace("\n", " ").strip()
                        )
                elif isinstance(value, dict):
                    _iter_dict(value)
                elif isinstance(value, list):
                    for item in value:
                        if isinstance(item, dict):
                            _iter_dict(item)
                            
        _iter_dict(data)
        return texts

    def blocks_to_markdown(self, blocks: List[Dict]) -> str:
        """å°†é£ä¹¦æ–‡æ¡£å—è½¬æ¢ä¸ºMarkdownæ ¼å¼
        
        Args:
            blocks: æ–‡æ¡£å—åˆ—è¡¨
            
        Returns:
            Markdownæ ¼å¼çš„æ–‡æ¡£å†…å®¹
        """
        lines: List[str] = []
        
        for block in blocks:
            # æå–æ–‡æœ¬
            text = self.extract_block_text(block)
            if not text:
                continue
                
            # æ ¹æ®å—ç±»å‹æ ¼å¼åŒ–
            block_type = str(block.get("block_type", "")).lower()
            
            # æ ‡é¢˜å—å¤„ç†
            if block_type.startswith("heading") or block_type == "3":
                level = block_type[-1] if block_type[-1].isdigit() else "2"
                lines.append(f"{'#' * int(level)} {text}")
                
            # åˆ—è¡¨å—å¤„ç†
            elif block_type in ("bullet", "ordered", "list", "4", "5", "6"):
                lines.append(f"- {text}")
                
            # æ™®é€šæ–‡æœ¬å—
            else:
                lines.append(text)
                
        # æ¸…ç†è¿ç»­ç©ºè¡Œ
        return self._clean_empty_lines(lines)
        
    def _clean_empty_lines(self, lines: List[str]) -> str:
        """æ¸…ç†æ–‡æœ¬ä¸­çš„è¿ç»­ç©ºè¡Œ
        
        Args:
            lines: æ–‡æœ¬è¡Œåˆ—è¡¨
            
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        cleaned: List[str] = []
        prev_blank = False
        
        for line in lines:
            is_blank = not line.strip()
            if is_blank and prev_blank:
                continue
            cleaned.append(line)
            prev_blank = is_blank
            
        return "\n".join(cleaned)
        
    def fetch_document(self, url_or_id: str) -> str:
        """è·å–å¹¶å¤„ç†é£ä¹¦æ–‡æ¡£å†…å®¹
        
        Args:
            url_or_id: æ–‡æ¡£URLæˆ–ID
            
        Returns:
            Markdownæ ¼å¼çš„æ–‡æ¡£å†…å®¹
        """
        try:
            # æå–æ–‡æ¡£ID
            doc_id = self._extract_document_id(url_or_id)
            if not doc_id:
                raise ValueError("æ— æ³•ä»URLæå–æ–‡æ¡£ID")
                
            # è·å–è®¿é—®ä»¤ç‰Œ
            token = self.get_tenant_access_token()
                
            # è·å–æ–‡æ¡£å—
            blocks = self.fetch_document_blocks(
                doc_id=doc_id,
                block_id=doc_id,
                token=token,
                depth=0,
                max_depth=6
            )
                
            if self.debug:
                logger.debug(f"è·å–åˆ° {len(blocks)} ä¸ªæ–‡æ¡£å—")
                if blocks:
                    logger.debug(
                        f"ç¬¬ä¸€ä¸ªå—ç¤ºä¾‹: {json.dumps(blocks[0], ensure_ascii=False)[:200]}..."
                    )
                
            # è½¬æ¢ä¸ºMarkdown
            markdown = self.blocks_to_markdown(blocks)
                
            if self.debug:
                logger.debug(f"ç”ŸæˆMarkdowné•¿åº¦: {len(markdown)}")
                logger.debug(f"Markdowné¢„è§ˆ: {markdown[:200]}...")
                
            return markdown
            
        except Exception as e:
            logger.exception("å¤„ç†é£ä¹¦æ–‡æ¡£å¤±è´¥")
            return f"ã€é£ä¹¦APIé”™è¯¯ã€‘{str(e)}"
            
    def _extract_document_id(self, url_or_id: str) -> Optional[str]:
        """ä»URLæˆ–IDå­—ç¬¦ä¸²ä¸­æå–æ–‡æ¡£ID
        
        Args:
            url_or_id: URLæˆ–IDå­—ç¬¦ä¸²
            
        Returns:
            æ–‡æ¡£IDï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
        """
        doc_input = url_or_id.strip()
        match = re.search(r"/(?:docx|wiki|docs)/([A-Za-z0-9]+)", doc_input)
        
        if match:
            return match.group(1)
            
        # å¦‚æœä¸æ˜¯URLæ ¼å¼ï¼Œå‡å®šæ•´ä¸ªè¾“å…¥å°±æ˜¯ID
        if re.match(r"^[A-Za-z0-9]+$", doc_input):
            return doc_input
            
        return None

from feishu_client import FeishuClient
from url_utils import UrlFetcher

def create_feishu_client() -> FeishuClient:
    """åˆ›å»ºé£ä¹¦å®¢æˆ·ç«¯å®ä¾‹"""
    app_id = st.session_state.get("feishu_app_id", "cli_a85ffa34d3fad00c")
    app_secret = st.session_state.get("feishu_app_secret", "MxD6ukGa9ZMJeGl5KicVSgNQLhnE1tcN")
    debug = st.session_state.get("debug_mode", False)
    return FeishuClient(app_id, app_secret, debug)

def fetch_background_content(url: str, timeout: int = 10, max_chars: int = 12000) -> str:
    """è·å–èƒŒæ™¯æ–‡æ¡£å†…å®¹
    
    æ”¯æŒ:
    - é£ä¹¦æ–‡æ¡£ (APIè®¿é—®)
    - æ™®é€šç½‘é¡µ (HTMLæ¸…ç†)
    
    Args:
        url: æ–‡æ¡£URL
        timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´
        max_chars: æœ€å¤§å­—ç¬¦æ•°
    
    Returns:
        æ–‡æ¡£å†…å®¹
    """
    try:
        # å¤„ç†é£ä¹¦æ–‡æ¡£
        if 'feishu.cn' in url or 'larksuite' in url:
            if re.search(r"/(?:docx|wiki|docs)/[A-Za-z0-9]+", url):
                try:
                    client = create_feishu_client()
                    content = client.fetch_document(url)
                    if content and not content.startswith("ã€é£ä¹¦APIé”™è¯¯ã€‘"):
                        if len(content) > max_chars:
                            content = content[:max_chars] + "...ã€æˆªæ–­ã€‘"
                        return content
                except Exception as e:
                    if st.session_state.get("debug_mode"):
                        logger.debug(f"é£ä¹¦APIå¤±è´¥ï¼Œå›é€€ç½‘é¡µæŠ“å–: {e}")
                    st.warning(f"é£ä¹¦APIè®¿é—®å¤±è´¥: {str(e)}ï¼Œå°è¯•ç½‘é¡µæŠ“å–")
                    
        # æ™®é€šç½‘é¡µå¤„ç†
        fetcher = UrlFetcher()
        return fetcher.fetch_content(url, timeout, max_chars)
        
    except Exception as e:
        logger.exception("è·å–èƒŒæ™¯å†…å®¹å¤±è´¥")
        return f"ã€å¼‚å¸¸: {e.__class__.__name__}ã€‘{url}"

@handle_errors
def read_word(file) -> str:
    doc = Document(file)
    paras = [p.text.strip() for p in doc.paragraphs if p.text and p.text.strip()]
    content = "\n".join(paras)
    if not content.strip():
        raise ValueError("Word æ–‡æ¡£ä¸ºç©º")
    return content

@handle_errors
def read_excel(uploaded_file) -> Dict[str, pd.DataFrame]:
    xl = pd.ExcelFile(uploaded_file)
    sheets = {}
    for sheet in xl.sheet_names:
        df = xl.parse(sheet)
        if df.empty:
            continue
        sheets[sheet] = df
    if not sheets:
        raise ValueError("Excel æ²¡æœ‰æœ‰æ•ˆå·¥ä½œè¡¨")
    return sheets

def build_prompt(requirement: str, headers: List[str], pos_n: int, neg_n: int, edge_n: int, req_id: str = "", background_knowledge: Optional[str] = None) -> str:
    if not requirement.strip():
        raise ValueError("éœ€æ±‚ä¸èƒ½ä¸ºç©º")
    cols_line = ",".join(headers)
    total_cases = pos_n + neg_n + edge_n
    background_section = ""
    if background_knowledge and background_knowledge.strip():
        background_section = f"""
è¯·å‚è€ƒä»¥ä¸‹èƒŒæ™¯çŸ¥è¯†æ¥ç”Ÿæˆç”¨ä¾‹ï¼š
---
{background_knowledge.strip()}
---
"""
    guidance = f"""
{background_section}
ä½ æ˜¯ä¸€åå…·å¤‡ç”µåŠ›ç”µå­ä¸è½¦è½½ç³»ç»Ÿç»éªŒçš„é«˜çº§æµ‹è¯•å·¥ç¨‹å¸ˆï¼Œç†Ÿæ‚‰ OBC/CCU/BMS/EVCCã€CAN/CAN-FDã€å……ç”µæµç¨‹ä¸åŠŸç‡çº¦æŸã€‚
è¯·åŸºäºä¸‹åˆ—éœ€æ±‚ç”Ÿæˆ {total_cases} æ¡é«˜è´¨é‡ã€å¯æ‰§è¡Œçš„æµ‹è¯•ç”¨ä¾‹ï¼ˆCSV æ ¼å¼ï¼Œç¬¬ä¸€è¡Œä¸ºè¡¨å¤´ï¼‰ï¼š
{cols_line}

åˆ†é…ï¼šæ­£å‘ {pos_n} æ¡ï¼Œå¼‚å¸¸ {neg_n} æ¡ï¼Œè¾¹ç•Œ {edge_n} æ¡ã€‚

è§„åˆ™ï¼š
- ä»…è¾“å‡º CSV å†…å®¹ï¼Œä¸è¦é™„åŠ è§£é‡Šæˆ–ä»£ç å—ã€‚
- æµ‹è¯•æ­¥éª¤ç”¨åˆ†å·ï¼ˆï¼›ï¼‰åˆ†éš”å¹¶æ”¾åœ¨åŒä¸€å•å…ƒæ ¼å†…ã€‚
- å‰ç½®æ¡ä»¶ä¸ºç©ºå¡«å†™ "æ— "ã€‚
- è¾“å…¥æ•°æ®è¦å…·ä½“ï¼ˆä¾‹å¦‚ï¼šVIN=1234, CAN_ID=0x18FF50E5, ç”µå‹=400V, ç”µæµ=50Aï¼‰ã€‚
- é¢„æœŸç»“æœåº”åŒ…å«å¯è§‚æµ‹çš„é˜ˆå€¼æˆ–æ—¶é—´æ¡ä»¶ï¼ˆä¾‹å¦‚ï¼šç”µæµç¨³å®šåœ¨ 50A Â±5% æŒç»­ 10sï¼‰ã€‚
- éœ€æ±‚ç¼–å·åˆ—å¡«å†™: {req_id if req_id else "REQ-001"}
- éœ€æ±‚æè¿°åˆ—ç®€è¦æ¦‚æ‹¬éœ€æ±‚å†…å®¹ï¼ˆä¸è¶…è¿‡50å­—ï¼‰
- éœ€æ±‚è¿½æº¯åˆ—å¡«å†™è¯¥æµ‹è¯•ç”¨ä¾‹éªŒè¯çš„å…·ä½“éœ€æ±‚ç‚¹

ç”µåŠ›ç”µå­æ³¨æ„äº‹é¡¹ï¼šæ˜ç¡®é‡‡æ ·æ—¶åºã€SOC/æ¸©åº¦/ç”µåŠ›è¾¹ç•Œã€æ•…éšœæ³¨å…¥ï¼ˆä¸¢å¸§/å»¶è¿Ÿ/çŸ­è·¯ï¼‰ã€EVCCé€šä¿¡åè®®å’Œå®‰å…¨äº’é”ã€‚
"""
    return f"{guidance}\n\néœ€æ±‚ID: {req_id}\néœ€æ±‚æè¿°:\n{requirement.strip()}\n\nè¯·å¼€å§‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼š"

def get_standard_prompt_template() -> str:
    """è¿”å›åœ¨ç”Ÿæˆç”¨ä¾‹æ—¶ä½¿ç”¨çš„æ ‡å‡† Prompt æ¨¡æ¿ï¼ˆå ä½ç¬¦å½¢å¼å±•ç¤ºï¼‰ã€‚"""
    return (
        "[ç³»ç»Ÿè§’è‰²]\n"
        "ä½ æ˜¯èµ„æ·±çš„OBC/CCUæµ‹è¯•å¼€å‘ä¸“å®¶ï¼Œç²¾é€šç”µåŠ›ç”µå­ã€è½¦è½½å……ç”µã€CAN/CAN-FDåè®®ã€ç¡¬ä»¶äº¤äº’ã€è¯Šæ–­ä¸å®‰å…¨ã€‚\n\n"
        "[å¯é€‰èƒŒæ™¯çŸ¥è¯†]\n"
        "å¦‚æœ‰èƒŒæ™¯çŸ¥è¯†ï¼Œè¯·å……åˆ†ç»“åˆç†è§£ã€‚\n---\n{èƒŒæ™¯çŸ¥è¯†}\n---\n\n"
        "[ä»»åŠ¡]\n"
        "é’ˆå¯¹â€˜éœ€æ±‚æè¿°â€™ï¼Œç”Ÿæˆ {æ­£å‘æ•°} æ¡æ­£å‘ã€{å¼‚å¸¸æ•°} æ¡å¼‚å¸¸ã€{è¾¹ç•Œæ•°} æ¡è¾¹ç•Œæµ‹è¯•ç”¨ä¾‹ï¼ˆå…± {æ€»ç”¨ä¾‹æ•°} æ¡ï¼‰ï¼Œè¦æ±‚å¦‚ä¸‹ï¼š\n\n"
        "[CSV åˆ—é¡ºåº]\n{åˆ—åé€—å·åˆ†éš”}\n\n"
        "[ç”Ÿæˆè§„åˆ™]\n"
        "1. ä»…è¾“å‡ºåŸå§‹ CSV å†…å®¹ï¼Œä¸è¾“å‡ºä»»ä½•è§£é‡Šã€ä»£ç å—æˆ–å¤šä½™æ–‡æœ¬ã€‚\n"
        "2. æµ‹è¯•æ­¥éª¤åº”ç»†è‡´ã€å¯å¤ç°ï¼Œå•å…ƒæ ¼å†…ç”¨å…¨è§’åˆ†å·ï¼ˆï¼›ï¼‰åˆ†éš”ã€‚\n"
        "3. å‰ç½®æ¡ä»¶ä¸ºç©ºå¡«â€˜æ— â€™ï¼Œå¦‚éœ€ç‰¹å®šç¡¬ä»¶/çº¿æŸ/ç¯å¢ƒè¯·æ˜ç¡®ã€‚\n"
        "4. è¾“å…¥/å‚æ•°éœ€å…·ä½“å¯æ‰§è¡Œï¼ˆå¦‚VIN=1234, CAN_ID=0x18FF50E5, ç”µå‹=400V, ç”µæµ=50Aï¼‰ï¼Œæ¶‰åŠä¿¡å·/æŠ¥æ–‡/ç‰©ç†æ“ä½œè¦å†™æ˜ã€‚\n"
        "5. é¢„æœŸç»“æœåº”åŒ…å«å¯è§‚æµ‹é˜ˆå€¼ã€æ—¶åºã€è¯Šæ–­ç ã€åŠŸç‡/å®‰å…¨/äº’é”ç­‰åˆ¤æ®ï¼ˆå¦‚ï¼šç”µæµç¨³å®šåœ¨50AÂ±5%æŒç»­10sï¼Œæˆ–ä¸‹å‘BMSæ•…éšœç 0x1234ï¼‰ã€‚\n"
        "6. â€˜éœ€æ±‚ç¼–å·â€™åˆ—å¡«{éœ€æ±‚ç¼–å·}ï¼ˆæˆ–è‡ªåŠ¨ç”ŸæˆREQ-001/002â€¦ï¼‰ã€‚\n"
        "7. â€˜éœ€æ±‚æè¿°â€™åˆ—â‰¤50å­—ï¼Œç²¾å‡†æ¦‚æ‹¬éœ€æ±‚å…³é”®ç‚¹ã€‚\n"
        "8. â€˜éœ€æ±‚è¿½æº¯â€™åˆ—å†™æ˜è¯¥ç”¨ä¾‹éªŒè¯çš„å…·ä½“éœ€æ±‚ç‚¹ã€åè®®æ¡æ¬¾æˆ–åœºæ™¯ã€‚\n"
        "9. ç”¨ä¾‹åº”è¦†ç›–å…¸å‹æµç¨‹ã€å¼‚å¸¸åœºæ™¯ï¼ˆå¦‚é€šä¿¡ä¸¢å¸§/è¶…æ—¶/éæ³•æŠ¥æ–‡/ç¡¬ä»¶æ–­å¼€ï¼‰ã€è¾¹ç•Œæ¡ä»¶ï¼ˆå¦‚æé™ç”µå‹/æ¸©åº¦/åŠŸç‡/æ—¶åºï¼‰ã€‚\n"
        "10. OBC/CCUå…³æ³¨ï¼š\n"
        "    - å……ç”µæµç¨‹ï¼ˆæ’æªã€æˆæƒã€å¯åŠ¨ã€å®Œæˆã€æ‹”æªã€å¼‚å¸¸ä¸­æ–­ï¼‰\n"
        "    - CAN/CAN-FDæŠ¥æ–‡äº¤äº’ã€ä¿¡å·é‡‡é›†ã€è¯Šæ–­å¸§\n"
        "    - åŠŸç‡/æ¸©åº¦/ç”µæµ/ç”µå‹è¾¹ç•Œã€SOCé˜ˆå€¼\n"
        "    - æ•…éšœæ³¨å…¥ï¼ˆä¸¢å¸§ã€å»¶è¿Ÿã€çŸ­è·¯ã€ä¿¡å·å¼‚å¸¸ï¼‰\n"
        "    - å®‰å…¨äº’é”ã€ç¡¬ä»¶çŠ¶æ€æ£€æµ‹ã€è¯Šæ–­ç ä¸ŠæŠ¥\n"
        "    - æ—¶åºè¦æ±‚ï¼ˆå¦‚xx mså†…å“åº”/åŠ¨ä½œï¼‰\n"
        "    - ç‰©ç†æ“ä½œä¸äººæœºäº¤äº’ï¼ˆå¦‚æ’æ‹”æªã€æ€¥åœã€æˆæƒæµç¨‹ï¼‰\n\n"
        "[éœ€æ±‚è¾“å…¥]\n"
        "éœ€æ±‚ID: {éœ€æ±‚ç¼–å·}\n"
        "éœ€æ±‚æè¿°:\n{éœ€æ±‚å…¨æ–‡}\n\n"
        "[è¾“å‡º]\nä»…è¾“å‡º CSVï¼Œæ— å…¶ä»–æ–‡å­—ã€‚"
    )

def get_output_format_template(headers: List[str] = None) -> str:
    """è¿”å›æ ‡å‡†çš„è¾“å‡ºæ ¼å¼æ¨¡æ¿ï¼ˆCSVæ ¼å¼ï¼Œç¬¬ä¸€è¡Œä¸ºè¡¨å¤´ï¼Œç¬¬äºŒè¡Œä¸ºå ä½ç¬¦ç¤ºä¾‹ï¼‰ã€‚"""
    if headers is None:
        headers = DEFAULT_HEADERS
    header_line = ",".join(f'"{h}"' for h in headers)
    example_line = ",".join(f'"{h}ç¤ºä¾‹"' for h in headers)
    return f"{header_line}\n{example_line}"

REQ_ID_PATTERN = re.compile(r"\b(REQ-[A-Za-z0-9]+-\d{2,4})\b")

def extract_req_id(text: str) -> Optional[str]:
    """å°è¯•ä»éœ€æ±‚æ–‡æœ¬ä¸­æŠ½å–éœ€æ±‚ç¼–å· (æ ¼å¼ç¤ºä¾‹: REQ-OBC-001)ã€‚

    è‹¥æ‰¾åˆ°å¤šä¸ª, è¿”å›ç¬¬ä¸€ä¸ªã€‚è¿”å›ç»Ÿä¸€å¤§å†™ã€‚æœªæ‰¾åˆ°è¿”å› Noneã€‚
    """
    if not text:
        return None
    match = REQ_ID_PATTERN.search(text.upper())
    if match:
        return match.group(1).upper().rstrip(':')
    return None

# ===== åŠ¨æ€ç”¨ä¾‹æ•°é‡åˆ†é… =====
KEYWORD_WEIGHTS = {
    "å¼‚å¸¸": 1.0,
    "é”™è¯¯": 1.0,
    "æ•…éšœ": 1.1,
    "è¶…æ—¶": 0.9,
    "è¾¹ç•Œ": 0.8,
    "é™åˆ¶": 0.6,
    "ä¿æŠ¤": 0.7,
    "é™çº§": 0.9,
    "é‡è¯•": 0.8,
    "å®‰å…¨": 0.7,
    "åŠ å¯†": 0.6,
}

def _complexity_score(text: str) -> float:
    if not text:
        return 0.0
    t = text.strip()
    length = len(t)
    sentences = len(re.findall(r"[ã€‚.!?]", t)) or 1
    kw_score = 0.0
    for k, w in KEYWORD_WEIGHTS.items():
        cnt = t.count(k)
        if cnt:
            kw_score += cnt * w
    # å½’ä¸€åŒ–: è®¾è®¡ç»éªŒå‚æ•°
    base = (length / 300.0) + (sentences / 6.0) + (kw_score / 4.0)
    return min(base / 3.0, 1.0)  # é™åˆ¶ 0~1

def compute_dynamic_case_counts(text: str, min_total: int, max_total: int, pos_w: float, neg_w: float, edge_w: float) -> Tuple[int, int, int]:
    score = _complexity_score(text)
    total = int(round(min_total + (max_total - min_total) * score))
    total = max(min_total, min(total, max_total))
    weights = [max(pos_w, 0.01), max(neg_w, 0.01), max(edge_w, 0.01)]
    w_sum = sum(weights)
    raw_counts = [w / w_sum * total for w in weights]
    # åˆæ­¥å››èˆäº”å…¥
    counts = [max(1, int(round(c))) for c in raw_counts]
    # è°ƒæ•´ä½¿å¾—å’Œ=total
    diff = sum(counts) - total
    if diff != 0:
        # æ ¹æ®è¯¯å·®å¤§å°è°ƒæ•´, ä¼˜å…ˆè°ƒæ•´æœ€å¤§æˆ–æœ€å°çš„åˆ†ç±»
        for _ in range(abs(diff)):
            if diff > 0:
                # éœ€è¦å‡
                idx = counts.index(max(counts))
                if counts[idx] > 1:
                    counts[idx] -= 1
            else:
                # éœ€è¦åŠ 
                idx = counts.index(min(counts))
                counts[idx] += 1
    return counts[0], counts[1], counts[2]

# ===== å•æ¡éœ€æ±‚ -> å¤šåˆ†æ”¯è§£æ =====
BRANCH_BULLET_PATTERN = re.compile(r"^\s*(?:- |\* |\d+[).ã€]\s*|[ï¼ˆ(]\d+[)ï¼‰]\s*)")

def split_requirement_into_branches(text: str, max_branches: int = 15) -> List[Dict[str, str]]:
    """å°†å•æ¡åŸå§‹éœ€æ±‚æ‹†åˆ†ä¸ºå¤šä¸ªå¯æµ‹è¯•çš„ã€åˆ†æ”¯å­éœ€æ±‚ã€ã€‚

    è§£æç­–ç•¥ (å¯å‘å¼):
    1. ä¼˜å…ˆæŒ‰æ¢è¡Œä¸­çš„é¡¹ç›®ç¬¦å·/ç¼–å·æ‹†åˆ† (æ•°å­—. / ï¼ˆæ•°å­—ï¼‰ / - / * )
    2. è‹¥æœªæ£€æµ‹åˆ°æ˜æ˜¾æ¡ç›®, å°è¯•æŒ‰å¥å·/åˆ†å·åˆ‡æˆå¥å­ (é•¿åº¦>15) ä½œä¸ºå€™é€‰
    3. å¯¹è¿‡çŸ­ (<8) è¡Œè‡ªåŠ¨ä¸åç»­åˆå¹¶
    4. é™åˆ¶æœ€å¤§åˆ†æ”¯æ•°, è¶…è¿‡æ—¶æˆªæ–­å¹¶åœ¨æœ€åè¿½åŠ ä¸€æ¡ã€å…¶ä½™åˆå¹¶ã€
    è¿”å›: [{'branch_index':1,'branch_id':'B01','title':'...','content':'...'}]
    """
    if not text or len(text.strip()) < 8:
        return []
    raw_lines = [l.rstrip() for l in text.strip().splitlines() if l.strip()]
    candidates: List[str] = []
    buffer = []
    def flush_buffer():
        if buffer:
            merged = " ".join(buffer).strip()
            if merged:
                candidates.append(merged)
            buffer.clear()

    bullet_mode = any(BRANCH_BULLET_PATTERN.search(l) for l in raw_lines)
    if bullet_mode:
        for line in raw_lines:
            if BRANCH_BULLET_PATTERN.search(line):
                flush_buffer()
                # å»æ‰å‰ç¼€ç¬¦å·
                cleaned = BRANCH_BULLET_PATTERN.sub("", line, count=1).strip()
                buffer.append(cleaned)
            else:
                # ç»§ç»­ç´¯ç§¯åˆ°å½“å‰åˆ†æ”¯
                buffer.append(line.strip())
        flush_buffer()
    else:
        # å¥å­åˆ‡åˆ† (ä¸­æ–‡å¥å·/åˆ†å·/è‹±æ–‡æ ‡ç‚¹)
        sentences = re.split(r"(?<=[ã€‚ï¼›;.!?])\s+", text.strip())
        for s in sentences:
            s_clean = s.strip()
            if len(s_clean) >= 15:
                candidates.append(s_clean)
        # å¦‚æœè¿˜æ²¡æœ‰, æ•´ä½“ä½œä¸ºä¸€ä¸ª
        if not candidates:
            candidates = [text.strip()]

    # åˆå¹¶è¿‡çŸ­ç‰‡æ®µ (<8) åˆ°å‰ä¸€ä¸ª
    merged: List[str] = []
    for seg in candidates:
        if merged and len(seg) < 8:
            merged[-1] = merged[-1] + " " + seg
        else:
            merged.append(seg)

    # æˆªæ–­ä¸æº¢å‡ºå¤„ç†
    overflow = []
    if len(merged) > max_branches:
        overflow = merged[max_branches-1:]
        merged = merged[:max_branches-1]
        merged.append("å…¶ä½™åˆå¹¶: " + " | ".join(overflow[:5]) + (" ..." if len(overflow) > 5 else ""))

    branches: List[Dict[str, str]] = []
    for idx, seg in enumerate(merged, 1):
        title = seg[:40].replace('\n', ' ').strip()
        branches.append({
            "branch_index": idx,
            "branch_id": f"B{idx:02d}",
            "title": title,
            "content": seg.strip(),
        })
    return branches

def get_requirement_templates() -> Dict[str, str]:
    return {
        "OBC å……ç”µæµç¨‹": """
REQ-OBC-001: ã€åŠŸèƒ½ã€‘è½¦è½½å……ç”µæœº (OBC)ï¼šæ’æªæ¡æ‰‹->æˆæƒ->å……ç”µ->åœæ­¢
åœºæ™¯åŒ…æ‹¬ï¼šæ¥åœ°æ£€æµ‹ã€äº’é”ã€é™æµã€å……ç”µå®Œæˆæ£€æµ‹ä¸æ•…éšœå¤„ç†
éªŒè¯ç‚¹ï¼šæ¡æ‰‹æ—¶åºã€æˆæƒæµç¨‹ã€å……ç”µå‚æ•°åå•†ã€å¼‚å¸¸æ–­å¼€å¤„ç†
""",
        "CCU ä¸ BMS äº¤äº’": """
REQ-CCU-001: ã€åŠŸèƒ½ã€‘CCU è¯·æ±‚ BMS çŠ¶æ€ï¼ˆSOC/æ¸©åº¦/ç”µå‹/æ•…éšœç ï¼‰ï¼Œå¤„ç†è¶…æ—¶ä¸é‡è¯•
éªŒè¯ç‚¹ï¼šCANé€šä¿¡æ—¶åºã€æ•°æ®å®Œæ•´æ€§ã€è¶…æ—¶é‡è¯•æœºåˆ¶ã€æ•…éšœç è§£æ
""",
        "BMS SOC ä¸å……æ”¾ç”µç­–ç•¥": """
REQ-BMS-001: ã€åŠŸèƒ½ã€‘SOC ä¼°ç®—ã€æ¸©åº¦ç›¸å…³å……æ”¾ç”µé™åˆ¶ã€ä½ç”µé‡ä¿æŠ¤
éªŒè¯ç‚¹ï¼šSOCç²¾åº¦ã€æ¸©åº¦ä¿æŠ¤é˜ˆå€¼ã€åŠŸç‡é™åˆ¶ç®—æ³•ã€ä¿æŠ¤ç­–ç•¥è§¦å‘
""",
        "EVCC é€šä¿¡æ§åˆ¶": """
REQ-EVCC-001: ã€åŠŸèƒ½ã€‘EVCCä¸å……ç”µæ¡©é€šä¿¡ï¼šISO15118åè®®ã€æ•°å­—è¯ä¹¦éªŒè¯ã€å……ç”µå‚æ•°åå•†
éªŒè¯ç‚¹ï¼šåè®®æ¡æ‰‹ã€è¯ä¹¦é“¾éªŒè¯ã€å‚æ•°åå•†ã€é€šä¿¡å®‰å…¨æ€§
""",
        "å……ç”µè¿æ¥ä¸æ–­å¼€æµç¨‹": """
REQ-CHG-001: ã€åŠŸèƒ½ã€‘äººæœºä¸ç¡¬ä»¶äº¤äº’ï¼šæ’æªã€æˆæƒã€å¼€å§‹ã€å®Œæˆã€æ‹”æªä¸å¼ºåˆ¶ä¸­æ–­åœºæ™¯
éªŒè¯ç‚¹ï¼šç‰©ç†è¿æ¥æ£€æµ‹ã€ç”¨æˆ·æˆæƒã€å……ç”µå¯åœã€ç´§æ€¥æ–­å¼€
""",
    }

def get_requirement_examples() -> List[str]:
    return [
        "OBC: æ’æªå 5s å†…æœªæˆæƒåº”å–æ¶ˆè¯·æ±‚",
        "BMS: æ¸©åº¦>60Â°C æ—¶é™åˆ¶å……ç”µç”µæµè‡³ 0.2C",
        "CCU: BMS è¯·æ±‚è¶…æ—¶ 100ms åé‡è¯• 3 æ¬¡å¹¶è®°å½•æ•…éšœ",
    ]

@handle_errors
def call_model(model: str, prompt: str, base_url: str, temperature: float = 0.2) -> str:
    """è°ƒç”¨æ¨¡å‹: ä¼˜å…ˆ chat.completions, éœ€è¦æ—¶å›é€€ completions.

    å›é€€æ¡ä»¶: fallback é›†åˆæ¨¡å‹å‡ºç° 400 ä¸”è¿”å›å†…å®¹åŒ…å« prompt/field required/missing.
    """
    provider = MODEL_PROVIDER_HEADER.get(model, ROUTE_HEADER_VALUE)
    debug = st.session_state.get("debug_mode", False)
    actual_model = MODEL_MAP.get(model, model)

    def _chat_payload() -> dict:
        return {
            "model": actual_model,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯æµ‹è¯•ç”¨ä¾‹ç”ŸæˆåŠ©æ‰‹ï¼Œä¸¥æ ¼è¾“å‡º CSV"},
                {"role": "user", "content": prompt},
            ],
            "temperature": temperature,
            "max_tokens": 2000,
        }

    def _completions_payload() -> dict:
        return {
            "model": actual_model,
            "prompt": "ä½ æ˜¯æµ‹è¯•ç”¨ä¾‹ç”ŸæˆåŠ©æ‰‹ï¼Œä¸¥æ ¼è¾“å‡º CSVã€‚\n" + prompt,
            "temperature": temperature,
            "max_tokens": 2000,
        }

    def _do_request(url: str, payload: dict) -> requests.Response:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {API_KEY}",
            "X-Model-Provider-Id": provider,
        }
        return requests.post(url, headers=headers, json=payload, timeout=60)

    chat_url = f"{base_url.rstrip('/')}/v1/chat/completions"
    comp_url = f"{base_url.rstrip('/')}/v1/completions"
    fallback_allowed = {"Qwen-235B-A22B", "deepseek-v3.1", "Qwen2.5-VL-72B-Instruct-AWQ"}

    # Chat è°ƒç”¨
    for attempt in range(MAX_RETRY_ATTEMPTS):
        try:
            resp = _do_request(chat_url, _chat_payload())
            if resp.status_code >= 500:
                if debug:
                    st.warning(f"[è°ƒè¯•-chat] {attempt+1} æ¬¡ -> {resp.status_code}: {resp.text[:200]}")
                if attempt < MAX_RETRY_ATTEMPTS - 1:
                    time.sleep(1.2 * (attempt + 1))
                    continue
            if resp.status_code == 400:
                low = resp.text.lower()
                if model in fallback_allowed and any(k in low for k in ["prompt", "field required", "missing"]):
                    if debug:
                        st.info("[è°ƒè¯•] Chat 400 ç¼ºå­—æ®µ, å›é€€ completions")
                    break
            resp.raise_for_status()
            data = resp.json()
            return data["choices"][0]["message"]["content"]
        except requests.exceptions.HTTPError as e:
            code = e.response.status_code if e.response else None
            if code in (502, 503, 504, 429) and attempt < MAX_RETRY_ATTEMPTS - 1:
                time.sleep(1.2 * (attempt + 1))
                continue
            if code == 400:
                if model not in fallback_allowed:
                    raise e
                break
            raise e
        except (requests.exceptions.RequestException, KeyError, IndexError) as e:
            if attempt == MAX_RETRY_ATTEMPTS - 1:
                raise e
            if debug:
                st.warning(f"[è°ƒè¯•-chat] å¼‚å¸¸é‡è¯• {attempt+1}: {e}")
            time.sleep(1.0 * (attempt + 1))
    else:
        if model not in fallback_allowed:
            raise Exception("chat.completions é‡è¯•è€—å°½")

    # å›é€€ completions
    if model in fallback_allowed:
        if debug:
            st.info(f"[è°ƒè¯•] å›é€€ completions è°ƒç”¨ {model}")
        for attempt in range(MAX_RETRY_ATTEMPTS):
            try:
                resp = _do_request(comp_url, _completions_payload())
                if resp.status_code >= 500:
                    if debug:
                        st.warning(f"[è°ƒè¯•-comp] {attempt+1} æ¬¡ -> {resp.status_code}: {resp.text[:200]}")
                    if attempt < MAX_RETRY_ATTEMPTS - 1:
                        time.sleep(1.2 * (attempt + 1))
                        continue
                resp.raise_for_status()
                data = resp.json()
                if "choices" in data and data["choices"]:
                    c0 = data["choices"][0]
                    if isinstance(c0, dict):
                        if "message" in c0 and "content" in c0["message"]:
                            return c0["message"]["content"]
                        if "text" in c0:
                            return c0["text"]
                return json.dumps(data, ensure_ascii=False)[:4000]
            except requests.exceptions.HTTPError as e:
                code = e.response.status_code if e.response else None
                if code in (502, 503, 504, 429) and attempt < MAX_RETRY_ATTEMPTS - 1:
                    time.sleep(1.2 * (attempt + 1))
                    continue
                raise e
            except (requests.exceptions.RequestException, KeyError, IndexError) as e:
                if attempt == MAX_RETRY_ATTEMPTS - 1:
                    raise e
                if debug:
                    st.warning(f"[è°ƒè¯•-comp] å¼‚å¸¸é‡è¯• {attempt+1}: {e}")
                time.sleep(1.0 * (attempt + 1))
        raise Exception("completions å›é€€ä¹Ÿå¤±è´¥")

    raise Exception("æ¨¡å‹è°ƒç”¨å¤±è´¥ (æœªå‘½ä¸­æˆåŠŸè·¯å¾„)")

@handle_errors
def parse_csv_to_df(csv_text: str, expected_headers: List[str]) -> pd.DataFrame:
    if not csv_text or not csv_text.strip(): raise ValueError("CSV å†…å®¹ä¸ºç©º")
    cleaned = csv_text.strip()
    cleaned = re.sub(r"^```.*?\n", "", cleaned, flags=re.MULTILINE)
    cleaned = re.sub(r"\n```$", "", cleaned)
    cleaned = cleaned.replace("\ufeff", "")
    lines = [l for l in cleaned.splitlines() if l.strip()]
    if not lines: raise ValueError("CSV å†…å®¹ä¸ºç©ºï¼ˆæ¸…ç†åï¼‰")
    text = "\n".join(lines)
    try:
        sniffer = csv.Sniffer(); dialect = sniffer.sniff(text[:4096], delimiters=",;\t|")
        delimiter = dialect.delimiter
    except Exception:
        delimiter = ','
    reader = csv.reader(StringIO(text), delimiter=delimiter, quotechar='"')
    rows = [r for r in reader if any(cell.strip() for cell in r)]
    if not rows: raise ValueError("CSV å†…å®¹æ— æ³•è§£æä¸ºè¡Œ")
    def _normalize_rows(rows_list, n_cols, delim):
        normalized = []
        for r in rows_list:
            r = [c.strip().strip('"') for c in r]
            if len(r) <= n_cols: normalized.append(r + [""] * (n_cols - len(r)))
            else:
                merged_last = delim.join(r[n_cols - 1:]); normalized.append(r[:n_cols - 1] + [merged_last])
        return normalized
    header = [c.strip().strip('"') for c in rows[0]]
    matches = sum(1 for h in header if any(exp in h or h in exp for exp in expected_headers))
    if matches >= max(1, len(expected_headers)//2):
        data_rows = rows[1:]
        if not all(len(r)==len(header) for r in data_rows): data_rows = _normalize_rows(data_rows, len(header), delimiter)
        df = pd.DataFrame(data_rows, columns=header)
    else:
        if all(len(r)==len(expected_headers) for r in rows):
            df = pd.DataFrame(rows, columns=expected_headers)
        else:
            normalized = _normalize_rows(rows, len(expected_headers), delimiter)
            df = pd.DataFrame(normalized, columns=expected_headers)
    return df.fillna("").astype(str)

def make_excel_download(df: pd.DataFrame, filename: str = "æµ‹è¯•ç”¨ä¾‹.xlsx") -> None:
    if df is None or (hasattr(df, "empty") and df.empty): st.warning("æ²¡æœ‰æ•°æ®å¯å¯¼å‡º"); return
    buf = BytesIO();
    with pd.ExcelWriter(buf, engine='openpyxl') as w: df.to_excel(w, index=False, sheet_name='æµ‹è¯•ç”¨ä¾‹')
    buf.seek(0)
    st.download_button("ğŸ’¾ ä¸‹è½½ Excel", data=buf, file_name=filename, mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", key=f"dxl_{uuid.uuid4().hex}")

def make_csv_download(df: pd.DataFrame, filename: str = "æµ‹è¯•ç”¨ä¾‹.csv") -> None:
    if df is None or (hasattr(df, "empty") and df.empty): st.warning("æ²¡æœ‰æ•°æ®å¯å¯¼å‡º"); return
    csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ğŸ’¾ ä¸‹è½½ CSV", data=csv_bytes, file_name=filename, mime="text/csv", key=f"dcsv_{uuid.uuid4().hex}")

def process_batch_requirements(base_url: str, requirements: List[str], headers: List[str], model: str, pos_n: int, neg_n: int, edge_n: int, temperature: float, background_knowledge: Optional[str] = None, *, dynamic: bool = False, dyn_params: Optional[Dict[str, Any]] = None) -> pd.DataFrame:
    all_cases = []
    pb = st.progress(0)
    status = st.empty()
    total = len(requirements)
    used_ids = set()
    for i, req in enumerate(requirements):
        pb.progress((i + 1) / total)
        status.text(f"å¤„ç†ä¸­ {i+1}/{total}")
        extracted = extract_req_id(req)
        if extracted:
            req_id = extracted
            if req_id in used_ids:  # ç®€å•é‡å¤å¤„ç†
                suffix = 2
                new_id = f"{req_id}-DUP{suffix}"
                while new_id in used_ids:
                    suffix += 1
                    new_id = f"{req_id}-DUP{suffix}"
                req_id = new_id
        else:
            req_id = f"REQ-{i+1:03d}"
        used_ids.add(req_id)
        local_pos, local_neg, local_edge = pos_n, neg_n, edge_n
        if dynamic:
            p = dyn_params or {}
            local_pos, local_neg, local_edge = compute_dynamic_case_counts(
                req,
                p.get("min_total", 3),
                p.get("max_total", 9),
                p.get("pos_w", 3.0),
                p.get("neg_w", 2.0),
                p.get("edge_w", 2.0),
            )
            if st.session_state.get("debug_mode"):
                st.write(f"{req_id} åŠ¨æ€åˆ†é… -> æ­£å‘:{local_pos} å¼‚å¸¸:{local_neg} è¾¹ç•Œ:{local_edge}")
        prompt = build_prompt(req, headers, local_pos, local_neg, local_edge, req_id, background_knowledge)
        text = call_model(model, prompt, base_url, temperature)
        if text:
            df = parse_csv_to_df(text, headers)
            if df is not None and not df.empty:
                if "éœ€æ±‚ç¼–å·" not in df.columns:
                    df.insert(0, "éœ€æ±‚ç¼–å·", req_id)
                else:
                    # å¡«å……ç©ºå€¼ / çº æ­£é¦–è¡Œç¼ºå¤±
                    df['éœ€æ±‚ç¼–å·'] = df['éœ€æ±‚ç¼–å·'].astype(str)
                    df['éœ€æ±‚ç¼–å·'] = df['éœ€æ±‚ç¼–å·'].where(df['éœ€æ±‚ç¼–å·'].str.strip() != "", req_id)
                if "éœ€æ±‚æè¿°" not in df.columns:
                    df.insert(1, "éœ€æ±‚æè¿°", req[:100])
                all_cases.append(df)
        if i < total - 1:
            time.sleep(2)
    pb.empty(); status.empty()
    if all_cases:
        return pd.concat(all_cases, ignore_index=True)
    raise ValueError("æœªç”Ÿæˆä»»ä½•ç”¨ä¾‹")

@handle_errors
def read_background_doc(file: Optional[Any]) -> Optional[str]:
    if file is None: return None
    name = file.name.lower()
    if name.endswith('.docx'): return read_word(file)
    if name.endswith(('.txt', '.md')): return StringIO(file.getvalue().decode("utf-8")).read()
    if name.endswith('.pdf'):
        try:
            # å°è¯•å¯¼å…¥PDFå¤„ç†åº“
            from PyPDF2 import PdfReader
            pdf = PdfReader(BytesIO(file.getvalue()))
            text = ""
            for page in pdf.pages:
                text += page.extract_text() + "\n"
            return text.strip()
        except ImportError:
            st.error("PDFå¤„ç†éœ€è¦å®‰è£… PyPDF2 åº“ã€‚è¯·è¿è¡Œ: pip install PyPDF2")
            return None
        except Exception as e:
            st.error(f"PDFè¯»å–å¤±è´¥: {e}")
            return None
    st.warning("ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œè¯·ä½¿ç”¨ .docx, .txt, .md æˆ– .pdf")
    return None

def setup_sidebar() -> Tuple[str, str, float, List[str], int, int, int, bool, Dict[str, Any]]:
    with st.sidebar:
        st.header("è¿æ¥è®¾ç½®")
        st.caption("å½“å‰ä½¿ç”¨ç¡¬ç¼–ç  API Key (ç•Œé¢ä¸å†æä¾›ä¿®æ”¹)ã€‚")
        # æ¨¡å‹æ ‡ç­¾å±•ç¤º (å…è´¹ / è®¡è´¹)
        model_display = {m: f"{m} {MODEL_PRICING_TAG.get(m,'')}" for m in ALLOWED_MODELS}
        model_choice = st.selectbox("æ¨¡å‹ (MiMoå…è´¹ / å…¶ä»–è®¡è´¹)", list(model_display.keys()), format_func=lambda k: model_display[k])
        model = model_choice
        base_url = st.text_input("API Base URL", value=DEFAULT_BASE_URL)
        st.checkbox("è°ƒè¯•æ¨¡å¼", value=False, key="debug_mode", help="æ˜¾ç¤ºé‡è¯• / åŸå§‹é”™è¯¯ç‰‡æ®µï¼ŒååŠ©æ’æŸ¥ 502 ç­‰é—®é¢˜")
        temperature = st.slider("Temperature", 0.0, 1.0, 0.2, 0.05)
        st.divider(); st.header("èƒŒæ™¯çŸ¥è¯† (å¯é€‰)")
        background_doc = st.file_uploader("ä¸Šä¼ èƒŒæ™¯æ–‡æ¡£", type=["docx", "txt", "md", "pdf"])
        if background_doc:
            if st.session_state.get('last_background_doc_name') != background_doc.name:
                content = read_background_doc(background_doc)
                st.session_state['background_knowledge'] = content
                st.session_state['last_background_doc_name'] = background_doc.name
                if content:
                    st.success("å·²åŠ è½½èƒŒæ™¯")
        else:
            st.session_state.pop('background_knowledge_file', None)
            st.session_state.pop('last_background_doc_name', None)

        # ç›´æ¥æ–‡æœ¬è¾“å…¥èƒŒæ™¯çŸ¥è¯†
        st.markdown("**ç›´æ¥è¾“å…¥èƒŒæ™¯çŸ¥è¯† (ç²˜è´´æ–‡æ¡£å†…å®¹)**")
        direct_text = st.text_area("èƒŒæ™¯çŸ¥è¯†æ–‡æœ¬", placeholder="ç²˜è´´æ–‡æ¡£å†…å®¹ã€éœ€æ±‚è§„æ ¼è¯´æ˜ç­‰...", height=150, key="direct_background_text")
        if direct_text and direct_text.strip():
            st.session_state['background_knowledge'] = direct_text.strip()
            st.success("å·²è®¾ç½®èƒŒæ™¯çŸ¥è¯†æ–‡æœ¬")
        elif not background_doc and not st.session_state.get('background_urls_content'):
            st.session_state.pop('background_knowledge', None)

        # å¤šä¸ª URL è¾“å…¥
        st.markdown("**ç½‘é¡µé“¾æ¥ (æ¯è¡Œä¸€ä¸ª URLï¼Œå¯ä¸æ–‡æ¡£æ··åˆ)**")
        url_text = st.text_area("èƒŒæ™¯é“¾æ¥åˆ—è¡¨", placeholder="https://example.com/doc1\nhttps://example.com/spec", height=110)
        load_urls = st.button("åŠ è½½é“¾æ¥å†…å®¹")
        if load_urls:
            raw_urls = [u.strip() for u in url_text.splitlines() if u.strip()]
            valid_urls = [u for u in raw_urls if _is_valid_url(u)]
            bad_urls = [u for u in raw_urls if u and u not in valid_urls]
            fetched = []
            for u in valid_urls[:8]:  # é™åˆ¶æœ€å¤š 8 ä¸ªï¼Œé¿å…è¿‡æ…¢
                with st.spinner(f"æŠ“å– {u} ..."):
                    txt = fetch_url_content(u)
                fetched.append((u, txt))
            st.session_state['background_urls'] = valid_urls
            st.session_state['background_urls_content'] = fetched
            if bad_urls:
                st.warning(f"æ— æ•ˆé“¾æ¥å·²å¿½ç•¥: {len(bad_urls)}")
            st.success(f"å·²è·å– {len(fetched)} ä¸ªé“¾æ¥")

        # ç»„åˆèƒŒæ™¯ (æ–‡æ¡£ + ç›´æ¥æ–‡æœ¬ + URL)
        combined_parts = []
        if st.session_state.get('background_knowledge') and not st.session_state.get('direct_background_text'):
            # å¦‚æœæœ‰ä¸Šä¼ çš„æ–‡æ¡£å†…å®¹ä¸”æ²¡æœ‰ç›´æ¥è¾“å…¥ï¼Œåˆ™ä½¿ç”¨æ–‡æ¡£å†…å®¹
            combined_parts.append("ã€æ–‡æ¡£å†…å®¹ã€‘\n" + st.session_state['background_knowledge'])
        if st.session_state.get('direct_background_text') and st.session_state.get('direct_background_text').strip():
            combined_parts.append("ã€ç›´æ¥è¾“å…¥ã€‘\n" + st.session_state['direct_background_text'].strip())
        if st.session_state.get('background_urls_content'):
            for u, txt in st.session_state['background_urls_content']:
                combined_parts.append(f"ã€ç½‘é¡µæ‘˜å½•ã€‘{u}\n{txt}")
        combined_text = "\n\n".join(combined_parts) if combined_parts else None
        st.session_state['background_knowledge'] = combined_text

        if combined_text:
            with st.expander("æŸ¥çœ‹åˆå¹¶èƒŒæ™¯ (å‰500å­—ç¬¦)"):
                st.text(combined_text[:500] + ("..." if len(combined_text) > 500 else ""))
        st.divider(); st.header("ç”¨ä¾‹é…ç½®")
        headers_text = st.text_input("åˆ—å", value=",".join(DEFAULT_HEADERS))
        headers = [h.strip() for h in headers_text.split(",") if h.strip()]
        auto_mode = st.checkbox("æŒ‰éœ€æ±‚è‡ªåŠ¨åˆ†é…ç”¨ä¾‹æ•°é‡", value=False, help="åŸºäºéœ€æ±‚é•¿åº¦/å…³é”®è¯åŠ¨æ€ç¡®å®šæ­£å‘/å¼‚å¸¸/è¾¹ç•Œæ•°é‡")
        dyn_params: Dict[str, Any] = {}
        if auto_mode:
            c1, c2 = st.columns(2)
            with c1:
                min_total = st.number_input("æœ€å°æ€»æ•°", 3, 30, 3)
                pos_w = st.number_input("æ­£å‘æƒé‡", 0.5, 10.0, 3.0, 0.5)
            with c2:
                max_total = st.number_input("æœ€å¤§æ€»æ•°", 3, 50, 9)
                neg_w = st.number_input("å¼‚å¸¸æƒé‡", 0.5, 10.0, 2.0, 0.5)
            edge_w = st.number_input("è¾¹ç•Œæƒé‡", 0.5, 10.0, 2.0, 0.5)
            dyn_params = {"min_total": min_total, "max_total": max_total, "pos_w": pos_w, "neg_w": neg_w, "edge_w": edge_w}
            st.caption("æ ¹æ®éœ€æ±‚å¤æ‚åº¦ (é•¿åº¦/å¥å­æ•°/é£é™©å…³é”®è¯) åœ¨çº¿è®¡ç®—ç”¨ä¾‹æ•°é‡")
            # å ä½å›ºå®šå€¼ (ä¸ä¼šè¢«ä½¿ç”¨)
            pos_n = neg_n = edge_n = 0
        else:
            pos_n = st.number_input("æ­£å‘", 1, 20, 2)
            neg_n = st.number_input("å¼‚å¸¸", 1, 20, 2)
            edge_n = st.number_input("è¾¹ç•Œ", 1, 20, 2)
        st.divider()
        st.subheader("é£ä¹¦APIé…ç½® (å¯é€‰)")
        st.caption("ç”¨äºè®¿é—®é£ä¹¦æ–‡æ¡£ä½œä¸ºèƒŒæ™¯çŸ¥è¯†ã€‚éœ€è¦å…ˆåœ¨é£ä¹¦å¼€å‘è€…åå°é…ç½®åº”ç”¨å¹¶è·å–å‡­è¯ã€‚")
        st.info("ğŸ’¡ **é£ä¹¦æ–‡æ¡£è®¿é—®æç¤º**: å¦‚æœé‡åˆ°æƒé™é—®é¢˜ï¼Œå¯ä»¥ï¼š1) åœ¨é£ä¹¦ä¸­å¯¼å‡ºæ–‡æ¡£ä¸ºWord/PDFåä¸Šä¼ ï¼›2) å¤åˆ¶æ–‡æ¡£å†…å®¹ç›´æ¥ç²˜è´´åˆ°ä¸Šæ–¹æ–‡æœ¬æ¡†ï¼›3) åˆ†äº«æ–‡æ¡£ä¸ºå…¬å¼€é“¾æ¥")
        feishu_app_id = st.text_input("é£ä¹¦åº”ç”¨ID", placeholder="cli_xxx", help="ä»é£ä¹¦å¼€å‘è€…åå°è·å–")
        feishu_app_secret = st.text_input("é£ä¹¦åº”ç”¨å¯†é’¥", type="password", placeholder="xxx", help="ä»é£ä¹¦å¼€å‘è€…åå°è·å–")
        if feishu_app_id and feishu_app_secret:
            # å­˜å‚¨åˆ°ç¯å¢ƒå˜é‡æˆ–session
            os.environ["FEISHU_APP_ID"] = feishu_app_id
            os.environ["FEISHU_APP_SECRET"] = feishu_app_secret
            st.success("é£ä¹¦APIå‡­è¯å·²é…ç½®")
        elif feishu_app_id or feishu_app_secret:
            st.warning("è¯·åŒæ—¶æä¾›é£ä¹¦åº”ç”¨IDå’Œåº”ç”¨å¯†é’¥")
        else:
            st.info("æœªé…ç½®é£ä¹¦APIå‡­è¯ï¼Œå°†ä½¿ç”¨ç½‘é¡µæŠ“å–æ–¹å¼è®¿é—®é£ä¹¦æ–‡æ¡£")
        return base_url, model, temperature, headers, pos_n, neg_n, edge_n, auto_mode, dyn_params

from app_handlers import (
    handle_single_requirement,
    handle_batch_processing,
    handle_help_page
)

import streamlit as st
from typing import Dict, Any, List, Tuple
from app_handlers import (
    handle_single_requirement,
    handle_batch_processing,
    handle_help_page
)

def setup_session():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'requirements_initialized' not in st.session_state:
        st.session_state.requirements_initialized = True
        st.session_state.collected_requirements = []
        st.session_state.source_counts = []
        st.session_state.last_batch_result = None

# è¿™äº›å‡½æ•°å·²ç§»è‡³ app_handlers.py

def initialize_session_state():
    """åˆå§‹åŒ–Streamlitä¼šè¯çŠ¶æ€å˜é‡"""
    session_vars = {
        'requirements_initialized': True,
        'collected_requirements': [],
        'source_counts': [],
        'last_batch_result': None,
        'background_knowledge': None,
        'background_file': None,
        'background_urls': [],
        'background_urls_content': [],
        'debug_mode': False,
        'direct_background_text': ""
    }
    
    for var, default in session_vars.items():
        if var not in st.session_state:
            st.session_state[var] = default

def initialize_session_state():
    """åˆå§‹åŒ–Streamlitä¼šè¯çŠ¶æ€å˜é‡"""
    session_vars = {
        'requirements_initialized': True,
        'collected_requirements': [],
        'source_counts': [],
        'last_batch_result': None,
        'background_knowledge': None,
        'background_file': None,
        'background_urls': [],
        'background_urls_content': [],
        'debug_mode': False,
        'direct_background_text': ""
    }
    
    for var, default in session_vars.items():
        if var not in st.session_state:
            st.session_state[var] = default

def main() -> None:
    """ä¸»åº”ç”¨å…¥å£ç‚¹"""
    try:
        # è®¾ç½®é¡µé¢é…ç½®
        st.set_page_config(
            page_title="AI æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨",
            page_icon="ğŸ”",
            layout="wide"
        )
        
        # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        initialize_session_state()
        
        # é¡µé¢æ ‡é¢˜
        st.title("AI æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨ - ç”µåŠ›ç”µå­")
        
        # è®¾ç½®ä¾§è¾¹æ é…ç½®
        base_url, model, temperature, headers, pos_n, neg_n, edge_n, auto_mode, dyn_params = setup_sidebar()
        
        # åˆ›å»ºä¸»æ ‡ç­¾é¡µ
        tab1, tab2, tab3 = st.tabs(["å•æ¡éœ€æ±‚ ğŸ’¡", "æ‰¹é‡å¤„ç† ğŸ“‘", "å¸®åŠ© â“"])
        
        # å¤„ç†å„æ ‡ç­¾é¡µå†…å®¹
        with tab1:
            handle_single_requirement(
                base_url=base_url,
                model=model,
                temperature=temperature,
                headers=headers,
                pos_n=pos_n,
                neg_n=neg_n,
                edge_n=edge_n,
                auto_mode=auto_mode,
                dyn_params=dyn_params
            )
            
        with tab2:
            handle_batch_processing(
                base_url=base_url,
                model=model,
                temperature=temperature,
                headers=headers,
                pos_n=pos_n,
                neg_n=neg_n,
                edge_n=edge_n,
                auto_mode=auto_mode,
                dyn_params=dyn_params
            )
            
        with tab3:
            handle_help_page()
            
    except Exception as e:
        st.error("åº”ç”¨ç¨‹åºå‘ç”Ÿé”™è¯¯")
        if st.session_state.get("debug_mode"):
            st.exception(e)
        logger.exception("åº”ç”¨ç¨‹åºé”™è¯¯")

if __name__ == '__main__':
    main()
import pandas as pd
import plotly.express as px
from typing import Dict, Any, List, Optional

from helper_functions import (
    render_batch_input, MIN_PARAGRAPH_LENGTH,
    read_excel, read_word, read_background_doc,
    fetch_feishu_document
)

API_BASE_URL = "https://api.your-server.com/v1"  # AI æ¥å£åŸºç¡€ URL

def generate_testcases(requirement: str) -> List[Dict[str, str]]:
    """æ ¹æ®éœ€æ±‚ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
    
    Args:
        requirement: éœ€æ±‚æè¿°æ–‡æœ¬
    
    Returns:
        æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
    """
    try:
        # è¿™é‡Œæ·»åŠ å®é™…çš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆé€»è¾‘
        # ç›®å‰è¿”å›ä¸€ä¸ªç¤ºä¾‹æµ‹è¯•ç”¨ä¾‹
        return [{
            "title": "åŸºæœ¬åŠŸèƒ½æµ‹è¯•",
            "priority": "é«˜",
            "precondition": "ç³»ç»Ÿæ­£å¸¸è¿è¡Œ",
            "steps": "1. æ‰§è¡Œä¸»è¦åŠŸèƒ½\n2. éªŒè¯ç»“æœ",
            "expected": "åŠŸèƒ½æ­£å¸¸æ‰§è¡Œ,ç»“æœç¬¦åˆé¢„æœŸ"
        }]
    except Exception as e:
        st.error(f"ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å¤±è´¥: {e}")
        return []

def read_excel(file: BytesIO) -> Dict[str, pd.DataFrame]:
    """è¯»å–Excelæ–‡ä»¶å†…å®¹
    
    Args:
        file: ä¸Šä¼ çš„Excelæ–‡ä»¶å¯¹è±¡
    
    Returns:
        å·¥ä½œè¡¨åç§°åˆ°æ•°æ®è¡¨çš„æ˜ å°„å­—å…¸
    """
    try:
        return pd.read_excel(file, sheet_name=None)
    except Exception as e:
        st.error(f"Excelè¯»å–å¤±è´¥: {e}")
        return {}

def read_word(file: BytesIO) -> str:
    """è¯»å–Wordæ–‡ä»¶å†…å®¹
    
    Args:
        file: ä¸Šä¼ çš„Wordæ–‡ä»¶å¯¹è±¡
    
    Returns:
        æ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²
    """
    try:
        doc = Document(file)
        return "\n".join(p.text for p in doc.paragraphs)
    except Exception as e:
        st.error(f"Wordè¯»å–å¤±è´¥: {e}")
        return ""

def read_background_doc(file: BytesIO) -> str:
    """è¯»å–PDFç­‰èƒŒæ™¯æ–‡æ¡£
    
    Args:
        file: ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
    
    Returns:
        æ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²
    """
    try:
        # ä½¿ç”¨PDFè§£æåº“è¯»å–å†…å®¹
        # ç›®å‰ç®€å•è¿”å›ç©ºå­—ç¬¦ä¸²
        return ""
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return ""

def fetch_feishu_document(url_or_id: str) -> Optional[str]:
    """è¯»å–é£ä¹¦æ–‡æ¡£å†…å®¹
    
    Args:
        url_or_id: é£ä¹¦æ–‡æ¡£URLæˆ–ID
    
    Returns:
        æ–‡æ¡£å†…å®¹å­—ç¬¦ä¸²,å¤±è´¥è¿”å›None
    """
    try:
        # ä½¿ç”¨é£ä¹¦APIè¯»å–æ–‡æ¡£
        # ç›®å‰ç®€å•è¿”å›None
        return None
    except Exception as e:
        st.error(f"é£ä¹¦æ–‡æ¡£è¯»å–å¤±è´¥: {e}")
        return None
    # å¯¼å…¥å¿…è¦çš„æ¨¡å—
    import streamlit as st
    from requirements_manager import RequirementsManager
    import pandas as pd
    from io import BytesIO, StringIO
    from docx import Document
    import re
    
    # åˆå§‹åŒ–å…¨å±€æ ·å¼å’Œé…ç½®
    st.set_page_config(
        page_title="éœ€æ±‚åˆ†æåŠ©æ‰‹",
        page_icon="ğŸ“",
        layout="wide"
    )
    
    # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
    context = {
        'reqmgr': RequirementsManager()
    }
    
    # æ˜¾ç¤ºæ ‡é¢˜å’Œè¯´æ˜
    st.title("éœ€æ±‚åˆ†æåŠ©æ‰‹")
    st.write(
        """
        è¿™æ˜¯ä¸€ä¸ªå¸®åŠ©åˆ†æå’Œç®¡ç†éœ€æ±‚çš„å·¥å…·ã€‚ä½ å¯ä»¥:
        - ä»å¤šç§æ¥æºå¯¼å…¥éœ€æ±‚(é£ä¹¦æ–‡æ¡£ã€Excelã€Wordç­‰)
        - äº¤äº’å¼åˆ†ææ¯æ¡éœ€æ±‚å¹¶ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        - åœ¨çœ‹æ¿ä¸­æŸ¥çœ‹æ•´ä½“è¿›åº¦
        """
    )
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs(["æ‰¹é‡å¯¼å…¥ ğŸ“¥", "äº¤äº’å¼åˆ†æ ğŸ”", "çœ‹æ¿ ğŸ“Š"])

    # æ‰¹é‡å¯¼å…¥æ ‡ç­¾é¡µ
    with tab1:
        col1, col2 = st.columns(2)
        with col1:
            render_batch_input(context)
        with col2:
            render_batch_preview(context)

    # äº¤äº’å¼åˆ†ææ ‡ç­¾é¡µ
    with tab2:
        col1, col2 = st.columns(2)
        with col1:
            render_manual_input(context)
        with col2:
            render_testcase_preview(context)
    
    # çœ‹æ¿æ ‡ç­¾é¡µ
    with tab3:
        render_dashboard(context)
        
        if st.button("ç”Ÿæˆ"):
            auto_req_id = req_id.strip() or extract_req_id(req_text) or ""
            if not req_id.strip() and auto_req_id:
                st.info(f"è‡ªåŠ¨è¯†åˆ«éœ€æ±‚ç¼–å·: {auto_req_id}")
            
            placeholder = st.empty()
            progress = st.progress(0)
            
            try:
                local_pos = pos_n
                local_neg = neg_n
                local_edge = edge_n
                
                if auto_mode:
                    local_pos, local_neg, local_edge = compute_dynamic_case_counts(
                        req_text,
                        dyn_params.get("min_total", 3),
                        dyn_params.get("max_total", 9),
                        dyn_params.get("pos_w", 3.0),
                        dyn_params.get("neg_w", 2.0),
                        dyn_params.get("edge_w", 2.0),
                    )
                    st.info(f"åŠ¨æ€åˆ†é… -> æ­£å‘:{local_pos} å¼‚å¸¸:{local_neg} è¾¹ç•Œ:{local_edge} (æ€»è®¡:{local_pos+local_neg+local_edge})")
                
                prompt = build_prompt(
                    req_text, 
                    headers, 
                    local_pos,
                    local_neg, 
                    local_edge,
                    auto_req_id,
                    st.session_state.get('background_knowledge')
                )
                
                placeholder.info("ç”Ÿæˆä¸­...")
                progress.progress(10)
                
                text = call_model(model, prompt, base_url, temperature)
                progress.progress(80)
                
                if text:
                    df = parse_csv_to_df(text, headers)
                    progress.progress(95)
                    
                    if df is None or df.empty:
                        placeholder.error("è§£æå¤±è´¥")
                    else:
                        if "éœ€æ±‚ç¼–å·" in df.columns and auto_req_id:
                            df['éœ€æ±‚ç¼–å·'] = df['éœ€æ±‚ç¼–å·'].astype(str)
                            df['éœ€æ±‚ç¼–å·'] = df['éœ€æ±‚ç¼–å·'].where(df['éœ€æ±‚ç¼–å·'].str.strip() != "", auto_req_id)
                        elif auto_req_id and "éœ€æ±‚ç¼–å·" not in df.columns:
                            df.insert(0, "éœ€æ±‚ç¼–å·", auto_req_id)
                        
                        st.dataframe(df, use_container_width=True)
                        make_excel_download(df)
                        make_csv_download(df)
                        progress.progress(100)
                        placeholder.success("å®Œæˆ")
            except Exception as e:
                progress.empty()
                placeholder.error(f"ç”Ÿæˆå¤±è´¥: {e}")
    
    # æ‰¹é‡å¤„ç†æ ‡ç­¾é¡µ
    with tab2:
        st.subheader("æ‰¹é‡å¯¼å…¥éœ€æ±‚")
        # åˆ›å»ºå·¦å³ä¸¤åˆ—
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### éœ€æ±‚è¾“å…¥")
            render_batch_input(ctx)
            
        with col2:
            st.markdown("### éœ€æ±‚é¢„è§ˆä¸ç”Ÿæˆ")
            render_batch_preview(ctx)
            
from app_handlers import handle_help_page  # ä»app_handlerså¯¼å…¥
    
    # ç¤ºä¾‹å±•ç¤º
    st.markdown("### ğŸ“ éœ€æ±‚ç¤ºä¾‹")
    for example in get_requirement_examples():
        st.markdown(f"- {example}")
    
    # èƒŒæ™¯çŸ¥è¯†è®¾ç½®
    st.markdown("""
    ### ğŸ“š èƒŒæ™¯çŸ¥è¯†è®¾ç½®
    
    **æ”¯æŒçš„è¾“å…¥æ–¹å¼ï¼š**
    - ğŸ“„ **æ–‡ä»¶ä¸Šä¼ **
      - Wordæ–‡æ¡£ (.docx)
      - æ–‡æœ¬æ–‡ä»¶ (.txt)
      - Markdown (.md)
      - PDFæ–‡æ¡£ (.pdf)
    
    - ğŸ“ **ç›´æ¥è¾“å…¥**
      - å¤åˆ¶ç²˜è´´æ–‡æ¡£å†…å®¹
      - æ”¯æŒå¤šæ®µè½æ ¼å¼
    
    - ğŸŒ **ç½‘é¡µé“¾æ¥**
      - è‡ªåŠ¨æŠ“å–ç½‘é¡µå†…å®¹
      - æ™ºèƒ½æ¸…ç†HTMLæ ‡ç­¾
      - æ”¯æŒå¤šä¸ªURL
    
    - ğŸª¶ **é£ä¹¦æ–‡æ¡£**
      - APIç›´æ¥è®¿é—®
      - ä¿ç•™æ–‡æ¡£ç»“æ„
      - æ”¯æŒdocxå’Œwiki
    
    **é£ä¹¦æ–‡æ¡£è®¿é—®è¯´æ˜ï¼š**
    1. APIè®¿é—®éœ€è¦æ–‡æ¡£æƒé™å’Œå‡­è¯
    2. é‡åˆ°æƒé™é—®é¢˜æ—¶çš„æ›¿ä»£æ–¹æ¡ˆï¼š
       - å¯¼å‡ºä¸ºWord/PDFåä¸Šä¼ 
       - å¤åˆ¶å†…å®¹åˆ°è¾“å…¥æ¡†
       - è®¾ç½®ä¸ºå…¬å¼€æ–‡æ¡£
    """)
    
    # æ•°æ®æ ¼å¼
    st.markdown("### ğŸ“Š æ•°æ®æ ¼å¼")
    
    st.markdown("**CSVè¾“å‡ºæ ¼å¼ï¼š**")
    output_tpl = get_output_format_template()
    st.code(output_tpl, language="csv")
    st.caption("æ ‡å‡†CSVæ ¼å¼è¯´æ˜ï¼šç¬¬ä¸€è¡Œä¸ºè¡¨å¤´ï¼Œä¸‹é¢ä¸ºæ•°æ®è¡Œ")
    
    # æç¤ºè¯æ¨¡æ¿
    st.markdown("### ğŸ¤– æç¤ºè¯æ¨¡æ¿")
    tpl = get_standard_prompt_template()
    st.code(tpl, language="text")
    st.caption("""
    æ¨¡æ¿å‚æ•°è¯´æ˜ï¼š
    - {èƒŒæ™¯çŸ¥è¯†}: ä¸Šä¸‹æ–‡ä¿¡æ¯
    - {åˆ—å}: CSVè¡¨å¤´å®šä¹‰
    - {éœ€æ±‚ç¼–å·}: éœ€æ±‚è¿½è¸ªID
    - {éœ€æ±‚å…¨æ–‡}: å®Œæ•´éœ€æ±‚æè¿°
    - {æ­£å‘æ•°}/{å¼‚å¸¸æ•°}/{è¾¹ç•Œæ•°}: ç”¨ä¾‹æ•°é‡åˆ†é…
    """)
    
    # æ¨¡å‹è¯´æ˜
    st.markdown("""
    ### ğŸš€ æ¨¡å‹è¯´æ˜
    
    å½“å‰æ”¯æŒçš„æ¨¡å‹ï¼š
    - **MiMo-7B-RL**: å…è´¹ä½¿ç”¨
    - **Qwen-235B-A22B**: è®¡è´¹ä½¿ç”¨
    - **deepseek-v3.1**: è®¡è´¹ä½¿ç”¨
    - **Qwen2.5-VL-72B**: è®¡è´¹ä½¿ç”¨
    
    ğŸ’¡ æ‰€æœ‰æ¨¡å‹ä½¿ç”¨å›ºå®šçš„å†…éƒ¨APIå¯†é’¥
    """)
    
    # ä½¿ç”¨å»ºè®®
    st.markdown("""
    ### ğŸ’¡ ä½¿ç”¨å»ºè®®
    
    1. **éœ€æ±‚ç¼–å†™**
       - ä½¿ç”¨æ¸…æ™°çš„æè¿°
       - é¿å…æ­§ä¹‰è¡¨è¾¾
       - åŒ…å«å…·ä½“å‚æ•°
    
    2. **èƒŒæ™¯çŸ¥è¯†**
       - æä¾›å®Œæ•´ä¸Šä¸‹æ–‡
       - åŒ…å«ç›¸å…³è§„èŒƒ
       - è¯´æ˜æŠ€æœ¯é™åˆ¶
    
    3. **ç”¨ä¾‹ç”Ÿæˆ**
       - åˆç†åˆ†é…æ•°é‡
       - æ³¨æ„è¾¹ç•Œåœºæ™¯
       - éªŒè¯è¾“å‡ºç»“æœ
    """)
    
    # æ•…éšœæ’é™¤
    st.markdown("""
    ### âš ï¸ å¸¸è§é—®é¢˜
    
    1. **é£ä¹¦æ–‡æ¡£è®¿é—®å¤±è´¥**
       - æ£€æŸ¥æ–‡æ¡£æƒé™
       - ç¡®è®¤APIå‡­è¯
       - ä½¿ç”¨æ›¿ä»£æ–¹æ¡ˆ
    
    2. **ç”Ÿæˆç»“æœå¼‚å¸¸**
       - å®Œå–„éœ€æ±‚æè¿°
       - è¡¥å……èƒŒæ™¯çŸ¥è¯†
       - è°ƒæ•´æ¨¡å‹å‚æ•°
    
    3. **æ‰¹é‡å¤„ç†æ…¢**
       - å‡å°‘å¹¶è¡Œæ•°é‡
       - æ§åˆ¶å•æ¬¡æ•°é‡
       - åˆ†æ‰¹æ¬¡å¤„ç†
    """)
    
    # åé¦ˆæ¸ é“
    st.markdown("""
    ### ğŸ“® é—®é¢˜åé¦ˆ
    
    å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼åé¦ˆï¼š
    1. æäº¤è¯¦ç»†çš„é—®é¢˜æè¿°
    2. é™„ä¸Šç›¸å…³çš„æ—¥å¿—ä¿¡æ¯
    3. è¯´æ˜ä½¿ç”¨çš„ç¯å¢ƒé…ç½®
    """)

if __name__ == '__main__':
    main()
                else:
                    # åˆ†æ”¯è§£æ
                    branches = split_requirement_into_branches(req_text, max_branches=max_branches)
                    if not branches:
                        st.warning("æœªè§£æå‡ºæœ‰æ•ˆåˆ†æ”¯ï¼Œå›é€€ä¸ºæ•´ä½“ç”Ÿæˆ")
                        branches = [{"branch_index":1, "branch_id":"B01", "title":"æ•´ä½“", "content":req_text}]
                    st.info(f"è§£æå¾—åˆ° {len(branches)} ä¸ªåˆ†æ”¯")
                    # åˆ†æ”¯ç”¨ä¾‹åˆ†é…ç­–ç•¥
                    branch_cases: List[Tuple[Dict[str,str], Tuple[int,int,int]]] = []
                    # æ‰‹åŠ¨å›ºå®š
                    manual_tuple = None
                    if branch_strategy == "æ‰‹åŠ¨å›ºå®š" and manual_counts_text:
                        try:
                            parts = [int(x) for x in re.split(r"[ï¼Œ,]\s*", manual_counts_text) if x.strip()][:3]
                            if len(parts)==3 and all(p>0 for p in parts):
                                manual_tuple = tuple(parts)  # type: ignore
                        except Exception:
                            pass
                        if not manual_tuple:
                            st.warning("æ‰‹åŠ¨å›ºå®šæ ¼å¼ä¸æ­£ç¡®ï¼Œå°†å›é€€ä¸ºå‡åˆ†")
                    # é¢„è®¡ç®—å¤æ‚åº¦ç”¨äºåŠ¨æ€ç­–ç•¥
                    scores = [ _complexity_score(b['content']) for b in branches ]
            except Exception as e:
                progress.empty()
                placeholder.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")

        try:
            with tab2:
                st.subheader("æ‰¹é‡å¯¼å…¥éœ€æ±‚")
                # å¯¼å…¥å¿…è¦çš„æ¨¡å—
                import requirements_manager as reqmgr
                import pandas as pd
                from docx import Document
                import PyPDF2
                from io import BytesIO, StringIO
                import re
                from test_batch import BatchProcessor
                
                # åˆ›å»ºå·¦å³ä¸¤åˆ—å¸ƒå±€
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("### éœ€æ±‚è¾“å…¥")
                    
                    # æ¸…ç©ºæŒ‰é’®
                    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰éœ€æ±‚"):
                        reqmgr.clear_requirements()
                        st.success("å·²æ¸…ç©ºæ‰€æœ‰éœ€æ±‚")
                    
                    # 1. é£ä¹¦æ–‡æ¡£è¾“å…¥
                    feishu_doc = st.text_input("é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID", 
                                           placeholder="è¾“å…¥é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID")
                    if feishu_doc:
                        try:
                            with st.spinner("æ­£åœ¨è¯»å–é£ä¹¦æ–‡æ¡£..."):
                                doc_content = fetch_feishu_document(feishu_doc)
                                if doc_content:
                                    parts = re.split(r"\n\s*\n+", doc_content.strip())
                                    feishu_reqs = [p for p in parts 
                                                 if len(p.strip()) > MIN_PARAGRAPH_LENGTH]
                                    if feishu_reqs:
                                        reqmgr.add_requirements_batch(feishu_reqs, "é£ä¹¦æ–‡æ¡£")
                                        st.success(f"å·²å¯¼å…¥ {len(feishu_reqs)} æ¡éœ€æ±‚")
                        except Exception as e:
                            st.error(f"é£ä¹¦æ–‡æ¡£è¯»å–å¤±è´¥: {e}")
                    
                    # 2. æ–‡ä»¶ä¸Šä¼ 
                    uploaded_files = st.file_uploader(
                        "ä¸Šä¼ éœ€æ±‚æ–‡ä»¶",
                        type=["xlsx", "docx", "pdf", "txt", "csv"],
                        accept_multiple_files=True
                    )
                
                    if uploaded_files:
                        for file in uploaded_files:
                            try:
                                if file.name.lower().endswith('.xlsx'):
                                    with st.spinner(f"æ­£åœ¨å¤„ç† Excel æ–‡ä»¶ {file.name}..."):
                                        df = pd.read_excel(file)
                                        df_reqs = df['éœ€æ±‚æè¿°'].dropna().tolist()
                                        if df_reqs:
                                            reqmgr.add_requirements_batch(df_reqs, f"Excel-{file.name}")
                                            st.success(f"å·²å¯¼å…¥ {len(df_reqs)} æ¡éœ€æ±‚")
                                
                                elif file.name.lower().endswith('.docx'):
                                    with st.spinner(f"æ­£åœ¨å¤„ç† Word æ–‡ä»¶ {file.name}..."):
                                        doc = Document(file)
                                        word_reqs = [p.text.strip() for p in doc.paragraphs 
                                                   if len(p.text.strip()) > MIN_PARAGRAPH_LENGTH]
                                        if word_reqs:
                                            reqmgr.add_requirements_batch(word_reqs, f"Word-{file.name}")
                                            st.success(f"å·²å¯¼å…¥ {len(word_reqs)} æ¡éœ€æ±‚")
                                
                                elif file.name.lower().endswith('.pdf'):
                                    with st.spinner(f"æ­£åœ¨å¤„ç† PDF æ–‡ä»¶ {file.name}..."):
                                        pdf_reader = PyPDF2.PdfReader(BytesIO(file.read()))
                                        pdf_reqs = []
                                        for page in pdf_reader.pages:
                                            text = page.extract_text()
                                            parts = re.split(r"\n\s*\n+", text.strip())
                                            pdf_reqs.extend([p for p in parts 
                                                           if len(p.strip()) > MIN_PARAGRAPH_LENGTH])
                                        if pdf_reqs:
                                            reqmgr.add_requirements_batch(pdf_reqs, f"PDF-{file.name}")
                                            st.success(f"å·²å¯¼å…¥ {len(pdf_reqs)} æ¡éœ€æ±‚")
                                
                                elif file.name.lower().endswith(('.txt', '.csv')):
                                    with st.spinner(f"æ­£åœ¨å¤„ç†æ–‡æœ¬æ–‡ä»¶ {file.name}..."):
                                        stringio = StringIO(file.getvalue().decode("utf-8"))
                                        lines = [l.strip() for l in stringio.readlines() 
                                               if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                                        if lines:
                                            reqmgr.add_requirements_batch(lines, f"Text-{file.name}")
                                            st.success(f"å·²å¯¼å…¥ {len(lines)} æ¡éœ€æ±‚")
                            except Exception as e:
                                st.error(f"å¤„ç†æ–‡ä»¶ {file.name} å¤±è´¥: {e}")
                
                # 3. æ‰‹åŠ¨è¾“å…¥
                manual_reqs = st.text_area(
                    "ç›´æ¥è¾“å…¥éœ€æ±‚ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
                    placeholder="éœ€æ±‚1\néœ€æ±‚2\néœ€æ±‚3...",
                    height=150
                )
                
                if st.button("æ·»åŠ æ‰‹å·¥è¾“å…¥"):
                    if manual_reqs:
                        lines = [l.strip() for l in manual_reqs.splitlines() 
                                if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                        if lines:
                            reqmgr.add_requirements_batch(lines, "æ‰‹å·¥è¾“å…¥")
                            st.success(f"å·²æ·»åŠ  {len(lines)} æ¡éœ€æ±‚")
                    else:
                        st.warning("è¯·è¾“å…¥éœ€æ±‚å†…å®¹")
            
            with col2:
                st.markdown("### éœ€æ±‚é¢„è§ˆä¸ç”Ÿæˆ")
                
                # è·å–å»é‡éœ€æ±‚
                unique_reqs = reqmgr.get_unique_requirements()
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                source_summary = reqmgr.get_source_summary()
                if source_summary:
                    st.info(f"æ•°æ®æ¥æº: {source_summary}")
                    st.info(f"å»é‡åæ€»è®¡: {len(unique_reqs)} æ¡éœ€æ±‚")
                
                # é¢„è§ˆè¡¨æ ¼
                if unique_reqs:
                    preview_df = pd.DataFrame(unique_reqs)
                    st.dataframe(preview_df, use_container_width=True)
                    
                    st.divider()
                    st.markdown("### ç”Ÿæˆè®¾ç½®")
                    
                    parallel = st.number_input("å¹¶è¡Œå¤„ç†æ•°", 1, 8, 4)
                    progress_ph = st.empty()
                    result_ph = st.empty()
                    
                    if st.button("å¼€å§‹æ‰¹é‡ç”Ÿæˆ", type="primary"):
                        try:
                            progress_bar = progress_ph.progress(0)
                            result_ph.info("æ­£åœ¨ç”Ÿæˆ...")
                            
                            # åˆ›å»ºå¤„ç†å™¨
                            processor = BatchProcessor(
                                model=model,
                                base_url=base_url,
                                headers=headers,
                                pos_n=pos_n,
                                neg_n=neg_n,
                                edge_n=edge_n,
                                temperature=temperature,
                                max_workers=parallel,
                                background_knowledge=st.session_state.get('background_knowledge'),
                                dynamic_mode=auto_mode,
                                dynamic_params=dyn_params
                            )
                            
                            # å‡†å¤‡éœ€æ±‚åˆ—è¡¨
                            req_list = reqmgr.get_requirements_for_batch()
                            
                            # æ‰§è¡Œç”Ÿæˆ
                            df_result = processor.process_batch(req_list)
                            progress_bar.progress(100)
                            
                            if df_result is not None and not df_result.empty:
                                result_ph.success(f"å·²ç”Ÿæˆ {len(df_result)} æ¡æµ‹è¯•ç”¨ä¾‹")
                                st.dataframe(df_result, use_container_width=True)
                                
                                # å‡†å¤‡ä¸‹è½½
                                excel_data = BytesIO()
                                with pd.ExcelWriter(excel_data, engine='openpyxl') as writer:
                                    df_result.to_excel(writer, index=False)
                                excel_data.seek(0)
                                
                                # ä¸‹è½½æŒ‰é’®
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½ Excel",
                                    data=excel_data,
                                    file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                                
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½ CSV",
                                    data=df_result.to_csv(index=False).encode('utf-8-sig'),
                                    file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv",
                                    mime="text/csv"
                                )
                                
                                # é”™è¯¯ä¿¡æ¯
                                errors = processor.get_errors()
                                if errors:
                                    with st.expander(f"å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ ({len(errors)})"):
                                        for req_id, error in errors:
                                            st.error(f"{req_id}: {error}")
                            else:
                                result_ph.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
                        except Exception as e:
                            progress_ph.empty()
                            result_ph.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
                    else:
                        st.warning("è¯·å…ˆæ·»åŠ éœ€æ±‚")
def handle_file_upload():
    """å¤„ç†æ–‡ä»¶ä¸Šä¼ ç•Œé¢"""
    try:
        # æ¸…ç©ºæŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰éœ€æ±‚"):
            st.session_state.collected_requirements = []
            st.session_state.source_counts = []
            st.success("å·²æ¸…ç©ºæ‰€æœ‰éœ€æ±‚")

        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ éœ€æ±‚æ–‡ä»¶",
            type=["xlsx", "docx", "pdf", "txt", "csv"],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            for file in uploaded_files:
                try:
                    name = file.name.lower()
                    if name.endswith('.xlsx'):
                        _process_excel_file(file)
                    elif name.endswith('.docx'):
                        _process_word_file(file)
                    elif name.endswith('.pdf'):
                        _process_pdf_file(file)
                    elif name.endswith(('.txt', '.csv')):
                        _process_text_file(file)
                except Exception as e:
                    st.error(f"å¤„ç†æ–‡ä»¶ {file.name} å¤±è´¥: {e}")
        
        # æ‰‹åŠ¨è¾“å…¥
        return st.text_area(
            "ç›´æ¥è¾“å…¥éœ€æ±‚ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
            placeholder="éœ€æ±‚1\néœ€æ±‚2\néœ€æ±‚3...",
            height=150
        )
    except Exception as e:
        st.error(f"æ–‡ä»¶ä¸Šä¼ å¤„ç†é”™è¯¯: {e}")
        if st.session_state.get("debug_mode"):
            st.exception(e)
        return None

    if st.button("æ·»åŠ æ‰‹å·¥è¾“å…¥"):
        if manual_reqs:
            lines = [l.strip() for l in manual_reqs.splitlines() 
                   if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
            if lines:
                for line in lines:
                    st.session_state.collected_requirements.append({
                        "éœ€æ±‚ç¼–å·": "",
                        "éœ€æ±‚æè¿°": line,
                        "æ¥æº": "æ‰‹å·¥è¾“å…¥"
                    })
                st.session_state.source_counts.append(f"æ‰‹å·¥:{len(lines)}")
                st.success(f"å·²æ·»åŠ  {len(lines)} æ¡éœ€æ±‚")
        else:
            st.warning("è¯·è¾“å…¥éœ€æ±‚å†…å®¹")
            import pandas as pd
            from docx import Document
            import PyPDF2
            from io import BytesIO, StringIO
            import re
            
            # æ¸…ç©ºæŒ‰é’®
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰éœ€æ±‚"):
                reqmgr.clear_requirements()
                st.success("å·²æ¸…ç©ºæ‰€æœ‰éœ€æ±‚")
            
            # 1. é£ä¹¦æ–‡æ¡£è¾“å…¥
            feishu_doc = st.text_input("é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID", 
                                     placeholder="è¾“å…¥é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID")
            if feishu_doc:
                try:
                    with st.spinner("æ­£åœ¨è¯»å–é£ä¹¦æ–‡æ¡£..."):
                        doc_content = fetch_feishu_document(feishu_doc)
                        if doc_content:
                            parts = re.split(r"\n\s*\n+", doc_content.strip())
                            feishu_reqs = [p for p in parts 
                                         if len(p.strip()) > MIN_PARAGRAPH_LENGTH]
                            reqmgr.add_requirements_batch(feishu_reqs, "é£ä¹¦æ–‡æ¡£")
                            st.success(f"å·²å¯¼å…¥ {len(feishu_reqs)} æ¡éœ€æ±‚")
                except Exception as e:
                    st.error(f"é£ä¹¦æ–‡æ¡£è¯»å–å¤±è´¥: {e}")
                                            st.success(f"å·²å¯¼å…¥ {len(df_reqs)} æ¡éœ€æ±‚")
                                    
                                    elif lname.endswith('.docx'):
                                        doc = Document(file)
                                        word_reqs = [p.text.strip() for p in doc.paragraphs 
                                                if len(p.text.strip()) > MIN_PARAGRAPH_LENGTH]
                                        if word_reqs:
                                            for req in word_reqs:
                                                st.session_state.collected_requirements.append({
                                                    "éœ€æ±‚ç¼–å·": "",
                                                    "éœ€æ±‚æè¿°": req.strip(),
                                                    "æ¥æº": f"Word-{file.name}"
                                                })
                                            st.session_state.source_counts.append(
                                                f"Word-{file.name}:{len(word_reqs)}")
                                            st.success(f"å·²å¯¼å…¥ {len(word_reqs)} æ¡éœ€æ±‚")
                                    
                                    elif lname.endswith('.pdf'):
                                        bytes_data = file.getvalue()
                                        pdf_reader = PyPDF2.PdfReader(BytesIO(bytes_data))
                                        pdf_reqs = []
                                        for page in pdf_reader.pages:
                                            text = page.extract_text()
                                            parts = re.split(r"\n\s*\n+", text.strip())
                                            pdf_reqs.extend([p for p in parts 
                                                        if len(p.strip()) > MIN_PARAGRAPH_LENGTH])
                                        if pdf_reqs:
                                            for req in pdf_reqs:
                                                st.session_state.collected_requirements.append({
                                                    "éœ€æ±‚ç¼–å·": "",
                                                    "éœ€æ±‚æè¿°": req.strip(),
                                                    "æ¥æº": f"PDF-{file.name}"
                                                })
                                            st.session_state.source_counts.append(
                                                f"PDF-{file.name}:{len(pdf_reqs)}")
                                            st.success(f"å·²å¯¼å…¥ {len(pdf_reqs)} æ¡éœ€æ±‚")
                                    
                                    elif lname.endswith(('.txt', '.csv')):
                                        stringio = StringIO(file.getvalue().decode("utf-8"))
                                        lines = [l.strip() for l in stringio.readlines() 
                                               if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                                        if lines:
                                            for req in lines:
                                                st.session_state.collected_requirements.append({
                                                    "éœ€æ±‚ç¼–å·": "",
                                                    "éœ€æ±‚æè¿°": req.strip(),
                                                    "æ¥æº": f"Text-{file.name}"
                                                })
                                            st.session_state.source_counts.append(
                                                f"Text-{file.name}:{len(lines)}")
                                            st.success(f"å·²å¯¼å…¥ {len(lines)} æ¡éœ€æ±‚")
                            except Exception as e:
                                st.error(f"å¤„ç†æ–‡ä»¶ {file.name} å¤±è´¥: {e}")
                except Exception as e:
                    st.error(f"æ–‡ä»¶ä¸Šä¼ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
                return

            handle_file_uploads()
                
                if st.button("å¼€å§‹æ‰¹é‡ç”Ÿæˆ", type="primary"):
                    try:
                        progress_bar = progress_ph.progress(0)
                        result_ph.info("æ­£åœ¨ç”Ÿæˆ...")
                        
                        # åˆ›å»ºå¤„ç†å™¨
                        processor = BatchProcessor(
                            model=model,
                            base_url=base_url,
                            headers=headers,
                            pos_n=pos_n,
                            neg_n=neg_n,
                            edge_n=edge_n,
                            temperature=temperature,
                            max_workers=parallel,
                            background_knowledge=st.session_state.get('background_knowledge'),
                            dynamic_mode=auto_mode,
                            dynamic_params=dyn_params
                        )
                        
                        # å‡†å¤‡éœ€æ±‚åˆ—è¡¨
                        req_list = reqmgr.get_requirements_for_batch()
                        
                        # æ‰§è¡Œç”Ÿæˆ
                        df_result = processor.process_batch(req_list)
                        progress_bar.progress(100)
                        
                        if df_result is not None and not df_result.empty:
                            result_ph.success(f"å·²ç”Ÿæˆ {len(df_result)} æ¡æµ‹è¯•ç”¨ä¾‹")
                            st.dataframe(df_result, use_container_width=True)
                            
                            # å‡†å¤‡ä¸‹è½½
                            excel_data = BytesIO()
                            with pd.ExcelWriter(excel_data, engine='openpyxl') as writer:
                                df_result.to_excel(writer, index=False)
                            excel_data.seek(0)
                            
                            # ä¸‹è½½æŒ‰é’®
                            st.download_button(
                                "ğŸ“¥ ä¸‹è½½ Excel",
                                data=excel_data,
                                file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                            
                            st.download_button(
                                "ğŸ“¥ ä¸‹è½½ CSV",
                                data=df_result.to_csv(index=False).encode('utf-8-sig'),
                                file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv",
                                mime="text/csv"
                            )
                            
                            # é”™è¯¯ä¿¡æ¯
                            errors = processor.get_errors()
                            if errors:
                                with st.expander(f"å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ ({len(errors)})"):
                                    for req_id, error in errors:
                                        st.error(f"{req_id}: {error}")
                        else:
                            result_ph.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
                            
                    except Exception as e:
                        progress_ph.empty()
                        result_ph.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
            else:
                st.warning("è¯·å…ˆæ·»åŠ éœ€æ±‚")
        
        # åˆ›å»ºå·¦å³ä¸¤åˆ—å¸ƒå±€
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### éœ€æ±‚è¾“å…¥")
            render_batch_input()
        with col2:
            st.markdown("### éœ€æ±‚é¢„è§ˆä¸ç”Ÿæˆ")
            render_batch_preview()
        try:
            # å¯¼å…¥å¿…è¦çš„æ¨¡å—
            import requirements_manager as reqmgr
            import pandas as pd
            from docx import Document
            import PyPDF2
            from io import BytesIO, StringIO
            import re
            
            # åˆ›å»ºå·¦å³ä¸¤åˆ—å¸ƒå±€
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### éœ€æ±‚è¾“å…¥")
                
                # æ¸…ç©ºæŒ‰é’®
                if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰éœ€æ±‚"):
                    reqmgr.clear_requirements()
                    st.success("å·²æ¸…ç©ºæ‰€æœ‰éœ€æ±‚")
                
                # 1. é£ä¹¦æ–‡æ¡£è¾“å…¥
                feishu_doc = st.text_input("é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID", 
                                         placeholder="è¾“å…¥é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID")
                if feishu_doc:
                    try:
                        with st.spinner("æ­£åœ¨è¯»å–é£ä¹¦æ–‡æ¡£..."):
                            doc_content = fetch_feishu_document(feishu_doc)
                            if doc_content:
                                parts = re.split(r"\n\s*\n+", doc_content.strip())
                                feishu_reqs = [p for p in parts 
                                             if len(p.strip()) > MIN_PARAGRAPH_LENGTH]
                                reqmgr.add_requirements_batch(feishu_reqs, "é£ä¹¦æ–‡æ¡£")
                                st.success(f"å·²å¯¼å…¥ {len(feishu_reqs)} æ¡éœ€æ±‚")
                    except Exception as e:
                        st.error(f"é£ä¹¦æ–‡æ¡£è¯»å–å¤±è´¥: {e}")
                
                # 2. æ–‡ä»¶ä¸Šä¼ 
                uploaded_files = st.file_uploader(
                    "ä¸Šä¼ éœ€æ±‚æ–‡ä»¶",
                    type=["xlsx", "docx", "pdf", "txt", "csv"],
                    accept_multiple_files=True
                )
                
                if uploaded_files:
                    for file in uploaded_files:
                        try:
                            with st.spinner(f"æ­£åœ¨å¤„ç† {file.name}..."):
                                if file.name.lower().endswith('.xlsx'):
                                    df = pd.read_excel(file)
                                    df_reqs = df['éœ€æ±‚æè¿°'].dropna().tolist()
                                    if df_reqs:
                                        reqmgr.add_requirements_batch(
                                            df_reqs, 
                                            f"Excel-{file.name}"
                                        )
                                        st.success(f"å·²å¯¼å…¥ {len(df_reqs)} æ¡éœ€æ±‚")
                                
                                elif file.name.lower().endswith('.docx'):
                                    doc = Document(file)
                                    word_reqs = [p.text.strip() for p in doc.paragraphs 
                                               if len(p.text.strip()) > MIN_PARAGRAPH_LENGTH]
                                    if word_reqs:
                                        reqmgr.add_requirements_batch(
                                            word_reqs,
                                            f"Word-{file.name}"
                                        )
                                        st.success(f"å·²å¯¼å…¥ {len(word_reqs)} æ¡éœ€æ±‚")
                                
                                elif file.name.lower().endswith('.pdf'):
                                    bytes_data = file.getvalue()
                                    pdf_reader = PyPDF2.PdfReader(BytesIO(bytes_data))
                                    pdf_reqs = []
                                    for page in pdf_reader.pages:
                                        text = page.extract_text()
                                        parts = re.split(r"\n\s*\n+", text.strip())
                                        pdf_reqs.extend([p for p in parts 
                                                       if len(p.strip()) > MIN_PARAGRAPH_LENGTH])
                                    if pdf_reqs:
                                        reqmgr.add_requirements_batch(
                                            pdf_reqs,
                                            f"PDF-{file.name}"
                                        )
                                        st.success(f"å·²å¯¼å…¥ {len(pdf_reqs)} æ¡éœ€æ±‚")
                                
                                elif file.name.lower().endswith(('.txt', '.csv')):
                                    stringio = StringIO(file.getvalue().decode("utf-8"))
                                    lines = [l.strip() for l in stringio.readlines() 
                                           if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                                    if lines:
                                        reqmgr.add_requirements_batch(
                                            lines,
                                            f"Text-{file.name}"
                                        )
                                        st.success(f"å·²å¯¼å…¥ {len(lines)} æ¡éœ€æ±‚")
                        except Exception as e:
                            st.error(f"å¤„ç†æ–‡ä»¶ {file.name} å¤±è´¥: {e}")
                
                # 3. æ‰‹åŠ¨è¾“å…¥
                manual_reqs = st.text_area(
                    "ç›´æ¥è¾“å…¥éœ€æ±‚ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
                    placeholder="éœ€æ±‚1\néœ€æ±‚2\néœ€æ±‚3...",
                    height=150
                )
                
                if st.button("æ·»åŠ æ‰‹å·¥è¾“å…¥"):
                    if manual_reqs:
                        lines = [l.strip() for l in manual_reqs.splitlines() 
                                if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                        if lines:
                            reqmgr.add_requirements_batch(lines, "æ‰‹å·¥è¾“å…¥")
                            st.success(f"å·²æ·»åŠ  {len(lines)} æ¡éœ€æ±‚")
                    else:
                        st.warning("è¯·è¾“å…¥éœ€æ±‚å†…å®¹")
            
            with col2:
                st.markdown("### éœ€æ±‚é¢„è§ˆä¸ç”Ÿæˆ")
                
                # è·å–å»é‡éœ€æ±‚
                unique_reqs = reqmgr.get_unique_requirements()
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                source_summary = reqmgr.get_source_summary()
                if source_summary:
                    st.info(f"æ•°æ®æ¥æº: {source_summary}")
                    st.info(f"å»é‡åæ€»è®¡: {len(unique_reqs)} æ¡éœ€æ±‚")
                
                # é¢„è§ˆè¡¨æ ¼
                if unique_reqs:
                    preview_df = pd.DataFrame(unique_reqs)
                    st.dataframe(preview_df, use_container_width=True)
                    
                    st.divider()
                    st.markdown("### ç”Ÿæˆè®¾ç½®")
                    
                    parallel = st.number_input("å¹¶è¡Œå¤„ç†æ•°", 1, 8, 4)
                    progress_ph = st.empty()
                    result_ph = st.empty()
                    
                    if st.button("å¼€å§‹æ‰¹é‡ç”Ÿæˆ", type="primary"):
                        try:
                            progress_bar = progress_ph.progress(0)
                            result_ph.info("æ­£åœ¨ç”Ÿæˆ...")
                            
                            # åˆ›å»ºå¤„ç†å™¨
                            processor = BatchProcessor(
                                model=model,
                                base_url=base_url,
                                headers=headers,
                                pos_n=pos_n,
                                neg_n=neg_n,
                                edge_n=edge_n,
                                temperature=temperature,
                                max_workers=parallel,
                                background_knowledge=st.session_state.get('background_knowledge'),
                                dynamic_mode=auto_mode,
                                dynamic_params=dyn_params
                            )
                            
                            # å‡†å¤‡éœ€æ±‚åˆ—è¡¨
                            req_list = reqmgr.get_requirements_for_batch()
                            
                            # æ‰§è¡Œç”Ÿæˆ
                            df_result = processor.process_batch(req_list)
                            progress_bar.progress(100)
                            
                            if df_result is not None and not df_result.empty:
                                result_ph.success(f"å·²ç”Ÿæˆ {len(df_result)} æ¡æµ‹è¯•ç”¨ä¾‹")
                                st.dataframe(df_result, use_container_width=True)
                                
                                # å‡†å¤‡ä¸‹è½½
                                excel_data = BytesIO()
                                with pd.ExcelWriter(excel_data, engine='openpyxl') as writer:
                                    df_result.to_excel(writer, index=False)
                                excel_data.seek(0)
                                
                                # ä¸‹è½½æŒ‰é’®
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½ Excel",
                                    data=excel_data,
                                    file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                                
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½ CSV",
                                    data=df_result.to_csv(index=False).encode('utf-8-sig'),
                                    file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv",
                                    mime="text/csv"
                                )
                                
                                # é”™è¯¯ä¿¡æ¯
                                errors = processor.get_errors()
                                if errors:
                                    with st.expander(f"å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ ({len(errors)})"):
                                        for req_id, error in errors:
                                            st.error(f"{req_id}: {error}")
                            else:
                                result_ph.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
                                
                        except Exception as e:
                            progress_ph.empty()
                            result_ph.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
                else:
                    st.warning("è¯·å…ˆæ·»åŠ éœ€æ±‚")
        except Exception as e:
            st.error(f"é¡µé¢æ¸²æŸ“é”™è¯¯: {e}")
        try:
            import requirements_manager as reqmgr
            
            # åˆå§‹åŒ–å…¨å±€å˜é‡
            collected = []
            source_counts = []
            
            # åˆ›å»ºå·¦å³ä¸¤åˆ—å¸ƒå±€
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### éœ€æ±‚è¾“å…¥")
                
                # æ¸…ç©ºæŒ‰é’®
                if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰éœ€æ±‚"):
                    reqmgr.clear_requirements()
                    st.success("å·²æ¸…ç©ºæ‰€æœ‰éœ€æ±‚")
                
                # 1. é£ä¹¦æ–‡æ¡£è¾“å…¥
                feishu_doc = st.text_input("é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID", 
                                         placeholder="è¾“å…¥é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID")
                if feishu_doc:
                    try:
                        with st.spinner("æ­£åœ¨è¯»å–é£ä¹¦æ–‡æ¡£..."):
                            doc_content = fetch_feishu_document(feishu_doc)
                            if doc_content:
                                parts = re.split(r"\n\s*\n+", doc_content.strip())
                                feishu_reqs = [p for p in parts 
                                             if len(p.strip()) > MIN_PARAGRAPH_LENGTH]
                                reqmgr.add_requirements_batch(feishu_reqs, "é£ä¹¦æ–‡æ¡£")
                                st.success(f"å·²å¯¼å…¥ {len(feishu_reqs)} æ¡éœ€æ±‚")
                    except Exception as e:
                        st.error(f"é£ä¹¦æ–‡æ¡£è¯»å–å¤±è´¥: {e}")
                
                # 2. æ–‡ä»¶ä¸Šä¼ 
                uploaded_files = st.file_uploader(
                    "ä¸Šä¼ éœ€æ±‚æ–‡ä»¶",
                    type=["xlsx", "docx", "pdf", "txt", "csv"],
                    accept_multiple_files=True
                )
                
                if uploaded_files:
                    for file in uploaded_files:
                        try:
                            with st.spinner(f"æ­£åœ¨å¤„ç† {file.name}..."):
                                if file.name.lower().endswith('.xlsx'):
                                    df = pd.read_excel(file)
                                    df_reqs = df['éœ€æ±‚æè¿°'].dropna().tolist()
                                    if df_reqs:
                                        reqmgr.add_requirements_batch(
                                            df_reqs, 
                                            f"Excel-{file.name}"
                                        )
                                        st.success(f"å·²å¯¼å…¥ {len(df_reqs)} æ¡éœ€æ±‚")
                                
                                elif file.name.lower().endswith('.docx'):
                                    doc = Document(file)
                                    word_reqs = [p.text.strip() for p in doc.paragraphs 
                                               if len(p.text.strip()) > MIN_PARAGRAPH_LENGTH]
                                    if word_reqs:
                                        reqmgr.add_requirements_batch(
                                            word_reqs,
                                            f"Word-{file.name}"
                                        )
                                        st.success(f"å·²å¯¼å…¥ {len(word_reqs)} æ¡éœ€æ±‚")
                                
                                elif file.name.lower().endswith('.pdf'):
                                    bytes_data = file.getvalue()
                                    pdf_reader = PyPDF2.PdfReader(BytesIO(bytes_data))
                                    pdf_reqs = []
                                    for page in pdf_reader.pages:
                                        text = page.extract_text()
                                        parts = re.split(r"\n\s*\n+", text.strip())
                                        pdf_reqs.extend([p for p in parts 
                                                       if len(p.strip()) > MIN_PARAGRAPH_LENGTH])
                                    if pdf_reqs:
                                        reqmgr.add_requirements_batch(
                                            pdf_reqs,
                                            f"PDF-{file.name}"
                                        )
                                        st.success(f"å·²å¯¼å…¥ {len(pdf_reqs)} æ¡éœ€æ±‚")
                                
                                elif file.name.lower().endswith(('.txt', '.csv')):
                                    stringio = StringIO(file.getvalue().decode("utf-8"))
                                    lines = [l.strip() for l in stringio.readlines() 
                                           if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                                    if lines:
                                        reqmgr.add_requirements_batch(
                                            lines,
                                            f"Text-{file.name}"
                                        )
                                        st.success(f"å·²å¯¼å…¥ {len(lines)} æ¡éœ€æ±‚")
                        
                        except Exception as e:
                            st.error(f"å¤„ç†æ–‡ä»¶ {file.name} å¤±è´¥: {e}")
                
                # 3. æ‰‹åŠ¨è¾“å…¥
                manual_reqs = st.text_area(
                    "ç›´æ¥è¾“å…¥éœ€æ±‚ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
                    placeholder="éœ€æ±‚1\néœ€æ±‚2\néœ€æ±‚3...",
                    height=150
                )
                
                if st.button("æ·»åŠ æ‰‹å·¥è¾“å…¥"):
                    if manual_reqs:
                        lines = [l.strip() for l in manual_reqs.splitlines() 
                                if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                        if lines:
                            reqmgr.add_requirements_batch(lines, "æ‰‹å·¥è¾“å…¥")
                            st.success(f"å·²æ·»åŠ  {len(lines)} æ¡éœ€æ±‚")
                    else:
                        st.warning("è¯·è¾“å…¥éœ€æ±‚å†…å®¹")
            
            with col2:
                st.markdown("### éœ€æ±‚é¢„è§ˆä¸ç”Ÿæˆ")
                
                # è·å–å»é‡éœ€æ±‚
                unique_reqs = reqmgr.get_unique_requirements()
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                source_summary = reqmgr.get_source_summary()
                if source_summary:
                    st.info(f"æ•°æ®æ¥æº: {source_summary}")
                    st.info(f"å»é‡åæ€»è®¡: {len(unique_reqs)} æ¡éœ€æ±‚")
                
                # é¢„è§ˆè¡¨æ ¼
                if unique_reqs:
                    preview_df = pd.DataFrame(unique_reqs)
                    st.dataframe(preview_df, use_container_width=True)
                    
                    st.divider()
                    st.markdown("### ç”Ÿæˆè®¾ç½®")
                    
                    parallel = st.number_input("å¹¶è¡Œå¤„ç†æ•°", 1, 8, 4)
                    progress_ph = st.empty()
                    result_ph = st.empty()
                    
                    if st.button("å¼€å§‹æ‰¹é‡ç”Ÿæˆ", type="primary"):
                        try:
                            progress_bar = progress_ph.progress(0)
                            result_ph.info("æ­£åœ¨ç”Ÿæˆ...")
                            
                            # åˆ›å»ºå¤„ç†å™¨
                            processor = BatchProcessor(
                                model=model,
                                base_url=base_url,
                                headers=headers,
                                pos_n=pos_n,
                                neg_n=neg_n,
                                edge_n=edge_n,
                                temperature=temperature,
                                max_workers=parallel,
                                background_knowledge=st.session_state.get('background_knowledge'),
                                dynamic_mode=auto_mode,
                                dynamic_params=dyn_params
                            )
                            
                            # å‡†å¤‡éœ€æ±‚åˆ—è¡¨
                            req_list = reqmgr.get_requirements_for_batch()
                            
                            # æ‰§è¡Œç”Ÿæˆ
                            df_result = processor.process_batch(req_list)
                            progress_bar.progress(100)
                            
                            if df_result is not None and not df_result.empty:
                                result_ph.success(f"å·²ç”Ÿæˆ {len(df_result)} æ¡æµ‹è¯•ç”¨ä¾‹")
                                st.dataframe(df_result, use_container_width=True)
                                
                                # å‡†å¤‡ä¸‹è½½
                                excel_data = BytesIO()
                                with pd.ExcelWriter(excel_data, engine='openpyxl') as writer:
                                    df_result.to_excel(writer, index=False)
                                excel_data.seek(0)
                                
                                # ä¸‹è½½æŒ‰é’®
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½ Excel",
                                    data=excel_data,
                                    file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                                
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½ CSV",
                                    data=df_result.to_csv(index=False).encode('utf-8-sig'),
                                    file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv",
                                    mime="text/csv"
                                )
                                
                                # é”™è¯¯ä¿¡æ¯
                                errors = processor.get_errors()
                                if errors:
                                    with st.expander(f"å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ ({len(errors)})"):
                                        for req_id, error in errors:
                                            st.error(f"{req_id}: {error}")
                            else:
                                result_ph.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
                                
                        except Exception as e:
                            progress_ph.empty()
                            result_ph.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
                else:
                    st.warning("è¯·å…ˆæ·»åŠ éœ€æ±‚")
        except Exception as e:
            st.error(f"é¡µé¢æ¸²æŸ“é”™è¯¯: {e}")
        import requirements_manager as reqmgr
        
        # åˆå§‹åŒ–å…¨å±€å˜é‡
        collected = []
        source_counts = []
        
        try:
            # åˆ›å»ºå·¦å³ä¸¤åˆ—å¸ƒå±€
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### éœ€æ±‚è¾“å…¥")
                
                # æ¸…ç©ºæŒ‰é’®
                if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰éœ€æ±‚"):
                    reqmgr.clear_requirements()
                    st.success("å·²æ¸…ç©ºæ‰€æœ‰éœ€æ±‚")
                
                # 1. é£ä¹¦æ–‡æ¡£è¾“å…¥
                feishu_doc = st.text_input("é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID", 
                                         placeholder="è¾“å…¥é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID")
                if feishu_doc:
                    try:
                        with st.spinner("æ­£åœ¨è¯»å–é£ä¹¦æ–‡æ¡£..."):
                            doc_content = fetch_feishu_document(feishu_doc)
                            if doc_content:
                                parts = re.split(r"\n\s*\n+", doc_content.strip())
                                feishu_reqs = [p for p in parts 
                                             if len(p.strip()) > MIN_PARAGRAPH_LENGTH]
                                reqmgr.add_requirements_batch(feishu_reqs, "é£ä¹¦æ–‡æ¡£")
                                st.success(f"å·²å¯¼å…¥ {len(feishu_reqs)} æ¡éœ€æ±‚")
                    except Exception as e:
                        st.error(f"é£ä¹¦æ–‡æ¡£è¯»å–å¤±è´¥: {e}")
                
                # 2. æ–‡ä»¶ä¸Šä¼ 
                uploaded_files = st.file_uploader(
                    "ä¸Šä¼ éœ€æ±‚æ–‡ä»¶",
                    type=["xlsx", "docx", "pdf", "txt", "csv"],
                    accept_multiple_files=True
                )
                
                if uploaded_files:
                    for file in uploaded_files:
                        try:
                            with st.spinner(f"æ­£åœ¨å¤„ç† {file.name}..."):
                                if file.name.lower().endswith('.xlsx'):
                                    _process_excel_file(file)
                                elif file.name.lower().endswith('.docx'):
                                    _process_word_file(file)
                                elif file.name.lower().endswith('.pdf'):
                                    _process_pdf_file(file)
                                elif file.name.lower().endswith(('.txt', '.csv')):
                                    _process_text_file(file)
                        except Exception as e:
                            st.error(f"å¤„ç†æ–‡ä»¶ {file.name} å¤±è´¥: {e}")
                
                # 3. æ‰‹åŠ¨è¾“å…¥
                manual_reqs = st.text_area(
                    "ç›´æ¥è¾“å…¥éœ€æ±‚ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
                    placeholder="éœ€æ±‚1\néœ€æ±‚2\néœ€æ±‚3...",
                    height=150
                )
                
                if st.button("æ·»åŠ æ‰‹å·¥è¾“å…¥"):
                    if manual_reqs:
                        lines = [l.strip() for l in manual_reqs.splitlines() 
                                if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                        if lines:
                            reqmgr.add_requirements_batch(lines, "æ‰‹å·¥è¾“å…¥")
                            st.success(f"å·²æ·»åŠ  {len(lines)} æ¡éœ€æ±‚")
                    else:
                        st.warning("è¯·è¾“å…¥éœ€æ±‚å†…å®¹")
            
            with col2:
                st.markdown("### éœ€æ±‚é¢„è§ˆä¸ç”Ÿæˆ")
                
                # è·å–å»é‡éœ€æ±‚
                unique_reqs = reqmgr.get_unique_requirements()
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                source_summary = reqmgr.get_source_summary()
                if source_summary:
                    st.info(f"æ•°æ®æ¥æº: {source_summary}")
                    st.info(f"å»é‡åæ€»è®¡: {len(unique_reqs)} æ¡éœ€æ±‚")
                
                # é¢„è§ˆè¡¨æ ¼
                if unique_reqs:
                    preview_df = pd.DataFrame(unique_reqs)
                    st.dataframe(preview_df, use_container_width=True)
                    
                    st.divider()
                    st.markdown("### ç”Ÿæˆè®¾ç½®")
                    
                    parallel = st.number_input("å¹¶è¡Œå¤„ç†æ•°", 1, 8, 4)
                    progress_ph = st.empty()
                    result_ph = st.empty()
                    
                    if st.button("å¼€å§‹æ‰¹é‡ç”Ÿæˆ", type="primary"):
                        try:
                            progress_bar = progress_ph.progress(0)
                            result_ph.info("æ­£åœ¨ç”Ÿæˆ...")
                            
                            # åˆ›å»ºå¤„ç†å™¨
                            processor = BatchProcessor(
                                model=model,
                                base_url=base_url,
                                headers=headers,
                                pos_n=pos_n,
                                neg_n=neg_n,
                                edge_n=edge_n,
                                temperature=temperature,
                                max_workers=parallel,
                                background_knowledge=st.session_state.get('background_knowledge'),
                                dynamic_mode=auto_mode,
                                dynamic_params=dyn_params
                            )
                            
                            # å‡†å¤‡éœ€æ±‚åˆ—è¡¨
                            req_list = reqmgr.get_requirements_for_batch()
                            
                            # æ‰§è¡Œç”Ÿæˆ
                            df_result = processor.process_batch(req_list)
                            progress_bar.progress(100)
                            
                            if df_result is not None and not df_result.empty:
                                result_ph.success(f"å·²ç”Ÿæˆ {len(df_result)} æ¡æµ‹è¯•ç”¨ä¾‹")
                                st.dataframe(df_result, use_container_width=True)
                                
                                # å‡†å¤‡ä¸‹è½½
                                excel_data = BytesIO()
                                with pd.ExcelWriter(excel_data, engine='openpyxl') as writer:
                                    df_result.to_excel(writer, index=False)
                                excel_data.seek(0)
                                
                                # ä¸‹è½½æŒ‰é’®
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½ Excel",
                                    data=excel_data,
                                    file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                                
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½ CSV",
                                    data=df_result.to_csv(index=False).encode('utf-8-sig'),
                                    file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv",
                                    mime="text/csv"
                                )
                                
                                # é”™è¯¯ä¿¡æ¯
                                errors = processor.get_errors()
                                if errors:
                                    with st.expander(f"å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ ({len(errors)})"):
                                        for req_id, error in errors:
                                            st.error(f"{req_id}: {error}")
                            else:
                                result_ph.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
                                
                        except Exception as e:
                            progress_ph.empty()
                            result_ph.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
                else:
                    st.warning("è¯·å…ˆæ·»åŠ éœ€æ±‚")
        except Exception as e:
            st.error(f"é¡µé¢æ¸²æŸ“é”™è¯¯: {e}")
        import requirements_manager as reqmgr
        
        try:
            # åˆ›å»ºå·¦å³ä¸¤åˆ—å¸ƒå±€
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### éœ€æ±‚è¾“å…¥")
                
                # æ¸…ç©ºæŒ‰é’®
                if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰éœ€æ±‚"):
                    reqmgr.clear_requirements()
                    st.success("å·²æ¸…ç©ºæ‰€æœ‰éœ€æ±‚")
                
                # 1. é£ä¹¦æ–‡æ¡£è¾“å…¥
                feishu_doc = st.text_input("é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID", 
                                         placeholder="è¾“å…¥é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID")
                if feishu_doc:
                    try:
                        with st.spinner("æ­£åœ¨è¯»å–é£ä¹¦æ–‡æ¡£..."):
                            doc_content = fetch_feishu_document(feishu_doc)
                            if doc_content:
                                parts = re.split(r"\n\s*\n+", doc_content.strip())
                                feishu_reqs = [p for p in parts 
                                             if len(p.strip()) > MIN_PARAGRAPH_LENGTH]
                                reqmgr.add_requirements_batch(feishu_reqs, "é£ä¹¦æ–‡æ¡£")
                                st.success(f"å·²å¯¼å…¥ {len(feishu_reqs)} æ¡éœ€æ±‚")
                    except Exception as e:
                        st.error(f"é£ä¹¦æ–‡æ¡£è¯»å–å¤±è´¥: {e}")
                
                # 2. æ–‡ä»¶ä¸Šä¼ 
                uploaded_files = st.file_uploader(
                    "ä¸Šä¼ éœ€æ±‚æ–‡ä»¶",
                    type=["xlsx", "docx", "pdf", "txt", "csv"],
                    accept_multiple_files=True
                )
                
                if uploaded_files:
                    for file in uploaded_files:
                        try:
                            with st.spinner(f"æ­£åœ¨å¤„ç† {file.name}..."):
                                if file.name.lower().endswith('.xlsx'):
                                    _process_excel_file(file)
                                elif file.name.lower().endswith('.docx'):
                                    _process_word_file(file)
                                elif file.name.lower().endswith('.pdf'):
                                    _process_pdf_file(file)
                                elif file.name.lower().endswith(('.txt', '.csv')):
                                    _process_text_file(file)
                        except Exception as e:
                            st.error(f"å¤„ç†æ–‡ä»¶ {file.name} å¤±è´¥: {e}")
                
                # 3. æ‰‹åŠ¨è¾“å…¥
                manual_reqs = st.text_area(
                    "ç›´æ¥è¾“å…¥éœ€æ±‚ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
                    placeholder="éœ€æ±‚1\néœ€æ±‚2\néœ€æ±‚3...",
                    height=150
                )
                
                if st.button("æ·»åŠ æ‰‹å·¥è¾“å…¥"):
                    if manual_reqs:
                        lines = [l.strip() for l in manual_reqs.splitlines() 
                                if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                        if lines:
                            reqmgr.add_requirements_batch(lines, "æ‰‹å·¥è¾“å…¥")
                            st.success(f"å·²æ·»åŠ  {len(lines)} æ¡éœ€æ±‚")
                    else:
                        st.warning("è¯·è¾“å…¥éœ€æ±‚å†…å®¹")
            
            with col2:
                st.markdown("### éœ€æ±‚é¢„è§ˆä¸ç”Ÿæˆ")
                
                # è·å–å»é‡éœ€æ±‚
                unique_reqs = reqmgr.get_unique_requirements()
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                source_summary = reqmgr.get_source_summary()
                if source_summary:
                    st.info(f"æ•°æ®æ¥æº: {source_summary}")
                    st.info(f"å»é‡åæ€»è®¡: {len(unique_reqs)} æ¡éœ€æ±‚")
                
                # é¢„è§ˆè¡¨æ ¼
                if unique_reqs:
                    preview_df = pd.DataFrame(unique_reqs)
                    st.dataframe(preview_df, use_container_width=True)
                    
                    st.divider()
                    st.markdown("### ç”Ÿæˆè®¾ç½®")
                    
                    parallel = st.number_input("å¹¶è¡Œå¤„ç†æ•°", 1, 8, 4)
                    progress_ph = st.empty()
                    result_ph = st.empty()
                    
                    if st.button("å¼€å§‹æ‰¹é‡ç”Ÿæˆ", type="primary"):
                        try:
                            progress_bar = progress_ph.progress(0)
                            result_ph.info("æ­£åœ¨ç”Ÿæˆ...")
                            
                            # åˆ›å»ºå¤„ç†å™¨
                            processor = BatchProcessor(
                                model=model,
                                base_url=base_url,
                                headers=headers,
                                pos_n=pos_n,
                                neg_n=neg_n,
                                edge_n=edge_n,
                                temperature=temperature,
                                max_workers=parallel,
                                background_knowledge=st.session_state.get('background_knowledge'),
                                dynamic_mode=auto_mode,
                                dynamic_params=dyn_params
                            )
                            
                            # å‡†å¤‡éœ€æ±‚åˆ—è¡¨
                            req_list = reqmgr.get_requirements_for_batch()
                            
                            # æ‰§è¡Œç”Ÿæˆ
                            df_result = processor.process_batch(req_list)
                            progress_bar.progress(100)
                            
                            if df_result is not None and not df_result.empty:
                                result_ph.success(f"å·²ç”Ÿæˆ {len(df_result)} æ¡æµ‹è¯•ç”¨ä¾‹")
                                st.dataframe(df_result, use_container_width=True)
                                
                                # å‡†å¤‡ä¸‹è½½
                                excel_data = BytesIO()
                                with pd.ExcelWriter(excel_data, engine='openpyxl') as writer:
                                    df_result.to_excel(writer, index=False)
                                excel_data.seek(0)
                                
                                # ä¸‹è½½æŒ‰é’®
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½ Excel",
                                    data=excel_data,
                                    file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                                
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½ CSV",
                                    data=df_result.to_csv(index=False).encode('utf-8-sig'),
                                    file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv",
                                    mime="text/csv"
                                )
                                
                                # é”™è¯¯ä¿¡æ¯
                                errors = processor.get_errors()
                                if errors:
                                    with st.expander(f"å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ ({len(errors)})"):
                                        for req_id, error in errors:
                                            st.error(f"{req_id}: {error}")
                            else:
                                result_ph.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
                                
                        except Exception as e:
                            progress_ph.empty()
                            result_ph.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
                else:
                    st.warning("è¯·å…ˆæ·»åŠ éœ€æ±‚")
        except Exception as e:
            st.error(f"é¡µé¢æ¸²æŸ“é”™è¯¯: {e}")
    
    if st.button("æ·»åŠ æ‰‹å·¥è¾“å…¥"):
        if manual_reqs:
            lines = [l.strip() for l in manual_reqs.splitlines() 
                    if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
            if lines:
                for line in lines:
                    st.session_state.collected_requirements.append({
                        "éœ€æ±‚ç¼–å·": "",
                        "éœ€æ±‚æè¿°": line,
                        "æ¥æº": "æ‰‹å·¥è¾“å…¥"
                    })
                st.session_state.source_counts.append(f"æ‰‹å·¥:{len(lines)}")
                st.success(f"å·²æ·»åŠ  {len(lines)} æ¡éœ€æ±‚")
        else:
            st.warning("è¯·è¾“å…¥éœ€æ±‚å†…å®¹")
            st.warning("è¯·è¾“å…¥éœ€æ±‚å†…å®¹")

def render_manual_input(ctx: Dict[str, Any]) -> None:
    """æ¸²æŸ“æ‰‹åŠ¨è¾“å…¥ç•Œé¢
    
    Args:
        ctx: ä¸Šä¸‹æ–‡å‚æ•°å­—å…¸,åŒ…å«:
            reqmgr: éœ€æ±‚ç®¡ç†å™¨å®ä¾‹
    """
    import streamlit as st
    
    st.markdown("### éœ€æ±‚åˆ†æ")
    
    # é€‰æ‹©éœ€æ±‚è¿›è¡Œåˆ†æ
    reqs = ctx['reqmgr'].get_unique_requirements()
    if not reqs:
        st.info("è¯·å…ˆå¯¼å…¥æˆ–è¾“å…¥éœ€æ±‚")
        return
        
    selected = st.selectbox(
        "é€‰æ‹©éœ€æ±‚è¿›è¡Œåˆ†æ",
        reqs,
        format_func=lambda x: f"{x[:100]}..." if len(x) > 100 else x
    )
    
    if selected:
        # æ˜¾ç¤ºéœ€æ±‚è¯¦æƒ…
        st.markdown("##### éœ€æ±‚è¯¦æƒ…")
        st.text_area(
            "éœ€æ±‚æè¿°",
            value=selected,
            height=100,
            disabled=True
        )
        
        sources = ctx['reqmgr'].get_requirement_sources(selected)
        if sources:
            st.markdown(f"**æ¥æº**: {', '.join(sources)}")
            
        # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        if st.button("ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹..."):
                test_cases = generate_testcases(selected)
                if test_cases:
                    ctx['reqmgr'].add_testcases(selected, test_cases)
                    st.success("æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆ")
                else:
                    st.error("æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥")

def render_testcase_preview(ctx: Dict[str, Any]) -> None:
    """æ¸²æŸ“æµ‹è¯•ç”¨ä¾‹é¢„è§ˆç•Œé¢
    
    Args:
        ctx: ä¸Šä¸‹æ–‡å‚æ•°å­—å…¸,åŒ…å«:
            reqmgr: éœ€æ±‚ç®¡ç†å™¨å®ä¾‹
    """
    import streamlit as st
    import pandas as pd
    
    st.markdown("### æµ‹è¯•ç”¨ä¾‹é¢„è§ˆ")
    
    # è·å–æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹
    all_cases = ctx['reqmgr'].get_all_testcases()
    if not all_cases:
        st.info("æš‚æ— æµ‹è¯•ç”¨ä¾‹")
        return
        
    # æ„å»ºé¢„è§ˆæ•°æ®
    preview_data = []
    for req, cases in all_cases.items():
        for case in cases:
            preview_data.append({
                "éœ€æ±‚": req[:100] + "..." if len(req) > 100 else req,
                "ç”¨ä¾‹æ ‡é¢˜": case.get("title", ""),
                "ä¼˜å…ˆçº§": case.get("priority", ""),
                "å‰ç½®æ¡ä»¶": case.get("precondition", ""),
                "æµ‹è¯•æ­¥éª¤": case.get("steps", ""),
                "é¢„æœŸç»“æœ": case.get("expected", "")
            })
    
    # æ˜¾ç¤ºæµ‹è¯•ç”¨ä¾‹è¡¨æ ¼
    df = pd.DataFrame(preview_data)
    st.dataframe(df, use_container_width=True)

def render_dashboard(ctx: Dict[str, Any]) -> None:
    """æ¸²æŸ“ç»Ÿè®¡çœ‹æ¿ç•Œé¢
    
    Args:
        ctx: ä¸Šä¸‹æ–‡å‚æ•°å­—å…¸,åŒ…å«:
            reqmgr: éœ€æ±‚ç®¡ç†å™¨å®ä¾‹
    """
    import streamlit as st
    import plotly.express as px
    import pandas as pd
    
    st.markdown("### éœ€æ±‚åˆ†æçœ‹æ¿")
    
    # 1. éœ€æ±‚æ€»è§ˆ
    reqs = ctx['reqmgr'].get_unique_requirements()
    if not reqs:
        st.info("æš‚æ— éœ€æ±‚æ•°æ®")
        return
        
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ€»éœ€æ±‚æ•°", len(reqs))
    with col2:
        all_cases = ctx['reqmgr'].get_all_testcases()
        total_cases = sum(len(cases) for cases in all_cases.values())
        st.metric("æ€»ç”¨ä¾‹æ•°", total_cases)
    with col3:
        coverage = round(100 * len(all_cases) / len(reqs), 1) if reqs else 0
        st.metric("éœ€æ±‚è¦†ç›–ç‡", f"{coverage}%")
    
    # 2. éœ€æ±‚æ¥æºåˆ†å¸ƒ
    st.markdown("#### éœ€æ±‚æ¥æºåˆ†å¸ƒ")
    source_counts = []
    for req in reqs:
        sources = ctx['reqmgr'].get_requirement_sources(req)
        for source in sources:
            source_counts.append({"æ¥æº": source, "æ•°é‡": 1})
    
    if source_counts:
        df = pd.DataFrame(source_counts)
        fig = px.pie(
            df,
            values="æ•°é‡",
            names="æ¥æº",
            title="éœ€æ±‚æ¥æºåˆ†å¸ƒ"
        )
        st.plotly_chart(fig)

def render_batch_preview(ctx: Dict[str, Any]) -> None:
    """æ¸²æŸ“æ‰¹é‡éœ€æ±‚é¢„è§ˆç•Œé¢
    
    Args:
        ctx: ä¸Šä¸‹æ–‡å‚æ•°å­—å…¸,åŒ…å«:
            reqmgr: éœ€æ±‚ç®¡ç†å™¨å®ä¾‹
    """
    import streamlit as st
    import pandas as pd
    
    # æ˜¾ç¤ºéœ€æ±‚ç»Ÿè®¡
    reqs = ctx['reqmgr'].get_unique_requirements()
    if not reqs:
        st.info("æš‚æ— éœ€æ±‚è®°å½•")
        return
        
    st.write(f"å½“å‰å…±æœ‰ {len(reqs)} æ¡ç‹¬ç‰¹éœ€æ±‚")
    
    # æ„å»ºé¢„è§ˆè¡¨æ ¼
    preview_data = []
    for req in reqs:
        sources = ctx['reqmgr'].get_requirement_sources(req)
        preview_data.append({
            "éœ€æ±‚": req,
            "æ¥æº": ", ".join(sources)
        })
    
    # æ˜¾ç¤ºé¢„è§ˆè¡¨æ ¼
    df = pd.DataFrame(preview_data)
    st.dataframe(df, use_container_width=True)
    """æ¸²æŸ“éœ€æ±‚é¢„è§ˆå’Œç”Ÿæˆç•Œé¢

    Args:
        ctx: ä¸Šä¸‹æ–‡å‚æ•°å­—å…¸ï¼ŒåŒ…å«:
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            base_url: APIåŸºç¡€URL
            headers: è¾“å‡ºè¡¨æ ¼çš„åˆ—å
            pos_n: æ­£å‘ç”¨ä¾‹æ•°
            neg_n: å¼‚å¸¸ç”¨ä¾‹æ•°
            edge_n: è¾¹ç•Œç”¨ä¾‹æ•°
            temperature: æ¨¡å‹æ¸©åº¦å‚æ•°
            auto_mode: æ˜¯å¦å¯ç”¨åŠ¨æ€åˆ†é…æ¨¡å¼
            dyn_params: åŠ¨æ€å‚æ•°
            reqmgr: éœ€æ±‚ç®¡ç†å™¨å®ä¾‹
    """
    import streamlit as st
    import pandas as pd
    from io import BytesIO
    from test_batch import BatchProcessor
    
    # è·å–å»é‡éœ€æ±‚
    unique_reqs = ctx['reqmgr'].get_unique_requirements()
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    source_summary = ctx['reqmgr'].get_source_summary()
    if source_summary:
        st.info(f"æ•°æ®æ¥æº: {source_summary}")
        st.info(f"å»é‡åæ€»è®¡: {len(unique_reqs)} æ¡éœ€æ±‚")
    
    # é¢„è§ˆè¡¨æ ¼
    if unique_reqs:
        preview_df = pd.DataFrame(unique_reqs)
        st.dataframe(preview_df, use_container_width=True)
        
        st.divider()
        st.markdown("### ç”Ÿæˆè®¾ç½®")
        
        parallel = st.number_input("å¹¶è¡Œå¤„ç†æ•°", 1, 8, 4)
        progress_ph = st.empty()
        result_ph = st.empty()
        
        if st.button("å¼€å§‹æ‰¹é‡ç”Ÿæˆ", type="primary"):
            try:
                progress_bar = progress_ph.progress(0)
                result_ph.info("æ­£åœ¨ç”Ÿæˆ...")
                
                # åˆ›å»ºå¤„ç†å™¨
                processor = BatchProcessor(
                    model=ctx['model'],
                    base_url=ctx['base_url'],
                    headers=ctx['headers'],
                    pos_n=ctx['pos_n'],
                    neg_n=ctx['neg_n'],
                    edge_n=ctx['edge_n'],
                    temperature=ctx['temperature'],
                    max_workers=parallel,
                    background_knowledge=st.session_state.get('background_knowledge'),
                    dynamic_mode=ctx['auto_mode'],
                    dynamic_params=ctx['dyn_params']
                )
                
                # å‡†å¤‡éœ€æ±‚åˆ—è¡¨
                req_list = ctx['reqmgr'].get_requirements_for_batch()
                
                # æ‰§è¡Œç”Ÿæˆ
                df_result = processor.process_batch(req_list)
                progress_bar.progress(100)
                
                if df_result is not None and not df_result.empty:
                    result_ph.success(f"å·²ç”Ÿæˆ {len(df_result)} æ¡æµ‹è¯•ç”¨ä¾‹")
                    st.dataframe(df_result, use_container_width=True)
                    
                    # å‡†å¤‡ä¸‹è½½
                    excel_data = BytesIO()
                    with pd.ExcelWriter(excel_data, engine='openpyxl') as writer:
                        df_result.to_excel(writer, index=False)
                    excel_data.seek(0)
                    
                    # ä¸‹è½½æŒ‰é’®
                    st.download_button(
                        "ğŸ“¥ ä¸‹è½½ Excel",
                        data=excel_data,
                        file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                    
                    st.download_button(
                        "ğŸ“¥ ä¸‹è½½ CSV",
                        data=df_result.to_csv(index=False).encode('utf-8-sig'),
                        file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv",
                        mime="text/csv"
                    )
                    
                    # é”™è¯¯ä¿¡æ¯
                    errors = processor.get_errors()
                    if errors:
                        with st.expander(f"å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ ({len(errors)})"):
                            for req_id, error in errors:
                                st.error(f"{req_id}: {error}")
                else:
                    result_ph.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
                    
            except Exception as e:
                progress_ph.empty()
                result_ph.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
    else:
        st.warning("è¯·å…ˆæ·»åŠ éœ€æ±‚")
    # è·å–å»é‡éœ€æ±‚
    unique_reqs = []
    seen = set()
    for req in st.session_state.collected_requirements:
        key = req["éœ€æ±‚æè¿°"].strip()
        if key and key not in seen:
            seen.add(key)
            if not req["éœ€æ±‚ç¼–å·"]:
                req["éœ€æ±‚ç¼–å·"] = f"REQ-{len(unique_reqs)+1:03d}"
            unique_reqs.append(req)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if st.session_state.source_counts:
        st.info(f"æ•°æ®æ¥æº: {' | '.join(st.session_state.source_counts)}")
        st.info(f"å»é‡åæ€»è®¡: {len(unique_reqs)} æ¡éœ€æ±‚")
    
    # é¢„è§ˆè¡¨æ ¼
    if unique_reqs:
        preview_df = pd.DataFrame(unique_reqs)
        st.dataframe(preview_df, use_container_width=True)
        
        st.divider()
        st.markdown("### ç”Ÿæˆè®¾ç½®")
        
        parallel = st.number_input("å¹¶è¡Œå¤„ç†æ•°", 1, 8, 4)
        progress_ph = st.empty()
        result_ph = st.empty()
        
        if st.button("å¼€å§‹æ‰¹é‡ç”Ÿæˆ", type="primary"):
            try:
                # å‡†å¤‡ç”Ÿæˆ
                progress_bar = progress_ph.progress(0)
                result_ph.info("æ­£åœ¨ç”Ÿæˆ...")
                
                # åˆ›å»ºå¤„ç†å™¨
                processor = BatchProcessor(
                    model=model,
                    base_url=base_url,
                    headers=headers,
                    pos_n=pos_n,
                    neg_n=neg_n,
                    edge_n=edge_n,
                    temperature=temperature,
                    max_workers=parallel,
                    background_knowledge=st.session_state.get('background_knowledge'),
                    dynamic_mode=auto_mode,
                    dynamic_params=dyn_params
                )
                
                # å‡†å¤‡éœ€æ±‚åˆ—è¡¨
                req_list = [(r["éœ€æ±‚æè¿°"], r["éœ€æ±‚ç¼–å·"]) for r in unique_reqs]
                
                # æ‰§è¡Œç”Ÿæˆ
                df_result = processor.process_batch(req_list)
                progress_bar.progress(100)
                
                if df_result is not None and not df_result.empty:
                    result_ph.success(f"å·²ç”Ÿæˆ {len(df_result)} æ¡æµ‹è¯•ç”¨ä¾‹")
                    st.dataframe(df_result, use_container_width=True)
                    
                    # å‡†å¤‡ä¸‹è½½
                    excel_data = BytesIO()
                    with pd.ExcelWriter(excel_data, engine='openpyxl') as writer:
                        df_result.to_excel(writer, index=False)
                    excel_data.seek(0)
                    
                    # ä¸‹è½½æŒ‰é’®
                    st.download_button(
                        "ğŸ“¥ ä¸‹è½½ Excel",
                        data=excel_data,
                        file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                    
                    st.download_button(
                        "ğŸ“¥ ä¸‹è½½ CSV",
                        data=df_result.to_csv(index=False).encode('utf-8-sig'),
                        file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv",
                        mime="text/csv"
                    )
                    
                    # é”™è¯¯ä¿¡æ¯
                    errors = processor.get_errors()
                    if errors:
                        with st.expander(f"å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ ({len(errors)})"):
                            for req_id, error in errors:
                                st.error(f"{req_id}: {error}")
                else:
                    result_ph.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
                    
            except Exception as e:
                progress_ph.empty()
                result_ph.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
    else:
        st.warning("è¯·å…ˆæ·»åŠ éœ€æ±‚")
        
        # åˆ›å»ºå·¦å³ä¸¤åˆ—å¸ƒå±€
        col1, col2 = st.columns(2)
        
        # æ¸²æŸ“ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†
        with col1:
            st.markdown("### éœ€æ±‚è¾“å…¥")
            render_batch_input()
            
        with col2:
            st.markdown("### éœ€æ±‚é¢„è§ˆä¸ç”Ÿæˆ")
            render_batch_preview()
        
        with col1:
            st.markdown("### éœ€æ±‚è¾“å…¥")
            
            # æ¸…ç©ºæŒ‰é’®
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰éœ€æ±‚"):
                reqmgr.clear_requirements()
                st.success("å·²æ¸…ç©ºæ‰€æœ‰éœ€æ±‚")
            
            # 1. é£ä¹¦æ–‡æ¡£è¾“å…¥
            feishu_doc = st.text_input("é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID", placeholder="è¾“å…¥é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID")
            if feishu_doc:
                with st.spinner("æ­£åœ¨è¯»å–é£ä¹¦æ–‡æ¡£..."):
                    try:
                        doc_content = fetch_feishu_document(feishu_doc)
                        if doc_content:
                            parts = re.split(r"\n\s*\n+", doc_content.strip())
                            feishu_reqs = [p for p in parts if len(p.strip()) > MIN_PARAGRAPH_LENGTH]
                            reqmgr.add_requirements_batch(feishu_reqs, "é£ä¹¦æ–‡æ¡£")
                            st.success(f"å·²å¯¼å…¥ {len(feishu_reqs)} æ¡éœ€æ±‚")
                    except Exception as e:
                        st.error(f"é£ä¹¦æ–‡æ¡£è¯»å–å¤±è´¥: {e}")
                            
            # 2. æ–‡ä»¶ä¸Šä¼ 
            uploaded_files = st.file_uploader("ä¸Šä¼ éœ€æ±‚æ–‡ä»¶", 
                                           type=["xlsx", "docx", "pdf", "txt", "csv"],
                                           accept_multiple_files=True)
            if uploaded_files:
                for file in uploaded_files:
                    try:
                        lname = file.name.lower()
                        with st.spinner(f"æ­£åœ¨å¤„ç† {file.name}..."):
                            if lname.endswith('.xlsx'):
                                sheets = read_excel(file)
                                if sheets:
                                    for sheet_name, df in sheets.items():
                                        for col in df.columns:
                                            rows = df[col].dropna().astype(str).str.strip()
                                            df_reqs = [r for r in rows if len(r.strip()) > MIN_PARAGRAPH_LENGTH]
                                            reqmgr.add_requirements_batch(df_reqs, f"Excel-{file.name}")
                            elif lname.endswith('.docx'):
                                content = read_word(file)
                                if content:
                                    parts = re.split(r"\n\s*\n+", content.strip())
                                    word_reqs = [p for p in parts if len(p.strip()) > MIN_PARAGRAPH_LENGTH]
                                    reqmgr.add_requirements_batch(word_reqs, f"Word-{file.name}")
                            elif lname.endswith('.pdf'):
                                content = read_background_doc(file)
                                if content:
                                    parts = re.split(r"\n\s*\n+", content.strip())
                                    pdf_reqs = [p for p in parts if len(p.strip()) > MIN_PARAGRAPH_LENGTH]
                                    reqmgr.add_requirements_batch(pdf_reqs, f"PDF-{file.name}")
                            elif lname.endswith(('.txt', '.csv')):
                                text = file.getvalue().decode('utf-8')
                                lines = [l for l in text.splitlines() if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                                reqmgr.add_requirements_batch(lines, f"Text-{file.name}")
                    except Exception as e:
                        st.error(f"å¤„ç†æ–‡ä»¶ {file.name} å¤±è´¥: {e}")
                        
            # 3. ç›´æ¥ç²˜è´´éœ€æ±‚æ–‡æœ¬
            manual_reqs = st.text_area("ç›´æ¥è¾“å…¥éœ€æ±‚ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰", 
                                     placeholder="éœ€æ±‚1\néœ€æ±‚2\néœ€æ±‚3...",
                                     height=150)
            if st.button("æ·»åŠ æ‰‹å·¥è¾“å…¥"):
                if manual_reqs:
                    lines = [l for l in manual_reqs.splitlines() if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                    if lines:
                        reqmgr.add_requirements_batch(lines, "æ‰‹å·¥è¾“å…¥")
                        st.success(f"å·²æ·»åŠ  {len(lines)} æ¡éœ€æ±‚")
                else:
                    st.warning("è¯·è¾“å…¥éœ€æ±‚å†…å®¹")
                    
        with col2:
            st.markdown("### éœ€æ±‚é¢„è§ˆä¸ç”Ÿæˆ")
            
            # è·å–å»é‡åçš„éœ€æ±‚
            unique_reqs = reqmgr.get_unique_requirements()
            
            # æ˜¾ç¤ºæ¥æºç»Ÿè®¡
            source_summary = reqmgr.get_source_summary()
            if source_summary:
                st.info(f"æ•°æ®æ¥æº: {source_summary}")
                st.info(f"å»é‡åæ€»è®¡: {len(unique_reqs)} æ¡éœ€æ±‚")
                
            # éœ€æ±‚é¢„è§ˆè¡¨æ ¼
            if unique_reqs:
                preview_df = pd.DataFrame(unique_reqs)
                st.dataframe(preview_df, use_container_width=True)
                
                # ç”Ÿæˆæ§åˆ¶å‚æ•°
                st.divider()
                st.markdown("### ç”Ÿæˆè®¾ç½®")
                parallel = st.number_input("å¹¶è¡Œå¤„ç†æ•°", 1, 8, 4)
                
                # ç”Ÿæˆè¿›åº¦æŒ‡ç¤ºå™¨
                progress_ph = st.empty()
                result_ph = st.empty()
                
                if st.button("å¼€å§‹æ‰¹é‡ç”Ÿæˆ", type="primary"):
                    try:
                        progress_bar = progress_ph.progress(0)
                        result_ph.info("æ­£åœ¨ç”Ÿæˆ...")
                        
                        # å‡†å¤‡éœ€æ±‚åˆ—è¡¨
                        req_list = reqmgr.get_requirements_for_batch()
                        
                        # åˆ›å»ºå¤„ç†å™¨
                        from test_batch import BatchProcessor
                        processor = BatchProcessor(
                            model=model,
                            base_url=base_url,
                            headers=headers,
                            pos_n=pos_n,
                            neg_n=neg_n,
                            edge_n=edge_n,
                            temperature=temperature,
                            max_workers=parallel,
                            background_knowledge=st.session_state.get('background_knowledge'),
                            dynamic_mode=auto_mode,
                            dynamic_params=dyn_params
                        )
                        
                        # å¯åŠ¨æ‰¹å¤„ç†
                        df_result = processor.process_batch(req_list)
                        
                        # æ›´æ–°è¿›åº¦
                        progress_bar.progress(100)
                        
                        if df_result is not None and not df_result.empty:
                            result_ph.success(f"å·²ç”Ÿæˆ {len(df_result)} æ¡æµ‹è¯•ç”¨ä¾‹")
                            
                            # æ˜¾ç¤ºç»“æœ
                            st.dataframe(df_result, use_container_width=True)
                            
                            # ä¸‹è½½æŒ‰é’®
                            excel_data = BytesIO()
                            with pd.ExcelWriter(excel_data, engine='openpyxl') as writer:
                                df_result.to_excel(writer, index=False)
                            excel_data.seek(0)
                            
                            st.download_button(
                                "ğŸ“¥ ä¸‹è½½ Excel",
                                data=excel_data,
                                file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                            
                            st.download_button(
                                "ğŸ“¥ ä¸‹è½½ CSV",
                                data=df_result.to_csv(index=False).encode('utf-8-sig'),
                                file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv",
                                mime="text/csv"
                            )
                            
                            # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                            errors = processor.get_errors()
                            if errors:
                                with st.expander(f"å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ ({len(errors)})"):
                                    for req_id, error in errors:
                                        st.error(f"{req_id}: {error}")
                        else:
                            result_ph.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
                    except Exception as e:
                        progress_ph.empty()
                        result_ph.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
            else:
                st.warning("è¯·å…ˆæ·»åŠ éœ€æ±‚")
                
                # ç”Ÿæˆæ§åˆ¶å‚æ•°
                st.divider()
                st.markdown("### ç”Ÿæˆè®¾ç½®")
                parallel = st.number_input("å¹¶è¡Œå¤„ç†æ•°", 1, 8, 4)
                
                # ç”Ÿæˆè¿›åº¦æŒ‡ç¤ºå™¨
                progress_ph = st.empty()
                result_ph = st.empty()
                
                if st.button("å¼€å§‹æ‰¹é‡ç”Ÿæˆ", type="primary"):
                    if len(unique_reqs) == 0:
                        st.error("æ²¡æœ‰å¯ç”¨çš„éœ€æ±‚")
                    else:
                        try:
                            progress_bar = progress_ph.progress(0)
                            result_ph.info("æ­£åœ¨ç”Ÿæˆ...")
                            
                            # å‡†å¤‡éœ€æ±‚åˆ—è¡¨
                            req_list = [(r["éœ€æ±‚æè¿°"], r["éœ€æ±‚ç¼–å·"]) for r in unique_reqs]
                            
                            # åˆ›å»ºå¤„ç†å™¨
                            from test_batch import BatchProcessor
                            processor = BatchProcessor(
                                model=model,
                                base_url=base_url,
                                headers=headers,
                                pos_n=pos_n,
                                neg_n=neg_n,
                                edge_n=edge_n,
                                temperature=temperature,
                                max_workers=parallel,
                                background_knowledge=st.session_state.get('background_knowledge'),
                                dynamic_mode=auto_mode,
                                dynamic_params=dyn_params
                            )
                            
                            # å¯åŠ¨æ‰¹å¤„ç†
                            df_result = processor.process_batch(req_list)
                            
                            # æ›´æ–°è¿›åº¦
                            progress_bar.progress(100)
                            
                            if df_result is not None and not df_result.empty:
                                result_ph.success(f"å·²ç”Ÿæˆ {len(df_result)} æ¡æµ‹è¯•ç”¨ä¾‹")
                                
                                # æ˜¾ç¤ºç»“æœ
                                st.dataframe(df_result, use_container_width=True)
                                
                                # ä¸‹è½½æŒ‰é’®
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½ Excel",
                                    data=df_result.to_excel(index=False).getvalue(),
                                    file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                                
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½ CSV",
                                    data=df_result.to_csv(index=False).encode('utf-8-sig'),
                                    file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv",
                                    mime="text/csv"
                                )
                                
                                # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                                errors = processor.get_errors()
                                if errors:
                                    with st.expander(f"å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ ({len(errors)})"):
                                        for req_id, error in errors:
                                            st.error(f"{req_id}: {error}")
                            else:
                                result_ph.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
                        except Exception as e:
                            progress_ph.empty()
                            result_ph.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
            else:
                st.warning("è¯·å…ˆæ·»åŠ éœ€æ±‚")
                                    collected.append({"éœ€æ±‚ç¼–å·": "", "éœ€æ±‚æè¿°": r, "æ¥æº": "æ‰‹å·¥"})
                                source_counts.append(f"æ‰‹å·¥:{len(manual_list)}")

                        st.divider()
                        # é¢å¤–æŒ‡ä»¤è¾“å…¥çª—å£
                        extra_cmd = st.text_area("é¢å¤–æŒ‡ä»¤/å¤‡æ³¨ (å¯é€‰)", placeholder="å¦‚éœ€ç‰¹æ®Šå¤„ç†æˆ–è¡¥å……è¯´æ˜ï¼Œè¯·åœ¨æ­¤è¾“å…¥", height=80)

                        # éœ€æ±‚å»é‡ä¸é¢„è§ˆ
                        unique_reqs = []
                        seen = set()
                        for r in collected:
                            key = r["éœ€æ±‚æè¿°"].strip()
                            if key not in seen:
                                seen.add(key)
                                unique_reqs.append(r)

                        st.info(f"æ¥æºç»Ÿè®¡: {' | '.join(source_counts) if source_counts else 'æ— '} | åˆå¹¶åå»é‡: {len(unique_reqs)} æ¡")

                        if unique_reqs:
                            preview_df = pd.DataFrame(unique_reqs)
                            if "éœ€æ±‚ç¼–å·" in preview_df.columns:
                                for i in range(len(preview_df)):
                                    if not preview_df.at[i, "éœ€æ±‚ç¼–å·"]:
                                        preview_df.at[i, "éœ€æ±‚ç¼–å·"] = f"REQ-{i+1:03d}"
                            st.subheader("è¯†åˆ«å‡ºçš„éœ€æ±‚é¢„è§ˆ (æ ‡å‡†æ ¼å¼)")
                            st.dataframe(preview_df, use_container_width=True)
                            if extra_cmd:
                                st.write(f"**é¢å¤–æŒ‡ä»¤/å¤‡æ³¨ï¼š** {extra_cmd}")

                        if st.button("æ‰¹é‡ç”Ÿæˆ (æ··åˆæ¥æº)"):
                            if not unique_reqs:
                                st.error("æ²¡æœ‰å¯ç”¨éœ€æ±‚")
                            else:
                                req_list = [r["éœ€æ±‚æè¿°"] for r in unique_reqs]
                                df_all = process_batch_requirements(
                                    base_url,
                                    req_list,
                                    headers,
                                    model,
                                    pos_n,
                                    neg_n,
                                    edge_n,
                                    temperature,
                                    st.session_state.get('background_knowledge'),
                                    dynamic=auto_mode,
                                    dyn_params=dyn_params,
                                )
                                st.dataframe(df_all)
                                make_excel_download(df_all, "æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx")
                                make_csv_download(df_all, "æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv")
            except Exception as e:
                st.error(f"ç”Ÿæˆå¼‚å¸¸: {e}")

        st.divider()
        # 2. æ‰‹å·¥æ–‡æœ¬ (ä¸€è¡Œä¸€ä¸ªéœ€æ±‚)
        st.markdown("**æ‰‹å·¥è¾“å…¥éœ€æ±‚ (æ¯è¡Œä¸€ä¸ª)**")
        manual_text = st.text_area("æ‰‹å·¥éœ€æ±‚åˆ—è¡¨", placeholder="éœ€æ±‚1...\néœ€æ±‚2...", height=150)
        if manual_text:
            manual_list = [l.strip() for l in manual_text.splitlines() if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
            if manual_list:
                collected.extend([(l, "Manual") for l in manual_list])
                source_counts.append(f"æ‰‹å·¥:{len(manual_list)}")

        st.divider()
        # 3. ç½‘é¡µé“¾æ¥ -> éœ€æ±‚æå– (ç®€å•æŒ‰æ®µè½æ‹†åˆ†)
        st.markdown("**ç½‘é¡µé“¾æ¥ (éœ€æ±‚æ¥æº) æ¯è¡Œä¸€ä¸ª URL**")
        url_require_text = st.text_area("éœ€æ±‚é“¾æ¥åˆ—è¡¨", placeholder="https://example.com/page1\nhttps://example.com/page2", height=110, key="req_url_box")
        fetch_req_urls = st.button("æŠ“å–é“¾æ¥éœ€æ±‚")
        if fetch_req_urls:
            raw_urls = [u.strip() for u in url_require_text.splitlines() if u.strip()]
            valid_urls = [u for u in raw_urls if _is_valid_url(u)]
            fetched_req = []
            for u in valid_urls[:6]:  # é™åˆ¶ 6 ä¸ªé¿å…è¶…æ—¶
                with st.spinner(f"æŠ“å– {u} ..."):
                    txt = fetch_url_content(u, max_chars=16000)
                # ç²—åˆ†æ®µ
                segments = re.split(r"\n\s*\n+", txt)
                seg_clean = [s.strip() for s in segments if len(s.strip()) > MIN_PARAGRAPH_LENGTH]
                # é™åˆ¶æ¯ä¸ªé“¾æ¥æœ€å¤§æ®µæ•° 25
                seg_clean = seg_clean[:25]
                if seg_clean:
                    # store each with source indicating origin URL
                    fetched_req.extend([(s, f"Web:{u}") for s in seg_clean])
            if fetched_req:
                # å­˜å…¥ sessionï¼Œå…è®¸é‡å¤ç‚¹å‡»è¦†ç›–
                # session stores plain strings for backward compatibility
                st.session_state['batch_url_requirements'] = [s for s, _ in fetched_req]
                # also append to collected with source labels
                collected.extend(fetched_req)
                st.success(f"é“¾æ¥å…±æå– {len(fetched_req)} æ¡å€™é€‰éœ€æ±‚")
            else:
                st.warning("æœªä»é“¾æ¥ä¸­æå–åˆ°æœ‰æ•ˆéœ€æ±‚")

        if st.session_state.get('batch_url_requirements'):
            url_count = len(st.session_state['batch_url_requirements'])
            source_counts.append(f"ç½‘é¡µ:{url_count}")
            with st.expander(f"æŸ¥çœ‹é“¾æ¥æå–éœ€æ±‚ ({url_count})"):
                for i, rtxt in enumerate(st.session_state['batch_url_requirements'][:50]):
                    st.write(f"{i+1}. {rtxt[:160]}{'...' if len(rtxt)>160 else ''}")
            # note: collected already appended when fetch button clicked; if not, append now
            # (avoid double append)
            # collected.extend([(r, 'Web') for r in st.session_state['batch_url_requirements'])

        # 4. å¤–éƒ¨æ¥å£å¯¼å…¥ (URL è¿”å› JSON åˆ—è¡¨æˆ– {'requirements':[...]} )
        st.markdown("**ä»å¤–éƒ¨æ¥å£å¯¼å…¥éœ€æ±‚ (è¿”å› JSON æ•°ç»„æˆ– {requirements: []})**")
        api_url = st.text_input("å¤–éƒ¨æ¥å£ URL", placeholder="https://api.example.com/requirements", key="api_import_url")
        api_auth = st.text_input("æ¥å£è®¤è¯ token (å¯é€‰, æ”¾åœ¨ Authorization: Bearer)", type="password", key="api_import_token")
        import_api = st.button("å¯¼å…¥å¤–éƒ¨æ¥å£éœ€æ±‚")
        if import_api and api_url:
            try:
                headers = {"User-Agent": "TestCaseGenBot/1.0"}
                if api_auth and api_auth.strip():
                    headers["Authorization"] = f"Bearer {api_auth.strip()}"
                with st.spinner(f"è¯·æ±‚ {api_url} ..."):
                    resp = requests.get(api_url, headers=headers, timeout=15)
                if resp.status_code != 200:
                    st.error(f"æ¥å£è¿”å›çŠ¶æ€: {resp.status_code}")
                else:
                    try:
                        payload = resp.json()
                    except Exception:
                        st.error("æ¥å£è¿”å›éJSONå†…å®¹ï¼ŒæœŸæœ› JSON æ•°ç»„æˆ–åŒ…å« requirements é”®çš„å¯¹è±¡")
                        payload = None
                    fetched_api = []
                    if isinstance(payload, list):
                        fetched_api = [str(x).strip() for x in payload if isinstance(x, str) and len(x.strip()) > MIN_PARAGRAPH_LENGTH]
                    elif isinstance(payload, dict) and isinstance(payload.get('requirements'), list):
                        fetched_api = [str(x).strip() for x in payload.get('requirements') if isinstance(x, str) and len(x.strip()) > MIN_PARAGRAPH_LENGTH]
                    else:
                        st.error("JSON ç»“æ„ä¸ç¬¦åˆé¢„æœŸï¼šä¼ å…¥åˆ—è¡¨æˆ–åŒ…å« 'requirements' çš„å¯¹è±¡")
                    if fetched_api:
                        collected.extend([(r, f"API:{api_url}") for r in fetched_api])
                        source_counts.append(f"API:{len(fetched_api)}")
                        st.success(f"ä»æ¥å£å¯¼å…¥ {len(fetched_api)} æ¡éœ€æ±‚")
            except Exception as e:
                st.error(f"å¤–éƒ¨æ¥å£å¯¼å…¥å¤±è´¥: {e}")

        # å»é‡ & æ¸…ç†: collected contains tuples (text, source)
        unique_reqs = []  # type: List[str]
        dedup_records: List[Dict[str, str]] = []
        seen = set()
        for text, src in collected:
            key = text.strip()
            if key and key not in seen:
                seen.add(key)
                unique_reqs.append(key)
                dedup_records.append({
                    "æ¥æº": src,
                    "éœ€æ±‚ç¼–å·": extract_req_id(key) or "",
                    "æ‘˜è¦": (key.splitlines()[0][:80] if key else ""),
                    "å†…å®¹": key,
                })

        st.info(f"æ¥æºç»Ÿè®¡: {' | '.join(source_counts) if source_counts else 'æ— '} | åˆå¹¶åå»é‡: {len(unique_reqs)} æ¡")

        # æ˜¾ç¤ºæ ‡å‡†åŒ–è¯†åˆ«ç»“æœè¡¨æ ¼
        if dedup_records:
            try:
                df_recs = pd.DataFrame(dedup_records)
                with st.expander(f"å·²è¯†åˆ«éœ€æ±‚é¢„è§ˆ (å…±{len(df_recs)} æ¡)"):
                    st.dataframe(df_recs[['æ¥æº', 'éœ€æ±‚ç¼–å·', 'æ‘˜è¦', 'å†…å®¹']].head(200), use_container_width=True)
            except Exception:
                # é€€åŒ–æ˜¾ç¤º
                with st.expander("å·²è¯†åˆ«éœ€æ±‚ (çº¯æ–‡æœ¬é¢„è§ˆ)"):
                    for i, r in enumerate(dedup_records[:200], 1):
                        st.write(f"{i}. [{r['æ¥æº']}] {r['éœ€æ±‚ç¼–å·']} {r['æ‘˜è¦']}")

        # æ‰¹é‡ç”ŸæˆæŒ‰é’®
        if st.button("æ‰¹é‡ç”Ÿæˆ (æ··åˆæ¥æº)"):
            if not unique_reqs:
                st.error("æ²¡æœ‰å¯ç”¨éœ€æ±‚")
            else:
                df_all = process_batch_requirements(
                    base_url,
                    unique_reqs,
                    headers,
                    model,
                    pos_n,
                    neg_n,
                    edge_n,
                    temperature,
                    st.session_state.get('background_knowledge'),
                    dynamic=auto_mode,
                    dyn_params=dyn_params,
                )
                st.dataframe(df_all)
                make_excel_download(df_all, "æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx")
                make_csv_download(df_all, "æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv")
    with tab3:
        st.subheader("ç¤ºä¾‹ä¸æœ€ä½³å®è·µ")
        for ex in get_requirement_examples(): st.write(f"- {ex}")
        st.markdown("---")
        st.subheader("èƒŒæ™¯çŸ¥è¯†è¾“å…¥æ–¹å¼")
        st.markdown("""
        **æ”¯æŒçš„è¾“å…¥æ–¹å¼ï¼š**
        - ğŸ“„ **ä¸Šä¼ æ–‡ä»¶**: æ”¯æŒ .docx, .txt, .md, .pdf æ ¼å¼
        - ğŸ“ **ç›´æ¥ç²˜è´´**: å¤åˆ¶æ–‡æ¡£å†…å®¹ç›´æ¥ç²˜è´´åˆ°æ–‡æœ¬æ¡†
        - ğŸŒ **ç½‘é¡µé“¾æ¥**: è¾“å…¥æ–‡æ¡£URLï¼Œè‡ªåŠ¨æŠ“å–å†…å®¹
        - ğŸª¶ **é£ä¹¦æ–‡æ¡£**: é€šè¿‡APIè®¿é—®æˆ–å¯¼å‡ºåä¸Šä¼ 

        **é£ä¹¦æ–‡æ¡£è®¿é—®é—®é¢˜è§£å†³ï¼š**
        - **æƒé™ä¸è¶³**: ä½¿ç”¨ tenant_access_token åªèƒ½è®¿é—®å…¬å¼€æ–‡æ¡£
        - **æ›¿ä»£æ–¹æ¡ˆ**:
          1. åœ¨é£ä¹¦ä¸­å¯¼å‡ºä¸º Word/PDF â†’ ä¸Šä¼ æ–‡ä»¶
          2. å¤åˆ¶æ–‡æ¡£å†…å®¹ â†’ ç›´æ¥ç²˜è´´åˆ°æ–‡æœ¬æ¡†
          3. è®¾ç½®æ–‡æ¡£ä¸ºå…¬å¼€åˆ†äº« â†’ ä½¿ç”¨ç½‘é¡µé“¾æ¥è¾“å…¥
        """)
        st.markdown("---")
        st.subheader("æ ‡å‡†è¾“å‡ºæ ¼å¼æ¨¡æ¿")
        output_tpl = get_output_format_template()
        st.code(output_tpl, language="csv")
        st.caption("è¿™æ˜¯ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹CSVçš„æ ‡å‡†æ ¼å¼ï¼Œç¬¬ä¸€è¡Œä¸ºè¡¨å¤´ï¼Œç¬¬äºŒè¡Œä¸ºå ä½ç¬¦ç¤ºä¾‹ã€‚")
    st.markdown("---")
    st.subheader("æ ‡å‡† Prompt æ¨¡æ¿")
    tpl = get_standard_prompt_template()
    st.code(tpl, language="text")
    st.caption("å ä½ç¬¦ç¤ºä¾‹: {èƒŒæ™¯çŸ¥è¯†} / {åˆ—åé€—å·åˆ†éš”} / {éœ€æ±‚ç¼–å·} / {éœ€æ±‚å…¨æ–‡} / {æ­£å‘æ•°} / {å¼‚å¸¸æ•°} / {è¾¹ç•Œæ•°} / {æ€»ç”¨ä¾‹æ•°}")
    st.caption("æ¨¡å‹è®¡è´¹: MiMo-7B-RL å…è´¹; å…¶ä½™ (Qwen / Deepseek / Qwen2.5-VL) è®¡è´¹ | ä½¿ç”¨å›ºå®šå†…éƒ¨ API Key")