"""å¤„ç†æ‰¹é‡å¯¼å…¥å’Œé¢„è§ˆçš„å‡½æ•°"""

import streamlit as st
from typing import Dict, Any, List, Optional
import pandas as pd
from docx import Document
import PyPDF2
from io import BytesIO, StringIO
import re
# from test_batch import BatchProcessor  # æš‚æ—¶æ³¨é‡Šæ‰ï¼Œæ¨¡å—ä¸å­˜åœ¨
from ai_requirement_processor import AIRequirementProcessor, estimate_requirement_complexity

# å¸¸é‡
MIN_PARAGRAPH_LENGTH = 10

def fetch_feishu_document(doc_id_or_url: str) -> Optional[str]:
    """è·å–é£ä¹¦æ–‡æ¡£å†…å®¹"""
    try:
        # å¯¼å…¥test.pyä¸­çš„fetch_url_contentå‡½æ•°
        from test import fetch_url_content
        
        # å¦‚æœæ˜¯æ–‡æ¡£IDè€Œä¸æ˜¯å®Œæ•´URLï¼Œæ„é€ URL
        if not doc_id_or_url.startswith('http'):
            doc_id_or_url = f"https://mi.feishu.cn/docx/{doc_id_or_url}"
        
        # ä½¿ç”¨test.pyä¸­çš„fetch_url_contentå‡½æ•°
        content = fetch_url_content(doc_id_or_url)
        
        # æ£€æŸ¥æ˜¯å¦è¿”å›é”™è¯¯ - åªæœ‰å½“å†…å®¹æ˜ç¡®ä»¥é”™è¯¯æ ‡è¯†å¼€å§‹æ—¶æ‰è¿”å›None
        if content.startswith("ã€é£ä¹¦APIé”™è¯¯ã€‘") or "ç½‘é¡µæŠ“å–ä½†éœ€è¦ç™»å½•" in content:
            return None
            
        return content
        
    except Exception as e:
        import logging
        logging.error(f"è·å–é£ä¹¦æ–‡æ¡£å¤±è´¥: {e}")
        return None

def handle_batch_input() -> None:
    """å¤„ç†æ‰¹é‡å¯¼å…¥éœ€æ±‚çš„è¾“å…¥éƒ¨åˆ†"""
    try:
        st.markdown("### éœ€æ±‚è¾“å…¥")
        
        # AIéœ€æ±‚å¤„ç†é…ç½®
        st.markdown("#### AIéœ€æ±‚æ™ºèƒ½å¤„ç†")
        col1, col2 = st.columns(2)
        with col1:
            enable_ai_analysis = st.checkbox("å¯ç”¨AIéœ€æ±‚åˆ†æ", value=True, 
                                           help="ä½¿ç”¨AIè‡ªåŠ¨è¯†åˆ«éœ€æ±‚ç±»å‹ã€ä¼˜å…ˆçº§å’Œå¤æ‚åº¦")
        with col2:
            enable_ai_decomposition = st.checkbox("å¯ç”¨AIéœ€æ±‚åˆ†è§£", value=True,
                                                help="è‡ªåŠ¨å°†å¤æ‚éœ€æ±‚åˆ†è§£ä¸ºå¯æµ‹è¯•çš„å­éœ€æ±‚")
        
        # æ¸…ç©ºæŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰éœ€æ±‚"):
            st.session_state.collected_requirements = []
            st.session_state.source_counts = []
            st.session_state.enable_ai_analysis = enable_ai_analysis
            st.session_state.enable_ai_decomposition = enable_ai_decomposition
            st.success("å·²æ¸…ç©ºæ‰€æœ‰éœ€æ±‚")
        
        # 1. é£ä¹¦æ–‡æ¡£è¾“å…¥
        feishu_doc = st.text_input(
            "é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID", 
            placeholder="è¾“å…¥é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID"
        )
        if feishu_doc:
            with st.spinner("æ­£åœ¨è¯»å–é£ä¹¦æ–‡æ¡£..."):
                doc_content = fetch_feishu_document(feishu_doc)
                if doc_content:
                    parts = re.split(r"\n\s*\n+", doc_content.strip())
                    feishu_reqs = [p for p in parts 
                                if len(p.strip()) > MIN_PARAGRAPH_LENGTH]
                    if feishu_reqs:
                        add_requirements_batch(feishu_reqs, "é£ä¹¦æ–‡æ¡£", 
                                             enable_ai_analysis, enable_ai_decomposition)
                        st.success(f"å·²å¯¼å…¥ {len(feishu_reqs)} æ¡éœ€æ±‚")
        
        # 2. æ–‡ä»¶ä¸Šä¼ 
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ éœ€æ±‚æ–‡ä»¶",
            type=["xlsx", "docx", "pdf", "txt", "csv"],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            for file in uploaded_files:
                with st.spinner(f"æ­£åœ¨å¤„ç† {file.name}..."):
                    process_uploaded_file(file, enable_ai_analysis, enable_ai_decomposition)
        
        # 3. æ‰‹åŠ¨è¾“å…¥
        manual_reqs = st.text_area(
            "ç›´æ¥è¾“å…¥éœ€æ±‚ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
            placeholder="éœ€æ±‚1\néœ€æ±‚2\néœ€æ±‚3...",
            height=150
        )
        
        if st.button("æ·»åŠ æ‰‹å·¥è¾“å…¥"):
            if manual_reqs:
                lines = [l.strip() for l in manual_reqs.splitlines() 
                        if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                if lines:
                    add_requirements_batch(lines, "æ‰‹å·¥è¾“å…¥", 
                                         enable_ai_analysis, enable_ai_decomposition)
                    st.success(f"å·²æ·»åŠ  {len(lines)} æ¡éœ€æ±‚")
            else:
                st.warning("è¯·è¾“å…¥éœ€æ±‚å†…å®¹")
                
    except Exception as e:
        st.error(f"éœ€æ±‚è¾“å…¥å¤„ç†é”™è¯¯: {str(e)}")
        if st.session_state.get("debug_mode"):
            st.exception(e)

def handle_batch_preview_and_generate(
    base_url: str,
    model: str,
    temperature: float,
    headers: List[str],
    pos_n: int,
    neg_n: int,
    edge_n: int,
    auto_mode: bool,
    dyn_params: Dict[str, Any],
    api_key: str
) -> None:
    """å¤„ç†æ‰¹é‡éœ€æ±‚çš„é¢„è§ˆå’Œç”Ÿæˆéƒ¨åˆ†"""
    try:
        st.markdown("### éœ€æ±‚é¢„è§ˆä¸ç”Ÿæˆ")
        
        # è·å–å·²æ”¶é›†çš„éœ€æ±‚
        requirements = st.session_state.get("collected_requirements", [])
        
        if not requirements:
            st.warning("è¯·å…ˆæ·»åŠ éœ€æ±‚")
            return
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        source_counts = st.session_state.get("source_counts", [])
        if source_counts:
            st.info("æ•°æ®æ¥æº: " + " | ".join(source_counts))
        st.info(f"æ€»è®¡: {len(requirements)} æ¡éœ€æ±‚")
        
        # AIéœ€æ±‚å¤„ç†é€‰é¡¹
        enable_ai_analysis = st.session_state.get("enable_ai_analysis", True)
        enable_ai_decomposition = st.session_state.get("enable_ai_decomposition", True)
        
        if enable_ai_analysis and api_key:
            st.markdown("#### AIéœ€æ±‚æ™ºèƒ½å¤„ç†")
            if st.button("ğŸ” æ‰§è¡ŒAIéœ€æ±‚åˆ†æ", type="secondary"):
                with st.spinner("æ­£åœ¨æ‰§è¡ŒAIéœ€æ±‚åˆ†æ..."):
                    try:
                        # åˆ›å»ºAIå¤„ç†å™¨
                        ai_processor = AIRequirementProcessor(
                            client=OpenAI(api_key=api_key, base_url=base_url),
                            model=model,
                            temperature=temperature
                        )
                        
                        # è·å–éœ€æ±‚æ–‡æœ¬åˆ—è¡¨
                        req_texts = [r["éœ€æ±‚æè¿°"] for r in requirements]
                        
                        # æ‰§è¡ŒAIåˆ†æ
                        processed_reqs = ai_processor.process_batch_requirements(req_texts)
                        
                        # æ›´æ–°éœ€æ±‚ä¿¡æ¯
                        for i, processed_req in enumerate(processed_reqs):
                            if i < len(requirements):
                                requirements[i].update({
                                    "ç±»å‹": processed_req["type"],
                                    "ä¼˜å…ˆçº§": processed_req["priority"],
                                    "å¤æ‚åº¦": processed_req["complexity"],
                                    "æ˜¯å¦åˆ†è§£": "æ˜¯" if processed_req["is_decomposed"] else "å¦"
                                })
                        
                        st.success(f"AIåˆ†æå®Œæˆï¼å…±åˆ†æ {len(processed_reqs)} æ¡éœ€æ±‚")
                        
                    except Exception as e:
                        st.error(f"AIéœ€æ±‚åˆ†æå¤±è´¥: {str(e)}")
        
        # é¢„è§ˆè¡¨æ ¼
        preview_df = pd.DataFrame(requirements)
        st.dataframe(preview_df, use_container_width=True)
        
        st.divider()
        st.markdown("### ç”Ÿæˆè®¾ç½®")
        
        parallel = st.number_input("å¹¶è¡Œå¤„ç†æ•°", 1, 8, 4)
        progress_ph = st.empty()
        result_ph = st.empty()
        
        if st.button("å¼€å§‹æ‰¹é‡ç”Ÿæˆ", type="primary"):
            try:
                progress_bar = progress_ph.progress(0)
                result_ph.info("æ­£åœ¨ç”Ÿæˆ...")
                
                # åˆ›å»ºå¤„ç†å™¨
                processor = BatchProcessor(
                    model=model,
                    base_url=base_url,
                    headers=headers,
                    pos_n=pos_n,
                    neg_n=neg_n,
                    edge_n=edge_n,
                    temperature=temperature,
                    max_workers=parallel,
                    background_knowledge=st.session_state.get('background_knowledge'),
                    dynamic_mode=auto_mode,
                    dynamic_params=dyn_params
                )
                
                # å‡†å¤‡éœ€æ±‚åˆ—è¡¨
                req_list = get_requirements_for_batch(requirements)
                
                # å¦‚æœå¯ç”¨äº†AIåˆ†è§£ï¼Œä½¿ç”¨åˆ†è§£åçš„å­éœ€æ±‚
                if enable_ai_decomposition and api_key:
                    try:
                        ai_processor = AIRequirementProcessor(
                            client=OpenAI(api_key=api_key, base_url=base_url),
                            model=model,
                            temperature=temperature
                        )
                        
                        # å¯¹å¤æ‚éœ€æ±‚è¿›è¡Œåˆ†è§£
                        decomposed_reqs = []
                        for req_text in req_list:
                            complexity = estimate_requirement_complexity(req_text)
                            if complexity == "é«˜":
                                sub_reqs = ai_processor.decompose_requirement(req_text)
                                for sub_req in sub_reqs:
                                    decomposed_reqs.append(sub_req["sub_requirement"])
                            else:
                                decomposed_reqs.append(req_text)
                        
                        req_list = decomposed_reqs
                        st.info(f"AIåˆ†è§£åå…± {len(req_list)} æ¡å¯æµ‹è¯•éœ€æ±‚")
                        
                    except Exception as e:
                        st.warning(f"AIéœ€æ±‚åˆ†è§£å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹éœ€æ±‚: {str(e)}")
                
                # æ‰§è¡Œç”Ÿæˆ
                df_result = processor.process_batch(req_list)
                progress_bar.progress(100)
                
                if df_result is not None and not df_result.empty:
                    result_ph.success(f"å·²ç”Ÿæˆ {len(df_result)} æ¡æµ‹è¯•ç”¨ä¾‹")
                    st.dataframe(df_result, use_container_width=True)
                    
                    # å‡†å¤‡ä¸‹è½½
                    excel_data = BytesIO()
                    with pd.ExcelWriter(excel_data, engine='openpyxl') as writer:
                        df_result.to_excel(writer, index=False)
                    excel_data.seek(0)
                    
                    # ä¸‹è½½æŒ‰é’®
                    st.download_button(
                        "ğŸ“¥ ä¸‹è½½ Excel",
                        data=excel_data,
                        file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                    
                    st.download_button(
                        "ğŸ“¥ ä¸‹è½½ CSV",
                        data=df_result.to_csv(index=False).encode('utf-8-sig'),
                        file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv",
                        mime="text/csv"
                    )
                    
                    # é”™è¯¯ä¿¡æ¯
                    errors = processor.get_errors()
                    if errors:
                        with st.expander(f"å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ ({len(errors)})"):
                            for req_id, error in errors:
                                st.error(f"{req_id}: {error}")
                else:
                    result_ph.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
                    
            except Exception as e:
                progress_ph.empty()
                result_ph.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {str(e)}")
                if st.session_state.get("debug_mode"):
                    st.exception(e)
                    
    except Exception as e:
        st.error(f"é¢„è§ˆå’Œç”Ÿæˆé”™è¯¯: {str(e)}")
        if st.session_state.get("debug_mode"):
            st.exception(e)

def process_uploaded_file(file, enable_ai_analysis: bool = True, enable_ai_decomposition: bool = True) -> None:
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼Œä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«éœ€æ±‚"""
    try:
        name = file.name.lower()
        
        if name.endswith('.xlsx'):
            df = pd.read_excel(file)
            # è‡ªåŠ¨æ£€æµ‹éœ€æ±‚åˆ—
            req_columns = [col for col in df.columns if any(keyword in col for keyword in ['éœ€æ±‚', 'è¦æ±‚', 'åŠŸèƒ½', 'æè¿°'])]
            if not req_columns:
                req_columns = [df.columns[0]]  # é»˜è®¤ä½¿ç”¨ç¬¬ä¸€åˆ—
            
            col = st.selectbox(f"é€‰æ‹©éœ€æ±‚åˆ— ({file.name})", req_columns)
            df_reqs = df[col].dropna().astype(str).str.strip().tolist()
            
            if df_reqs:
                add_requirements_batch(df_reqs, f"Excel-{file.name}", 
                                     enable_ai_analysis, enable_ai_decomposition)
                st.success(f"å·²å¯¼å…¥ {len(df_reqs)} æ¡éœ€æ±‚")
        
        elif name.endswith('.docx'):
            doc = Document(file)
            # æå–æ‰€æœ‰æ®µè½æ–‡æœ¬
            full_text = "\n".join([p.text.strip() for p in doc.paragraphs if p.text.strip()])
            
            if enable_ai_analysis:
                # ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«éœ€æ±‚æ®µè½
                st.info("ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«Wordæ–‡æ¡£ä¸­çš„éœ€æ±‚...")
                ai_identified_reqs = identify_requirements_with_ai(full_text, file.name)
                if ai_identified_reqs:
                    add_requirements_batch(ai_identified_reqs, f"Word-AIè¯†åˆ«-{file.name}",
                                         enable_ai_analysis, enable_ai_decomposition)
                    st.success(f"AIè¯†åˆ«å‡º {len(ai_identified_reqs)} æ¡éœ€æ±‚")
                else:
                    # AIè¯†åˆ«å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
                    word_reqs = [p.text.strip() for p in doc.paragraphs 
                                if len(p.text.strip()) > MIN_PARAGRAPH_LENGTH]
                    if word_reqs:
                        add_requirements_batch(word_reqs, f"Word-ä¼ ç»Ÿ-{file.name}",
                                             enable_ai_analysis, enable_ai_decomposition)
                        st.success(f"ä¼ ç»Ÿæ–¹æ³•å¯¼å…¥ {len(word_reqs)} æ¡éœ€æ±‚")
            else:
                # ä¸ä½¿ç”¨AIï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
                word_reqs = [p.text.strip() for p in doc.paragraphs 
                            if len(p.text.strip()) > MIN_PARAGRAPH_LENGTH]
                if word_reqs:
                    add_requirements_batch(word_reqs, f"Word-ä¼ ç»Ÿ-{file.name}",
                                         enable_ai_analysis, enable_ai_decomposition)
                    st.success(f"å·²å¯¼å…¥ {len(word_reqs)} æ¡éœ€æ±‚")
        
        elif name.endswith('.pdf'):
            pdf_reader = PyPDF2.PdfReader(BytesIO(file.getvalue()))
            # æå–æ‰€æœ‰æ–‡æœ¬
            full_text = ""
            for page in pdf_reader.pages:
                full_text += page.extract_text() + "\n"
            
            if enable_ai_analysis:
                # ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«PDFä¸­çš„éœ€æ±‚
                st.info("ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«PDFæ–‡æ¡£ä¸­çš„éœ€æ±‚...")
                ai_identified_reqs = identify_requirements_with_ai(full_text, file.name)
                if ai_identified_reqs:
                    add_requirements_batch(ai_identified_reqs, f"PDF-AIè¯†åˆ«-{file.name}",
                                         enable_ai_analysis, enable_ai_decomposition)
                    st.success(f"AIè¯†åˆ«å‡º {len(ai_identified_reqs)} æ¡éœ€æ±‚")
                else:
                    # AIè¯†åˆ«å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
                    parts = re.split(r"\n\s*\n+", full_text.strip())
                    pdf_reqs = [p for p in parts if len(p.strip()) > MIN_PARAGRAPH_LENGTH]
                    if pdf_reqs:
                        add_requirements_batch(pdf_reqs, f"PDF-ä¼ ç»Ÿ-{file.name}",
                                             enable_ai_analysis, enable_ai_decomposition)
                        st.success(f"ä¼ ç»Ÿæ–¹æ³•å¯¼å…¥ {len(pdf_reqs)} æ¡éœ€æ±‚")
            else:
                # ä¸ä½¿ç”¨AIï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
                parts = re.split(r"\n\s*\n+", full_text.strip())
                pdf_reqs = [p for p in parts if len(p.strip()) > MIN_PARAGRAPH_LENGTH]
                if pdf_reqs:
                    add_requirements_batch(pdf_reqs, f"PDF-ä¼ ç»Ÿ-{file.name}",
                                         enable_ai_analysis, enable_ai_decomposition)
                    st.success(f"å·²å¯¼å…¥ {len(pdf_reqs)} æ¡éœ€æ±‚")
        
        elif name.endswith(('.txt', '.csv')):
            stringio = StringIO(file.getvalue().decode("utf-8"))
            full_text = stringio.read()
            
            if enable_ai_analysis:
                # ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«æ–‡æœ¬ä¸­çš„éœ€æ±‚
                st.info("ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«æ–‡æœ¬æ–‡ä»¶ä¸­çš„éœ€æ±‚...")
                ai_identified_reqs = identify_requirements_with_ai(full_text, file.name)
                if ai_identified_reqs:
                    add_requirements_batch(ai_identified_reqs, f"Text-AIè¯†åˆ«-{file.name}",
                                         enable_ai_analysis, enable_ai_decomposition)
                    st.success(f"AIè¯†åˆ«å‡º {len(ai_identified_reqs)} æ¡éœ€æ±‚")
                else:
                    # AIè¯†åˆ«å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
                    lines = [l.strip() for l in full_text.splitlines() 
                            if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                    if lines:
                        add_requirements_batch(lines, f"Text-ä¼ ç»Ÿ-{file.name}",
                                             enable_ai_analysis, enable_ai_decomposition)
                        st.success(f"ä¼ ç»Ÿæ–¹æ³•å¯¼å…¥ {len(lines)} æ¡éœ€æ±‚")
            else:
                # ä¸ä½¿ç”¨AIï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
                lines = [l.strip() for l in full_text.splitlines() 
                        if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                if lines:
                    add_requirements_batch(lines, f"Text-ä¼ ç»Ÿ-{file.name}",
                                         enable_ai_analysis, enable_ai_decomposition)
                    st.success(f"å·²å¯¼å…¥ {len(lines)} æ¡éœ€æ±‚")
                
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶ {file.name} å¤±è´¥: {str(e)}")
        if st.session_state.get("debug_mode"):
            st.exception(e)

def add_requirements_batch(requirements: List[str], source: str, 
                          enable_ai_analysis: bool = True, enable_ai_decomposition: bool = True) -> None:
    """æ·»åŠ ä¸€æ‰¹éœ€æ±‚åˆ°ä¼šè¯çŠ¶æ€"""
    if not hasattr(st.session_state, "collected_requirements"):
        st.session_state.collected_requirements = []
    if not hasattr(st.session_state, "source_counts"):
        st.session_state.source_counts = []
    
    # ä¿å­˜AIå¤„ç†é…ç½®
    st.session_state.enable_ai_analysis = enable_ai_analysis
    st.session_state.enable_ai_decomposition = enable_ai_decomposition
        
    for req in requirements:
        req_text = req.strip()
        if not req_text:
            continue
            
        # åŸºç¡€åˆ†æï¼ˆå³ä½¿AIåˆ†ææœªå¯ç”¨ï¼‰
        complexity = estimate_requirement_complexity(req_text)
        
        st.session_state.collected_requirements.append({
            "éœ€æ±‚ç¼–å·": "",
            "éœ€æ±‚æè¿°": req_text,
            "æ¥æº": source,
            "å¤æ‚åº¦": complexity,
            "ç±»å‹": "å¾…åˆ†æ",
            "ä¼˜å…ˆçº§": "å¾…åˆ†æ",
            "æ˜¯å¦åˆ†è§£": "å¦"
        })
    st.session_state.source_counts.append(f"{source}:{len(requirements)}")

def get_requirements_for_batch(requirements: List[Dict[str, str]]) -> List[str]:
    """å°†éœ€æ±‚åˆ—è¡¨è½¬æ¢ä¸ºæ‰¹å¤„ç†æ ¼å¼"""
    return [r["éœ€æ±‚æè¿°"] for r in requirements if r["éœ€æ±‚æè¿°"].strip()]

def identify_requirements_with_ai(full_text: str, filename: str) -> List[str]:
    """ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«æ–‡æ¡£ä¸­çš„éœ€æ±‚"""
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰APIé…ç½®
        if not st.session_state.get('api_key') or not st.session_state.get('base_url'):
            st.warning("æœªé…ç½®API Keyï¼Œæ— æ³•ä½¿ç”¨AIéœ€æ±‚è¯†åˆ«")
            return []
        
        # åˆ›å»ºAIå¤„ç†å™¨
        from openai import OpenAI
        client = OpenAI(
            api_key=st.session_state.get('api_key'),
            base_url=st.session_state.get('base_url')
        )
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""è¯·ä»ä»¥ä¸‹æ–‡æ¡£å†…å®¹ä¸­è¯†åˆ«å‡ºæ‰€æœ‰çš„è½¯ä»¶éœ€æ±‚ã€‚æ–‡æ¡£å†…å®¹ï¼š
        
{full_text[:4000]}  # é™åˆ¶æ–‡æœ¬é•¿åº¦é¿å…tokenè¶…é™

è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚è¯†åˆ«éœ€æ±‚ï¼š
1. è¯†åˆ«ç‹¬ç«‹çš„åŠŸèƒ½éœ€æ±‚ã€æ€§èƒ½éœ€æ±‚ã€å®‰å…¨éœ€æ±‚ç­‰
2. æ¯ä¸ªéœ€æ±‚åº”è¯¥æ˜¯å®Œæ•´ã€å¯æµ‹è¯•çš„ç‹¬ç«‹å•å…ƒ
3. å¿½ç•¥æ–‡æ¡£çš„æ ¼å¼æ ‡è®°ã€æ ‡é¢˜ã€é¡µçœ‰é¡µè„šç­‰ééœ€æ±‚å†…å®¹
4. å°†è¯†åˆ«å‡ºçš„éœ€æ±‚æŒ‰JSONæ•°ç»„æ ¼å¼è¿”å›

è¿”å›æ ¼å¼ï¼š
{{
    "requirements": [
        "éœ€æ±‚1æè¿°",
        "éœ€æ±‚2æè¿°",
        ...
    ]
}}

è¯·åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚"""
        
        response = client.chat.completions.create(
            model=st.session_state.get('model', 'deepseek-chat'),
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è½¯ä»¶éœ€æ±‚åˆ†æå¸ˆï¼Œèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«æ–‡æ¡£ä¸­çš„è½¯ä»¶éœ€æ±‚ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        result_text = response.choices[0].message.content
        
        # è§£æç»“æœ
        import json
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if json_match:
            result = json.loads(json_match.group())
            requirements = result.get("requirements", [])
            
            # è¿‡æ»¤ç©ºéœ€æ±‚å’Œè¿‡çŸ­éœ€æ±‚
            filtered_reqs = [req.strip() for req in requirements 
                           if req.strip() and len(req.strip()) > MIN_PARAGRAPH_LENGTH]
            
            return filtered_reqs
        else:
            st.warning("AIéœ€æ±‚è¯†åˆ«è¿”å›æ ¼å¼ä¸æ­£ç¡®")
            return []
            
    except Exception as e:
        logger.error(f"AIéœ€æ±‚è¯†åˆ«å¤±è´¥ ({filename}): {e}")
        st.warning(f"AIéœ€æ±‚è¯†åˆ«å¤±è´¥: {str(e)}")
        return []