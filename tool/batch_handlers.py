"""å¤„ç†æ‰¹é‡å¯¼å…¥å’Œé¢„è§ˆçš„å‡½æ•°"""

import streamlit as st
from typing import Dict, Any, List
import pandas as pd
from docx import Document
import PyPDF2
from io import BytesIO, StringIO
import re
from test_batch import BatchProcessor

def handle_batch_input() -> None:
    """å¤„ç†æ‰¹é‡å¯¼å…¥éœ€æ±‚çš„è¾“å…¥éƒ¨åˆ†"""
    try:
        st.markdown("### éœ€æ±‚è¾“å…¥")
        
        # æ¸…ç©ºæŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰éœ€æ±‚"):
            st.session_state.collected_requirements = []
            st.session_state.source_counts = []
            st.success("å·²æ¸…ç©ºæ‰€æœ‰éœ€æ±‚")
        
        # 1. é£ä¹¦æ–‡æ¡£è¾“å…¥
        feishu_doc = st.text_input(
            "é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID", 
            placeholder="è¾“å…¥é£ä¹¦æ–‡æ¡£é“¾æ¥æˆ–ID"
        )
        if feishu_doc:
            with st.spinner("æ­£åœ¨è¯»å–é£ä¹¦æ–‡æ¡£..."):
                doc_content = fetch_feishu_document(feishu_doc)
                if doc_content:
                    parts = re.split(r"\n\s*\n+", doc_content.strip())
                    feishu_reqs = [p for p in parts 
                                if len(p.strip()) > MIN_PARAGRAPH_LENGTH]
                    if feishu_reqs:
                        add_requirements_batch(feishu_reqs, "é£ä¹¦æ–‡æ¡£")
                        st.success(f"å·²å¯¼å…¥ {len(feishu_reqs)} æ¡éœ€æ±‚")
        
        # 2. æ–‡ä»¶ä¸Šä¼ 
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ éœ€æ±‚æ–‡ä»¶",
            type=["xlsx", "docx", "pdf", "txt", "csv"],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            for file in uploaded_files:
                with st.spinner(f"æ­£åœ¨å¤„ç† {file.name}..."):
                    process_uploaded_file(file)
        
        # 3. æ‰‹åŠ¨è¾“å…¥
        manual_reqs = st.text_area(
            "ç›´æ¥è¾“å…¥éœ€æ±‚ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
            placeholder="éœ€æ±‚1\néœ€æ±‚2\néœ€æ±‚3...",
            height=150
        )
        
        if st.button("æ·»åŠ æ‰‹å·¥è¾“å…¥"):
            if manual_reqs:
                lines = [l.strip() for l in manual_reqs.splitlines() 
                        if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
                if lines:
                    add_requirements_batch(lines, "æ‰‹å·¥è¾“å…¥")
                    st.success(f"å·²æ·»åŠ  {len(lines)} æ¡éœ€æ±‚")
            else:
                st.warning("è¯·è¾“å…¥éœ€æ±‚å†…å®¹")
                
    except Exception as e:
        st.error(f"éœ€æ±‚è¾“å…¥å¤„ç†é”™è¯¯: {str(e)}")
        if st.session_state.get("debug_mode"):
            st.exception(e)

def handle_batch_preview_and_generate(
    base_url: str,
    model: str,
    temperature: float,
    headers: List[str],
    pos_n: int,
    neg_n: int,
    edge_n: int,
    auto_mode: bool,
    dyn_params: Dict[str, Any]
) -> None:
    """å¤„ç†æ‰¹é‡éœ€æ±‚çš„é¢„è§ˆå’Œç”Ÿæˆéƒ¨åˆ†"""
    try:
        st.markdown("### éœ€æ±‚é¢„è§ˆä¸ç”Ÿæˆ")
        
        # è·å–å·²æ”¶é›†çš„éœ€æ±‚
        requirements = st.session_state.get("collected_requirements", [])
        
        if not requirements:
            st.warning("è¯·å…ˆæ·»åŠ éœ€æ±‚")
            return
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        source_counts = st.session_state.get("source_counts", [])
        if source_counts:
            st.info("æ•°æ®æ¥æº: " + " | ".join(source_counts))
        st.info(f"æ€»è®¡: {len(requirements)} æ¡éœ€æ±‚")
        
        # é¢„è§ˆè¡¨æ ¼
        preview_df = pd.DataFrame(requirements)
        st.dataframe(preview_df, use_container_width=True)
        
        st.divider()
        st.markdown("### ç”Ÿæˆè®¾ç½®")
        
        parallel = st.number_input("å¹¶è¡Œå¤„ç†æ•°", 1, 8, 4)
        progress_ph = st.empty()
        result_ph = st.empty()
        
        if st.button("å¼€å§‹æ‰¹é‡ç”Ÿæˆ", type="primary"):
            try:
                progress_bar = progress_ph.progress(0)
                result_ph.info("æ­£åœ¨ç”Ÿæˆ...")
                
                # åˆ›å»ºå¤„ç†å™¨
                processor = BatchProcessor(
                    model=model,
                    base_url=base_url,
                    headers=headers,
                    pos_n=pos_n,
                    neg_n=neg_n,
                    edge_n=edge_n,
                    temperature=temperature,
                    max_workers=parallel,
                    background_knowledge=st.session_state.get('background_knowledge'),
                    dynamic_mode=auto_mode,
                    dynamic_params=dyn_params
                )
                
                # å‡†å¤‡éœ€æ±‚åˆ—è¡¨
                req_list = get_requirements_for_batch(requirements)
                
                # æ‰§è¡Œç”Ÿæˆ
                df_result = processor.process_batch(req_list)
                progress_bar.progress(100)
                
                if df_result is not None and not df_result.empty:
                    result_ph.success(f"å·²ç”Ÿæˆ {len(df_result)} æ¡æµ‹è¯•ç”¨ä¾‹")
                    st.dataframe(df_result, use_container_width=True)
                    
                    # å‡†å¤‡ä¸‹è½½
                    excel_data = BytesIO()
                    with pd.ExcelWriter(excel_data, engine='openpyxl') as writer:
                        df_result.to_excel(writer, index=False)
                    excel_data.seek(0)
                    
                    # ä¸‹è½½æŒ‰é’®
                    st.download_button(
                        "ğŸ“¥ ä¸‹è½½ Excel",
                        data=excel_data,
                        file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                    
                    st.download_button(
                        "ğŸ“¥ ä¸‹è½½ CSV",
                        data=df_result.to_csv(index=False).encode('utf-8-sig'),
                        file_name="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv",
                        mime="text/csv"
                    )
                    
                    # é”™è¯¯ä¿¡æ¯
                    errors = processor.get_errors()
                    if errors:
                        with st.expander(f"å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ ({len(errors)})"):
                            for req_id, error in errors:
                                st.error(f"{req_id}: {error}")
                else:
                    result_ph.error("ç”Ÿæˆå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœ")
                    
            except Exception as e:
                progress_ph.empty()
                result_ph.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {str(e)}")
                if st.session_state.get("debug_mode"):
                    st.exception(e)
                    
    except Exception as e:
        st.error(f"é¢„è§ˆå’Œç”Ÿæˆé”™è¯¯: {str(e)}")
        if st.session_state.get("debug_mode"):
            st.exception(e)

def process_uploaded_file(file) -> None:
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
    try:
        name = file.name.lower()
        if name.endswith('.xlsx'):
            df = pd.read_excel(file)
            df_reqs = df['éœ€æ±‚æè¿°'].dropna().tolist()
            if df_reqs:
                add_requirements_batch(df_reqs, f"Excel-{file.name}")
                st.success(f"å·²å¯¼å…¥ {len(df_reqs)} æ¡éœ€æ±‚")
        
        elif name.endswith('.docx'):
            doc = Document(file)
            word_reqs = [p.text.strip() for p in doc.paragraphs 
                        if len(p.text.strip()) > MIN_PARAGRAPH_LENGTH]
            if word_reqs:
                add_requirements_batch(word_reqs, f"Word-{file.name}")
                st.success(f"å·²å¯¼å…¥ {len(word_reqs)} æ¡éœ€æ±‚")
        
        elif name.endswith('.pdf'):
            pdf_reader = PyPDF2.PdfReader(BytesIO(file.getvalue()))
            pdf_reqs = []
            for page in pdf_reader.pages:
                text = page.extract_text()
                parts = re.split(r"\n\s*\n+", text.strip())
                pdf_reqs.extend([p for p in parts 
                            if len(p.strip()) > MIN_PARAGRAPH_LENGTH])
            if pdf_reqs:
                add_requirements_batch(pdf_reqs, f"PDF-{file.name}")
                st.success(f"å·²å¯¼å…¥ {len(pdf_reqs)} æ¡éœ€æ±‚")
        
        elif name.endswith(('.txt', '.csv')):
            stringio = StringIO(file.getvalue().decode("utf-8"))
            lines = [l.strip() for l in stringio.readlines() 
                    if len(l.strip()) > MIN_PARAGRAPH_LENGTH]
            if lines:
                add_requirements_batch(lines, f"Text-{file.name}")
                st.success(f"å·²å¯¼å…¥ {len(lines)} æ¡éœ€æ±‚")
                
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶ {file.name} å¤±è´¥: {str(e)}")
        if st.session_state.get("debug_mode"):
            st.exception(e)

def add_requirements_batch(requirements: List[str], source: str) -> None:
    """æ·»åŠ ä¸€æ‰¹éœ€æ±‚åˆ°ä¼šè¯çŠ¶æ€"""
    if not hasattr(st.session_state, "collected_requirements"):
        st.session_state.collected_requirements = []
    if not hasattr(st.session_state, "source_counts"):
        st.session_state.source_counts = []
        
    for req in requirements:
        st.session_state.collected_requirements.append({
            "éœ€æ±‚ç¼–å·": "",
            "éœ€æ±‚æè¿°": req.strip(),
            "æ¥æº": source
        })
    st.session_state.source_counts.append(f"{source}:{len(requirements)}")

def get_requirements_for_batch(requirements: List[Dict[str, str]]) -> List[str]:
    """å°†éœ€æ±‚åˆ—è¡¨è½¬æ¢ä¸ºæ‰¹å¤„ç†æ ¼å¼"""
    return [r["éœ€æ±‚æè¿°"] for r in requirements if r["éœ€æ±‚æè¿°"].strip()]