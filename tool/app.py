# app.py - ä¼˜åŒ–ç‰ˆæœ¬
import os
import re
from io import BytesIO, StringIO
from typing import List, Optional, Dict, Any
import logging

import pandas as pd
import streamlit as st
from docx import Document
from openai import OpenAI
from ai_requirement_processor import AIRequirementProcessor, estimate_requirement_complexity
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =========================
# å¸¸é‡é…ç½®
# =========================
DEFAULT_HEADERS = ["æµ‹è¯•åç§°", "æµ‹è¯•æè¿°", "å‰ç½®æ¡ä»¶", "æµ‹è¯•æ­¥éª¤", "é¢„æœŸç»“æœ"]
DEFAULT_BASE_URL = "https://api.deepseek.com"
DEFAULT_MODEL = "deepseek-chat"
MAX_RETRY_ATTEMPTS = 3
MIN_PARAGRAPH_LENGTH = 10

# =========================
# å¼‚å¸¸å¤„ç†è£…é¥°å™¨
# =========================
def handle_errors(func):
    """é”™è¯¯å¤„ç†è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error(f"å‡½æ•° {func.__name__} æ‰§è¡Œå¤±è´¥: {e}")
            st.error(f"æ“ä½œå¤±è´¥: {str(e)}")
            return None
    return wrapper


# =========================
# Helpers: read requirements
# =========================

def identify_requirements_with_ai(full_text: str, filename: str) -> List[str]:
    """ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«æ–‡æ¡£ä¸­çš„éœ€æ±‚"""
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰APIé…ç½®
        api_key = st.session_state.get('api_key') or os.getenv("DEEPSEEK_API_KEY", "")
        base_url = st.session_state.get('base_url', "https://api.deepseek.com")
        
        if not api_key:
            st.warning("æœªé…ç½®API Keyï¼Œæ— æ³•ä½¿ç”¨AIéœ€æ±‚è¯†åˆ«")
            return []
        
        # åˆ›å»ºAIå®¢æˆ·ç«¯
        client = OpenAI(api_key=api_key, base_url=base_url)
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""è¯·ä»ä»¥ä¸‹æ–‡æ¡£å†…å®¹ä¸­è¯†åˆ«å‡ºæ‰€æœ‰çš„è½¯ä»¶éœ€æ±‚ã€‚æ–‡æ¡£å†…å®¹ï¼š
        
{full_text[:4000]}  # é™åˆ¶æ–‡æœ¬é•¿åº¦é¿å…tokenè¶…é™

è¯·æŒ‰ç…§ä»¥ä¸‹è¦æ±‚è¯†åˆ«éœ€æ±‚ï¼š
1. è¯†åˆ«ç‹¬ç«‹çš„åŠŸèƒ½éœ€æ±‚ã€æ€§èƒ½éœ€æ±‚ã€å®‰å…¨éœ€æ±‚ç­‰
2. æ¯ä¸ªéœ€æ±‚åº”è¯¥æ˜¯å®Œæ•´ã€å¯æµ‹è¯•çš„ç‹¬ç«‹å•å…ƒ
3. å¿½ç•¥æ–‡æ¡£çš„æ ¼å¼æ ‡è®°ã€æ ‡é¢˜ã€é¡µçœ‰é¡µè„šç­‰ééœ€æ±‚å†…å®¹
4. å°†è¯†åˆ«å‡ºçš„éœ€æ±‚æŒ‰JSONæ•°ç»„æ ¼å¼è¿”å›

è¿”å›æ ¼å¼ï¼š
{{
    "requirements": [
        "éœ€æ±‚1æè¿°",
        "éœ€æ±‚2æè¿°",
        ...
    ]
}}

è¯·åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚"""
        
        response = client.chat.completions.create(
            model=st.session_state.get('model', 'deepseek-chat'),
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è½¯ä»¶éœ€æ±‚åˆ†æå¸ˆï¼Œèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«æ–‡æ¡£ä¸­çš„è½¯ä»¶éœ€æ±‚ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        result_text = response.choices[0].message.content
        
        # è§£æç»“æœ
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if json_match:
            result = json.loads(json_match.group())
            requirements = result.get("requirements", [])
            
            # è¿‡æ»¤ç©ºéœ€æ±‚å’Œè¿‡çŸ­éœ€æ±‚
            filtered_reqs = [req.strip() for req in requirements 
                           if req.strip() and len(req.strip()) > MIN_PARAGRAPH_LENGTH]
            
            return filtered_reqs
        else:
            st.warning("AIéœ€æ±‚è¯†åˆ«è¿”å›æ ¼å¼ä¸æ­£ç¡®")
            return []
            
    except Exception as e:
        logger.error(f"AIéœ€æ±‚è¯†åˆ«å¤±è´¥ ({filename}): {e}")
        st.warning(f"AIéœ€æ±‚è¯†åˆ«å¤±è´¥: {str(e)}")
        return []
def read_word(file) -> str:
    """è¯»å–Wordæ–‡æ¡£å†…å®¹"""
    try:
        doc = Document(file)
        paras = [p.text.strip() for p in doc.paragraphs if p.text and p.text.strip()]
        content = "\n".join(paras)
        return content
    except Exception as e:
        logging.error(f"è¯»å–Wordæ–‡æ¡£å¤±è´¥: {e}")
        raise ValueError(f"æ— æ³•è¯»å–Wordæ–‡æ¡£: {e}")

def split_word_requirements(content: str, mode: str = "by_blank_line") -> List[str]:
    """æŒ‰æŒ‡å®šæ¨¡å¼åˆ†å‰²éœ€æ±‚æ–‡æœ¬"""
    if not content or not content.strip():
        return []

    if mode == "single":
        return [content.strip()]

    # æŒ‰è¿ç»­ç©ºè¡Œåˆ†æ®µ
    blocks = re.split(r"\n\s*\n+", content.strip())
    # è¿‡æ»¤å¤ªçŸ­çš„æ®µè½ï¼ˆå°‘äº10ä¸ªå­—ç¬¦çš„æ®µè½å¯èƒ½æ— æ„ä¹‰ï¼‰
    return [b.strip() for b in blocks if len(b.strip()) > 10]

def read_excel(uploaded_file) -> dict:
    """è¯»å–Excelæ–‡ä»¶ï¼Œè¿”å›æ‰€æœ‰sheetçš„æ•°æ®"""
    try:
        xl = pd.ExcelFile(uploaded_file)
        sheets = {}
        for sheet in xl.sheet_names:
            df = xl.parse(sheet)
            sheets[sheet] = df
        return sheets
    except Exception as e:
        logging.error(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")
        raise ValueError(f"æ— æ³•è¯»å–Excelæ–‡ä»¶: {e}")


# =========================
# DeepSeek client factory
# =========================
@st.cache_resource(show_spinner=False)
def make_client(api_key: str, base_url: str) -> OpenAI:
    """åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼Œå¸¦ç¼“å­˜"""
    if not api_key:
        raise ValueError("API Key ä¸èƒ½ä¸ºç©º")
    return OpenAI(api_key=api_key, base_url=base_url)


# =========================
# Prompt builder
# =========================
def build_prompt(requirement: str, headers: list[str], pos_n: int, neg_n: int, edge_n: int):
    cols_line = ",".join(headers)
    guidance = f"""
ä½ æ˜¯ä¸€åèµ„æ·±æµ‹è¯•å·¥ç¨‹å¸ˆã€‚è¯·åŸºäºä»¥ä¸‹åŠŸèƒ½éœ€æ±‚ï¼Œç”Ÿæˆé«˜è´¨é‡æµ‹è¯•ç”¨ä¾‹ï¼Œè¦†ç›–æ­£å‘ï¼ˆ{pos_n} æ¡ï¼‰ã€å¼‚å¸¸ï¼ˆ{neg_n} æ¡ï¼‰ã€è¾¹ç•Œï¼ˆ{edge_n} æ¡ï¼‰ã€‚
è¾“å‡ºå¿…é¡»æ˜¯ä¸¥æ ¼çš„ CSVï¼Œç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´ï¼Œè¡¨å¤´åˆ—åä¸¥æ ¼ä¸ºï¼š
{cols_line}

çº¦æŸï¼š
- ä»…è¾“å‡º CSV æ•°æ®ï¼Œä¸è¦åŒ…å«å¤šä½™è¯´æ˜ã€ä»£ç å—æ ‡è®°æˆ–ç©ºè¡Œã€‚
- â€œæµ‹è¯•æ­¥éª¤â€ç”¨â€œï¼›â€åœ¨åŒä¸€å•å…ƒæ ¼å†…ä¸²è”æ­¥éª¤ï¼Œé¿å…æ¢è¡Œã€‚
- æ— å¯ç”¨å‰ç½®æ¡ä»¶æ—¶å¡«â€œæ— â€ã€‚
- ç”¨è¯ç®€æ´ã€å¯æ‰§è¡Œã€å¯å¤ç°ï¼Œé¿å…å«ç³Šæè¿°ã€‚
- ä¸è¦ä½¿ç”¨è‹±æ–‡é€—å·ä»¥å¤–çš„åˆ†éš”ç¬¦ï¼›ä¸­æ–‡å†…å®¹å¯ä»¥åŒ…å«é€—å·ï¼Œä½†æ•´ä½“ä»ä»¥è‹±æ–‡é€—å·åˆ†åˆ—ã€‚
"""
    return f"{guidance}\nåŠŸèƒ½éœ€æ±‚ï¼š\n{requirement}\n"


# =========================
# Call DeepSeek chat
# =========================
def call_deepseek(client: OpenAI, model: str, prompt: str, temperature: float = 0.2):
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„è½¯ä»¶æµ‹è¯•ç”¨ä¾‹ç”ŸæˆåŠ©æ‰‹ï¼Œåªè¾“å‡ºå¹²å‡€çš„CSVæ•°æ®ã€‚"},
            {"role": "user", "content": prompt},
        ],
        temperature=temperature,
    )
    return resp.choices[0].message.content


# =========================
# Parse CSV safely
# =========================
def parse_csv_to_df(csv_text: str, expected_headers: list[str]) -> pd.DataFrame:
    # å»é™¤å¯èƒ½çš„ä»£ç å—å›´æ å’Œ BOM
    cleaned = csv_text.strip()
    cleaned = re.sub(r"^```.*?\n", "", cleaned)
    cleaned = re.sub(r"\n```$", "", cleaned)
    cleaned = cleaned.replace("\ufeff", "")

    # ç›´æ¥å°è¯•è§£æ
    try:
        df = pd.read_csv(StringIO(cleaned))
        # å¦‚æœæ¨¡å‹æœªè¾“å‡ºè¡¨å¤´ï¼Œå°è¯•è¡¥é½
        if list(df.columns) != expected_headers and df.shape[1] == len(expected_headers):
            df.columns = expected_headers
        return df
    except Exception:
        # é€€åŒ–è§£æï¼šæŒ‰è¡Œåˆ‡åˆ†ï¼Œå†æŒ‰é€—å·åˆ‡åˆ†
        lines = [ln for ln in cleaned.splitlines() if ln.strip()]
        # è‹¥é¦–è¡Œä¸æ˜¯æŒ‡å®šè¡¨å¤´ï¼Œåˆ™æ’å…¥æœŸæœ›è¡¨å¤´
        if lines and ",".join(expected_headers) not in lines[0]:
            lines.insert(0, ",".join(expected_headers))
        try:
            df = pd.read_csv(StringIO("\n".join(lines)))
            return df
        except Exception as e:
            raise ValueError(f"CSV è§£æå¤±è´¥ï¼š{e}\nåŸå§‹è¾“å‡ºï¼š\n{csv_text}")


# =========================
# Export helpers
# =========================
def make_excel_download(df: pd.DataFrame, filename="æµ‹è¯•ç”¨ä¾‹.xlsx"):
    buf = BytesIO()
    df.to_excel(buf, index=False)
    buf.seek(0)
    st.download_button(
        "ğŸ’¾ ä¸‹è½½ Excel",
        data=buf,
        file_name=filename,
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

def make_csv_download(df: pd.DataFrame, filename="æµ‹è¯•ç”¨ä¾‹.csv"):
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "ğŸ’¾ ä¸‹è½½ CSV",
        data=csv,
        file_name=filename,
        mime="text/csv",
    )


# =========================
# UI
# =========================
st.set_page_config(page_title="AI æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨ï¼ˆDeepSeekï¼‰", layout="wide")
st.title("ğŸ¤– AI è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼ˆDeepSeek ç‰ˆï¼‰")

with st.sidebar:
    st.header("è¿æ¥è®¾ç½®")
    # API Key ä¼˜å…ˆçº§ï¼šä¾§è¾¹æ è¾“å…¥ > secrets > ç¯å¢ƒå˜é‡
    api_key_input = st.text_input("DeepSeek API Key", type="password", help="å»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ– Streamlit Secretsï¼Œæ›´å®‰å…¨")
    # api_key = api_key_input or st.secrets.get("DEEPSEEK_API_KEY", "") or os.getenv("DEEPSEEK_API_KEY", "")
    api_key = api_key_input or os.getenv("DEEPSEEK_API_KEY", "")

    base_url = st.text_input("API Base URL", value="https://api.deepseek.com")
    model = st.selectbox("æ¨¡å‹", ["deepseek-chat", "deepseek-reasoner"], index=0)
    temperature = st.slider("Temperature", 0.0, 1.0, 0.2, 0.05)

    st.divider()
    st.header("ç½‘ç»œä»£ç†ï¼ˆå¯é€‰ï¼‰")
    proxy = st.text_input("HTTP/HTTPS ä»£ç†ï¼Œä¾‹å¦‚ http://127.0.0.1:7890", value="")
    if proxy:
        os.environ["http_proxy"] = proxy
        os.environ["https_proxy"] = proxy
        st.caption("å·²è®¾ç½®ä»£ç†ç¯å¢ƒå˜é‡ http_proxy / https_proxy")

    st.divider()
    st.header("ç”¨ä¾‹åˆ—è®¾ç½®")
    default_headers = ["æµ‹è¯•åç§°", "æµ‹è¯•æè¿°", "å‰ç½®æ¡ä»¶", "æµ‹è¯•æ­¥éª¤", "é¢„æœŸç»“æœ"]
    headers_text = st.text_input("é€—å·åˆ†éš”çš„åˆ—å", value=",".join(default_headers))
    headers = [h.strip() for h in headers_text.split(",") if h.strip()]
    if not headers:
        st.warning("åˆ—åä¸èƒ½ä¸ºç©ºï¼Œå°†å›é€€ä¸ºé»˜è®¤åˆ—")
        headers = default_headers

    st.divider()
    st.header("æ¯ç±»ç”¨ä¾‹æ•°é‡")
    pos_n = st.number_input("æ­£å‘ç”¨ä¾‹æ•°", min_value=1, max_value=20, value=2, step=1)
    neg_n = st.number_input("å¼‚å¸¸ç”¨ä¾‹æ•°", min_value=1, max_value=20, value=2, step=1)
    edge_n = st.number_input("è¾¹ç•Œç”¨ä¾‹æ•°", min_value=1, max_value=20, value=2, step=1)

tab_single, tab_batch = st.tabs(["å•æ¡éœ€æ±‚", "æ‰¹é‡ï¼ˆExcel/Wordï¼‰"])

# ============ å•æ¡éœ€æ±‚ ============
with tab_single:
    st.subheader("å•æ¡éœ€æ±‚è¾“å…¥")
    requirement_text = st.text_area("è¯·è¾“å…¥åŠŸèƒ½éœ€æ±‚ï¼ˆæ”¯æŒå¤šè¡Œï¼‰", height=200, placeholder="ä¾‹å¦‚ï¼šccu-dsp å”¤é†’æµç¨‹æµ‹è¯•â€¦â€¦")

    if st.button("ğŸš€ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼ˆå•æ¡ï¼‰", type="primary", use_container_width=True):
        if not api_key:
            st.error("è¯·åœ¨ä¾§è¾¹æ é…ç½® DeepSeek API Key")
        elif not requirement_text.strip():
            st.warning("è¯·è¾“å…¥éœ€æ±‚å†…å®¹")
        else:
            client = make_client(api_key, base_url)
            prompt = build_prompt(requirement_text.strip(), headers, pos_n, neg_n, edge_n)
            with st.spinner("æ­£åœ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹â€¦â€¦"):
                try:
                    csv_text = call_deepseek(client, model, prompt, temperature)
                    df = parse_csv_to_df(csv_text, headers)
                    st.success(f"ç”Ÿæˆå®Œæˆï¼Œå…± {len(df)} æ¡ã€‚")
                    st.dataframe(df, use_container_width=True, height=360)
                    make_excel_download(df, filename="æµ‹è¯•ç”¨ä¾‹_å•æ¡.xlsx")
                    make_csv_download(df, filename="æµ‹è¯•ç”¨ä¾‹_å•æ¡.csv")
                except Exception as e:
                    st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")

# ============ æ‰¹é‡éœ€æ±‚ ============
with tab_batch:
    st.subheader("æ‰¹é‡éœ€æ±‚å¯¼å…¥")
    
    # AIéœ€æ±‚å¤„ç†é…ç½®
    st.markdown("#### AIéœ€æ±‚æ™ºèƒ½å¤„ç†")
    col1, col2 = st.columns(2)
    with col1:
        enable_ai_analysis = st.checkbox("å¯ç”¨AIéœ€æ±‚åˆ†æ", value=True, 
                                       help="ä½¿ç”¨AIè‡ªåŠ¨è¯†åˆ«éœ€æ±‚ç±»å‹ã€ä¼˜å…ˆçº§å’Œå¤æ‚åº¦")
    with col2:
        enable_ai_decomposition = st.checkbox("å¯ç”¨AIéœ€æ±‚åˆ†è§£", value=True,
                                            help="è‡ªåŠ¨å°†å¤æ‚éœ€æ±‚åˆ†è§£ä¸ºå¯æµ‹è¯•çš„å­éœ€æ±‚")
    
    uploaded = st.file_uploader("ä¸Šä¼  Excelï¼ˆ.xlsxï¼‰æˆ– Wordï¼ˆ.docxï¼‰", type=["xlsx", "docx"])

    if uploaded:
        if uploaded.name.lower().endswith(".xlsx"):
            sheets = read_excel(uploaded)
            sheet_name = st.selectbox("é€‰æ‹©å·¥ä½œè¡¨", list(sheets.keys()))
            df_sheet = sheets[sheet_name]
            st.write("é¢„è§ˆï¼ˆå‰ 10 è¡Œï¼‰")
            st.dataframe(df_sheet.head(10), use_container_width=True)

            col = st.selectbox("é€‰æ‹©éœ€æ±‚åˆ—", list(df_sheet.columns))
            batch_rows = df_sheet[col].dropna().astype(str).str.strip()
            st.caption(f"å·²æ”¶é›†æœ‰æ•ˆéœ€æ±‚ {batch_rows.shape[0]} æ¡")

            # AIéœ€æ±‚åˆ†ææŒ‰é’®
            if enable_ai_analysis and api_key and not batch_rows.empty:
                if st.button("ğŸ” æ‰§è¡ŒAIéœ€æ±‚åˆ†æ", type="secondary"):
                    with st.spinner("æ­£åœ¨æ‰§è¡ŒAIéœ€æ±‚åˆ†æ..."):
                        try:
                            # åˆ›å»ºAIå¤„ç†å™¨
                            ai_processor = AIRequirementProcessor(
                                client=make_client(api_key, base_url),
                                model=model,
                                temperature=temperature
                            )
                            
                            # æ‰§è¡ŒAIåˆ†æ
                            req_texts = batch_rows.tolist()
                            processed_reqs = ai_processor.process_batch_requirements(req_texts)
                            
                            # æ˜¾ç¤ºåˆ†æç»“æœ
                            analysis_df = pd.DataFrame([{
                                "åŸå§‹éœ€æ±‚": req["original_requirement"],
                                "å¤„ç†éœ€æ±‚": req["sub_requirement"],
                                "ç±»å‹": req["type"],
                                "ä¼˜å…ˆçº§": req["priority"],
                                "å¤æ‚åº¦": req["complexity"],
                                "æ˜¯å¦åˆ†è§£": "æ˜¯" if req["is_decomposed"] else "å¦"
                            } for req in processed_reqs])
                            
                            st.success(f"AIåˆ†æå®Œæˆï¼å…±åˆ†æ {len(processed_reqs)} æ¡éœ€æ±‚")
                            st.dataframe(analysis_df, use_container_width=True)
                            
                            # æ›´æ–°éœ€æ±‚åˆ—è¡¨ä¸ºå¤„ç†åçš„éœ€æ±‚
                            processed_req_texts = [req["sub_requirement"] for req in processed_reqs]
                            batch_rows = pd.Series(processed_req_texts)
                            
                        except Exception as e:
                            st.error(f"AIéœ€æ±‚åˆ†æå¤±è´¥: {str(e)}")
            
            if st.button("ğŸš€ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼ˆæ‰¹é‡ï¼‰", type="primary", use_container_width=True):
                if not api_key:
                    st.error("è¯·åœ¨ä¾§è¾¹æ é…ç½® DeepSeek API Key")
                elif batch_rows.empty:
                    st.warning("æœªæ£€ç´¢åˆ°éœ€æ±‚æ–‡æœ¬")
                else:
                    client = make_client(api_key, base_url)
                    all_cases = []
                    with st.spinner("æ‰¹é‡ç”Ÿæˆä¸­ï¼Œè¯·ç¨å€™â€¦â€¦"):
                        
                        # å¦‚æœå¯ç”¨äº†AIåˆ†è§£ï¼Œå¯¹å¤æ‚éœ€æ±‚è¿›è¡Œåˆ†è§£
                        req_list = batch_rows.tolist()
                        if enable_ai_decomposition:
                            try:
                                ai_processor = AIRequirementProcessor(
                                    client=client,
                                    model=model,
                                    temperature=temperature
                                )
                                
                                decomposed_reqs = []
                                for req_text in req_list:
                                    complexity = estimate_requirement_complexity(req_text)
                                    if complexity == "é«˜":
                                        sub_reqs = ai_processor.decompose_requirement(req_text)
                                        for sub_req in sub_reqs:
                                            decomposed_reqs.append(sub_req["sub_requirement"])
                                    else:
                                        decomposed_reqs.append(req_text)
                                
                                req_list = decomposed_reqs
                                st.info(f"AIåˆ†è§£åå…± {len(req_list)} æ¡å¯æµ‹è¯•éœ€æ±‚")
                                
                            except Exception as e:
                                st.warning(f"AIéœ€æ±‚åˆ†è§£å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹éœ€æ±‚: {str(e)}")
                        
                        for idx, req in enumerate(req_list, start=1):
                            prompt = build_prompt(req, headers, pos_n, neg_n, edge_n)
                            try:
                                csv_text = call_deepseek(client, model, prompt, temperature)
                                df_one = parse_csv_to_df(csv_text, headers)
                                df_one.insert(0, "éœ€æ±‚", req)
                                all_cases.append(df_one)
                            except Exception as e:
                                st.warning(f"ç¬¬ {idx} æ¡éœ€æ±‚ç”Ÿæˆå¤±è´¥ï¼š{e}")
                        if all_cases:
                            df_all = pd.concat(all_cases, ignore_index=True)
                            st.success(f"æ‰¹é‡å®Œæˆï¼Œå…± {len(df_all)} æ¡ç”¨ä¾‹ï¼ˆ{len(all_cases)} æ¡éœ€æ±‚æˆåŠŸç”Ÿæˆï¼‰")
                            st.dataframe(df_all.head(200), use_container_width=True, height=360)
                            make_excel_download(df_all, filename="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx")
                            make_csv_download(df_all, filename="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv")
                        else:
                            st.error("æœªç”Ÿæˆä»»ä½•ç”¨ä¾‹ï¼Œè¯·æ£€æŸ¥éœ€æ±‚æˆ–é‡è¯•ã€‚")

        elif uploaded.name.lower().endswith(".docx"):
            content = read_word(uploaded)
            
            if enable_ai_analysis:
                st.info("ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«Wordæ–‡æ¡£ä¸­çš„éœ€æ±‚...")
                # ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«éœ€æ±‚
                ai_reqs = identify_requirements_with_ai(content, uploaded.name)
                if ai_reqs:
                    reqs = ai_reqs
                    st.success(f"AIæ™ºèƒ½è¯†åˆ«å‡º {len(reqs)} æ¡éœ€æ±‚")
                else:
                    # AIè¯†åˆ«å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
                    split_mode = st.radio("Word åˆ†æ®µæ–¹å¼", ["æŒ‰ç©ºè¡Œåˆ†æ®µ", "æ•´ç¯‡ä½œä¸ºä¸€æ¡éœ€æ±‚"], horizontal=True)
                    reqs = split_word_requirements(content, mode="by_blank_line" if split_mode == "æŒ‰ç©ºè¡Œåˆ†æ®µ" else "single")
                    st.info(f"ä¼ ç»Ÿæ–¹æ³•è¯†åˆ«å‡º {len(reqs)} æ¡éœ€æ±‚")
            else:
                # ä¸ä½¿ç”¨AIï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
                split_mode = st.radio("Word åˆ†æ®µæ–¹å¼", ["æŒ‰ç©ºè¡Œåˆ†æ®µ", "æ•´ç¯‡ä½œä¸ºä¸€æ¡éœ€æ±‚"], horizontal=True)
                reqs = split_word_requirements(content, mode="by_blank_line" if split_mode == "æŒ‰ç©ºè¡Œåˆ†æ®µ" else "single")
                st.info(f"è¯†åˆ«å‡º {len(reqs)} æ¡éœ€æ±‚")
            
            st.caption(f"å·²è¯†åˆ«éœ€æ±‚æ®µè½ {len(reqs)} æ¡")
            if len(reqs) > 0:
                st.text_area("æ®µè½é¢„è§ˆ", value="\n\n".join(reqs[:5]), height=200)

            # AIéœ€æ±‚åˆ†ææŒ‰é’®
            if enable_ai_analysis and api_key and reqs:
                if st.button("ğŸ” æ‰§è¡ŒAIéœ€æ±‚åˆ†æ", type="secondary"):
                    with st.spinner("æ­£åœ¨æ‰§è¡ŒAIéœ€æ±‚åˆ†æ..."):
                        try:
                            # åˆ›å»ºAIå¤„ç†å™¨
                            ai_processor = AIRequirementProcessor(
                                client=make_client(api_key, base_url),
                                model=model,
                                temperature=temperature
                            )
                            
                            # æ‰§è¡ŒAIåˆ†æ
                            processed_reqs = ai_processor.process_batch_requirements(reqs)
                            
                            # æ˜¾ç¤ºåˆ†æç»“æœ
                            analysis_df = pd.DataFrame([{
                                "åŸå§‹éœ€æ±‚": req["original_requirement"],
                                "å¤„ç†éœ€æ±‚": req["sub_requirement"],
                                "ç±»å‹": req["type"],
                                "ä¼˜å…ˆçº§": req["priority"],
                                "å¤æ‚åº¦": req["complexity"],
                                "æ˜¯å¦åˆ†è§£": "æ˜¯" if req["is_decomposed"] else "å¦"
                            } for req in processed_reqs])
                            
                            st.success(f"AIåˆ†æå®Œæˆï¼å…±åˆ†æ {len(processed_reqs)} æ¡éœ€æ±‚")
                            st.dataframe(analysis_df, use_container_width=True)
                            
                            # æ›´æ–°éœ€æ±‚åˆ—è¡¨ä¸ºå¤„ç†åçš„éœ€æ±‚
                            reqs = [req["sub_requirement"] for req in processed_reqs]
                            
                        except Exception as e:
                            st.error(f"AIéœ€æ±‚åˆ†æå¤±è´¥: {str(e)}")
            
            if st.button("ğŸš€ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼ˆæ‰¹é‡ï¼‰", type="primary", use_container_width=True):
                if not api_key:
                    st.error("è¯·åœ¨ä¾§è¾¹æ é…ç½® DeepSeek API Key")
                elif not reqs:
                    st.warning("æœªè¯†åˆ«åˆ°æœ‰æ•ˆéœ€æ±‚å†…å®¹")
                else:
                    client = make_client(api_key, base_url)
                    all_cases = []
                    with st.spinner("æ‰¹é‡ç”Ÿæˆä¸­ï¼Œè¯·ç¨å€™â€¦â€¦"):
                        
                        # å¦‚æœå¯ç”¨äº†AIåˆ†è§£ï¼Œå¯¹å¤æ‚éœ€æ±‚è¿›è¡Œåˆ†è§£
                        req_list = reqs
                        if enable_ai_decomposition:
                            try:
                                ai_processor = AIRequirementProcessor(
                                    client=client,
                                    model=model,
                                    temperature=temperature
                                )
                                
                                decomposed_reqs = []
                                for req_text in req_list:
                                    complexity = estimate_requirement_complexity(req_text)
                                    if complexity == "é«˜":
                                        sub_reqs = ai_processor.decompose_requirement(req_text)
                                        for sub_req in sub_reqs:
                                            decomposed_reqs.append(sub_req["sub_requirement"])
                                    else:
                                        decomposed_reqs.append(req_text)
                                
                                req_list = decomposed_reqs
                                st.info(f"AIåˆ†è§£åå…± {len(req_list)} æ¡å¯æµ‹è¯•éœ€æ±‚")
                                
                            except Exception as e:
                                st.warning(f"AIéœ€æ±‚åˆ†è§£å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹éœ€æ±‚: {str(e)}")
                        
                        for idx, req in enumerate(req_list, start=1):
                            prompt = build_prompt(req, headers, pos_n, neg_n, edge_n)
                            try:
                                csv_text = call_deepseek(client, model, prompt, temperature)
                                df_one = parse_csv_to_df(csv_text, headers)
                                df_one.insert(0, "éœ€æ±‚", req)
                                all_cases.append(df_one)
                            except Exception as e:
                                st.warning(f"ç¬¬ {idx} æ¡éœ€æ±‚ç”Ÿæˆå¤±è´¥ï¼š{e}")
                        if all_cases:
                            df_all = pd.concat(all_cases, ignore_index=True)
                            st.success(f"æ‰¹é‡å®Œæˆï¼Œå…± {len(df_all)} æ¡ç”¨ä¾‹ï¼ˆ{len(all_cases)} æ®µéœ€æ±‚æˆåŠŸç”Ÿæˆï¼‰")
                            st.dataframe(df_all.head(200), use_container_width=True, height=360)
                            make_excel_download(df_all, filename="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.xlsx")
                            make_csv_download(df_all, filename="æµ‹è¯•ç”¨ä¾‹_æ‰¹é‡.csv")
                        else:
                            st.error("æœªç”Ÿæˆä»»ä½•ç”¨ä¾‹ï¼Œè¯·æ£€æŸ¥æ–‡æ¡£æˆ–é‡è¯•ã€‚")
    else:
        st.info("è¯·ä¸Šä¼  Excel æˆ– Word æ–‡ä»¶ä»¥å¼€å§‹æ‰¹é‡ç”Ÿæˆã€‚")


# =========================
# Footer tips
# =========================
st.divider()
st.caption("æç¤ºï¼šè‹¥é‡åˆ°ç½‘ç»œ/è¿æ¥é—®é¢˜ï¼Œå¯åœ¨ä¾§è¾¹æ è®¾ç½®ä»£ç†ï¼›å»ºè®®æŠŠ API Key é…ç½®ä¸ºç¯å¢ƒå˜é‡æˆ– Streamlit Secretsï¼Œé¿å…æ³„éœ²ã€‚")
